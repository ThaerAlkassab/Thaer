{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting & Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../_img/overfitting.jpg\" width=\"450px\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regularization](https://en.wikipedia.org/wiki/Regularization_(mathematics)) techniques in machine learning are used to prevent or reduce [overfitting](https://en.wikipedia.org/wiki/Overfitting) of a model to the training data. The fundamental idea is to simplify the model, making it less accurate on the training set but more accurate on unseen data. Essentially, the goal of regularization is to set a good balance between model complexity and generalization performance.\n",
    "\n",
    "Some specific regularization techniques are [L1 regularization](https://ml-cheatsheet.readthedocs.io/en/latest/regularization.html#l1-regularization), [L2 regularization](https://ml-cheatsheet.readthedocs.io/en/latest/regularization.html#l2-regularization), [noise injection](https://ml-cheatsheet.readthedocs.io/en/latest/regularization.html#injecting-noise), [data augmentation](https://ml-cheatsheet.readthedocs.io/en/latest/regularization.html#data-augmentation), [early stopping](https://ml-cheatsheet.readthedocs.io/en/latest/regularization.html#early-stopping), [dropout](https://ml-cheatsheet.readthedocs.io/en/latest/regularization.html#dropout) and [ensembling](https://ml-cheatsheet.readthedocs.io/en/latest/regularization.html#ensembling). In this lecture we will discuss **L2 regularization** that can be seen as simple and well understood form of regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The SMS Spam Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file [smsspam.txt](../_data/smsspam.txt) contains labeled SMS messages.\n",
    "Label \"ham\" indicates normal messages, label \"spam\" indicates undesired  messages.\n",
    "The goal is to build a classifier that estimates the label based on the text content of the SMS.\n",
    "The error metric should be the average cross-entropy (aka `log_loss`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../_img/sms_spam_problem.jpg\" width=\"100px\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the raw data into a DataFrame!\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"smsspam.txt\", sep=\"\\t\", names=['label', 'message'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   label    5572 non-null   object\n",
      " 1   message  5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "ham     4825\n",
       "spam     747\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of labels.\n",
    "df.groupby(\"label\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to represent SMS messages as numbers?\n",
    "\n",
    "- Machine learning algorithms work with numbers, not words.\n",
    "- One way to transform text into numbers is the [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) approach.\n",
    "  + We assign an index to each word, based on a dictionary.\n",
    "  + Each document is represented by a vector $x = [x_1, \\dots, x_d]$ where $x_j$ denotes how many times the $j$-th word appears in the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../_img/sparse_matrix.png\" width=\"350px\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**: Compute the bag-of-words representation of the following example documents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example documents.\n",
    "documents = [\n",
    "    'John likes to watch movies. Mary likes movies too.',\n",
    "    'Mary also likes to watch football games.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'also',\n",
       " 'football',\n",
       " 'games',\n",
       " 'john',\n",
       " 'likes',\n",
       " 'mary',\n",
       " 'movies',\n",
       " 'to',\n",
       " 'too',\n",
       " 'watch'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set of all words.\n",
    "import string\n",
    "def tokenize(doc):\n",
    "    return [w.strip(string.punctuation) for w in doc.lower().split()]\n",
    "words = set()\n",
    "for doc in documents:\n",
    "    for w in tokenize(doc):\n",
    "        words.add(w)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'also': 0,\n",
       " 'football': 1,\n",
       " 'games': 2,\n",
       " 'john': 3,\n",
       " 'likes': 4,\n",
       " 'mary': 5,\n",
       " 'movies': 6,\n",
       " 'to': 7,\n",
       " 'too': 8,\n",
       " 'watch': 9}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary of word indices.\n",
    "word_to_idx = {w: i for i, w in enumerate(sorted(words))}\n",
    "word_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build input matrix.\n",
    "import numpy as np\n",
    "X = np.zeros((len(documents), len(words)))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 0., 1., 1., 0., 1., 0., 1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, doc in enumerate(documents):\n",
    "    for w in tokenize(doc):\n",
    "        j = word_to_idx[w]\n",
    "        X[i, j] = 1\n",
    "        \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x10 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 14 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shorter solution with sklearn's CountVectorizer.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "X_sp = CountVectorizer(binary=True).fit_transform(documents) # fit(), then transform()\n",
    "X_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 0, 1, 1, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sp.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Sparse Matrices](https://en.wikipedia.org/wiki/Sparse_matrix) in Python\n",
    "\n",
    "- A sparse matrix contains many zeros and only a low ratio of nenzero elements.\n",
    "- The efficient method to store sparse matrices is to store only the nonzeros.\n",
    "- The linear algebra operations operations (like matrix-times-vector) use different algorithms as in the dense case.\n",
    "- NumPy supports dense matrices only.\n",
    "- A library to work with sparse matrices is [scipy.sparse](https://docs.scipy.org/doc/scipy-1.8.0/html-scipyorg/reference/sparse.html). A more general library that supports multidimensional sparse arrays is [Sparse](https://sparse.pydata.org)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some standard storage formats:\n",
    "  + [coo_matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html): A sparse matrix in COOrdinate list format.\n",
    "  + [csr_matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html): Compressed Sparse Row (CSR) matrix\n",
    "  + [csc_matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csc_matrix.html): Compressed Sparse Column (CSC) matrix.\n",
    "  \n",
    "Typically, the COO format is the most convnient for creating/building matrices. However, in computations, the CSR or CSC format can be more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an example COO matrix!\n",
    "import scipy.sparse as sp\n",
    "data = [1, 1, 1, 1, 1]\n",
    "i    = [0, 0, 1, 2, 2] # row indices\n",
    "j    = [0, 3, 1, 4, 5] # column indices\n",
    "\n",
    "A = sp.coo_matrix((data, (i, j)))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of nenzeros.\n",
    "A.nnz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 2, 2], dtype=int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Internal representation (.row, .col, .data).\n",
    "A.row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 1, 4, 5], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 1]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conversion to NumPy array.\n",
    "A.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conversion to CSR format.\n",
    "B = A.tocsr()\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 1, 4, 5], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Internal representation (.indices, .indptr, .data)\n",
    "B.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3, 5], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.indptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting rows.\n",
    "B[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'coo_matrix' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# try selecting rows from a COO matrix\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mA\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'coo_matrix' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# try selecting rows from a COO matrix?\n",
    "A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to CSC format.\n",
    "C = A.tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x1 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try selecting rows from a CSC matrix?\n",
    "C[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6x3 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What happens if we transpose a CSR matrix?\n",
    "B.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to the SMS Spam Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**: Prepare the input matrix $X$ (sparse) and the target vector $y$ (dense)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x8713 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 74169 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = CountVectorizer(binary=True).fit_transform(df['message'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (df['label'] == 'spam').values.astype('int64')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3**: Measure the training and test log_loss error of logistic regression, using 5-fold cross-validation! (Scikit-learn's `LogisticRegression` and `LinearRegression` accept sparse matrices as the input matrix.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.020030998513910356,\n",
       "  0.02026798586333316,\n",
       "  0.018731273244436235,\n",
       "  0.019306333644836884,\n",
       "  0.01860439768051876],\n",
       " [0.04673015055948079,\n",
       "  0.042830755193124764,\n",
       "  0.060999083223150466,\n",
       "  0.06704297424445832,\n",
       "  0.06559486598950316])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "scores_tr = []\n",
    "scores_te = []\n",
    "cv = KFold (5, shuffle=True, random_state=42)\n",
    "for tr, te in cv.split(X):\n",
    "    cl = LogisticRegression()\n",
    "    cl.fit(X[tr], y[tr])\n",
    "    yhat = cl.predict_proba(X)[:, 1]\n",
    "    scores_te.append(log_loss(y[te], yhat[te]))\n",
    "    scores_tr.append(log_loss(y[tr], yhat[tr]))\n",
    "\n",
    "scores_tr, scores_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [L2 Regularization](https://en.wikipedia.org/wiki/Tikhonov_regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../_img/regularization.jpg\" width=\"250\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L2 penalty term: $\\frac{1}{2}\\lambda \\|w\\|^2 = \\frac{1}{2}\\lambda w^Tw$, where $\\lambda \\geq 0$. (Other [norms](https://en.wikipedia.org/wiki/Norm_(mathematics)) could also be used instead of the L2 norm.)\n",
    "- Regularized cross-entropy: $RCE(w) = CE(w) + \\frac{1}{2}\\lambda w^Tw$.\n",
    "  + $\\lambda$ is called the regularization coefficient. Larger $\\lambda$ means stronger regularization.\n",
    "  + An alternative formulation is $RCE^*(w) = C \\cdot CE(w) + \\frac{1}{2} w^Tw$.\n",
    "- Gradient vector: $\\frac{d}{dw} RCE(w) = \\frac{d}{dw} CE(w) + \\lambda w$.\n",
    "- Hessian matrix: $\\left(\\frac{d}{dw}\\right)^2 RCE(w) = \\left(\\frac{d}{dw}\\right)^2 CE(w) + \\lambda I$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4**: Plot the training and test error of logistic regression, as the function of the regularization coefficient $\\lambda$! The relation between $\\lambda$ and scikit-learn's $C$ parameter is $C = 1 / \\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Ridge Regression](https://en.wikipedia.org/wiki/Ridge_regression)\n",
    "\n",
    "- Ridge regression is the L2 regularized variant of linear regression.\n",
    "\n",
    "\n",
    "- The error function is $RSSE(w) = \\left[\\sum_{i=1}^n (\\hat{y}_i - y_i)^2\\right] + \\lambda \\left[\\frac{1}{2} w^T w\\right]$,<br>where $\\lambda \\geq 0$ is the regularization coefficient.\n",
    "\n",
    "\n",
    "- Linear regression is contained as a special case, with $\\lambda$ set to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5**: Train ridge regression models on the Boston Housing data set that predict the `MEDV` column. The error metric should be RMSE. Plot the training and test error of ridge regression, as the function of the regularization coefficient $\\alpha$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Boston Housing data set.\n",
    "columns = []\n",
    "for l in open('../_data/housing_names.txt'):\n",
    "    if l[:4] == '    ' and l[4].isdigit():\n",
    "        columns.append(l.split()[1])\n",
    "df = pd.read_csv('../_data/housing_data.txt', sep='\\t', names=columns)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[:-1]].values # input matrix\n",
    "y = df['MEDV'].values          # target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
