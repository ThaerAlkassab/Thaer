{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate [Logistic Regression](https://en.wikipedia.org/wiki/Logistic_regression)\n",
    "\n",
    "- Logistic regression is an algorithm for **classification**.\n",
    "\n",
    "- Logistic regression builds a **linear model** that separates the two classes by a hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../_img/linear_classifier.jpg\" width=\"300\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, let' discuss first the **univariate** case, with a **binary target** variable and **no bias** term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../_img/logreg_1d.jpg\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Programming Exam Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>study_time</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>David Beckham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jessica Scott</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jack Johnson</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Scunner Campbell</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plain Jane</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Archie Gillis</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  study_time  result\n",
       "0     David Beckham         0.0       0\n",
       "1     Jessica Scott         7.0       1\n",
       "2      Jack Johnson         3.5       0\n",
       "3  Scunner Campbell         6.0       0\n",
       "4       Plain Jane          3.0       1\n",
       "5     Archie Gillis        15.0       1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = [\n",
    "    {'name': 'David Beckham',    'study_time': 0,   'result': 0},\n",
    "    {'name': 'Jessica Scott',    'study_time': 7,   'result': 1},\n",
    "    {'name': 'Jack Johnson',     'study_time': 3.5, 'result': 0},\n",
    "    {'name': 'Scunner Campbell', 'study_time': 6,   'result': 0},\n",
    "    {'name': 'Plain Jane ',      'study_time': 3,   'result': 1},\n",
    "    {'name': 'Archie Gillis',    'study_time': 15,  'result': 1},\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above toy data set contains 2 attributes of 6 students:\n",
    "- Hours spent on preparing for the exam.\n",
    "- Did the student pass the exam? (0=no, 1=yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**: Train a univariate logistic regression model that estimates the `result` column from the `study_time` column!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.75  1.25 -2.25  0.25 -2.75  9.25] [0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "x = df['study_time'].values # input vector\n",
    "y = df['result'].values     # target vector\n",
    "\n",
    "# subtract mean from inpute\n",
    "xm = x.mean()\n",
    "x -= xm\n",
    "\n",
    "print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sigmoid(t):\n",
    "    return 1/(1+np.exp(-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sigmoid (x)\n",
    "\n",
    "w = 0 # initial model parameter\n",
    "\n",
    "yhat = sigmoid(x*w)\n",
    "yhat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.75, 33.21875)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_i = ((yhat - y) * x).sum()\n",
    "\n",
    "ce_ii= (yhat * (1-yhat) * x**2).sum()\n",
    "\n",
    "ce_i, ce_ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2333019755409219"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st Newton's step\n",
    "\n",
    "w -= ce_i / ce_ii\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20726573, 0.57239452, 0.37170029, 0.51457724, 0.34488937,\n",
       "       0.896418  ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = sigmoid(x*w)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4666039510818438"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd Newton's step\n",
    "\n",
    "w -= ce_i / ce_ii\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06398561, 0.64181602, 0.2592522 , 0.52912972, 0.21701265,\n",
       "       0.98682389])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = sigmoid(x*w)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = 0.333032246 CE(w) = 3.103909\n",
      "[0.06398561 0.64181602 0.2592522  0.52912972 0.21701265 0.98682389]\n",
      "w = 0.359110223 CE(w) = 3.06404697\n",
      "[0.1284274  0.60259521 0.32096893 0.5208025  0.28580655 0.95608321]\n",
      "w = 0.360846759 CE(w) = 3.06039476\n",
      "[0.11255707 0.61037476 0.30831727 0.52242933 0.27139565 0.96516813]\n",
      "w = 0.360853783 CE(w) = 3.06038094\n",
      "[0.11156354 0.61089086 0.30748466 0.52253764 0.27045238 0.96570413]\n",
      "w = 0.360853783 CE(w) = 3.06038094\n",
      "[0.11155953 0.61089295 0.30748129 0.52253808 0.27044857 0.96570628]\n",
      "w = 0.360853783 CE(w) = 3.06038094\n",
      "[0.11155953 0.61089295 0.30748129 0.52253808 0.27044857 0.96570628]\n",
      "w = 0.360853783 CE(w) = 3.06038094\n",
      "[0.11155953 0.61089295 0.30748129 0.52253808 0.27044857 0.96570628]\n",
      "w = 0.360853783 CE(w) = 3.06038094\n",
      "[0.11155953 0.61089295 0.30748129 0.52253808 0.27044857 0.96570628]\n",
      "w = 0.360853783 CE(w) = 3.06038094\n",
      "[0.11155953 0.61089295 0.30748129 0.52253808 0.27044857 0.96570628]\n",
      "w = 0.360853783 CE(w) = 3.06038094\n",
      "[0.11155953 0.61089295 0.30748129 0.52253808 0.27044857 0.96570628]\n"
     ]
    }
   ],
   "source": [
    "# Newton steps in for loop\n",
    "for it in range(10):\n",
    "    yhat = sigmoid(x*w)\n",
    "    ce = -(np.log(yhat)* y + np.log(1-yhat) * (1-y)).sum()\n",
    "    ce_i = ((yhat - y) * x).sum()\n",
    "    ce_ii= (yhat * (1-yhat) * x**2).sum()\n",
    "    w -= ce_i / ce_ii\n",
    "    print(f'w = {w:.9f} CE(w) = {ce:.9}')\n",
    "    print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = -(np.log(yhat)* y + np.log(1-yhat) * (1-y)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'P(passing the exam)')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7AAAAFzCAYAAAAHXuXxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAAsTAAALEwEAmpwYAABAG0lEQVR4nO3dd5xcZaH/8c+zPdlserKB9IQ0CC0JhABCUNCAXlBARAUR6cUughXbvT/Fa0Evoqj0EkVAEBAUJYAGIZU0IIT03jfZzfZ5fn/sJCyBJBvI5Mzsft6v177mnDNnZr6Bh8l+Oec8J8QYkSRJkiQp2+UlHUCSJEmSpJawwEqSJEmScoIFVpIkSZKUEyywkiRJkqScYIGVJEmSJOUEC6wkSZIkKScUJB1gb3Xv3j0OGDAg6Ri7VVVVRWlpadIxpBZxvCrXOGaVaxyzyiWOV2WDadOmrY8x9ni753KuwA4YMICpU6cmHWO3Jk2axPjx45OOIbWI41W5xjGrXOOYVS5xvCobhBCW7Oo5TyGWJEmSJOUEC6wkSZIkKSdYYCVJkiRJOcECK0mSJEnKCRZYSZIkSVJOsMBKkiRJknKCBVaSJEmSlBMssJIkSZKknJCxAhtCuDWEsDaEMGcXz4cQwi9CCAtCCLNCCKMylUWSJEmSlPsyeQT2dmDCbp4/FRiS/rkUuDmDWSRJkiRJOS5jBTbG+CywcTe7nAHcGZv8B+gcQjggU3kkSZIkSbmtIMHP7g0sa7a+PL1tVTJxJEmSJOndiTGSipCKsekn1Ww5vvV5Im9ajzuWSa83X37jMTZ/TfpzY7P3iunPivCmz44RThjag/y8kPQ/qnckyQLbYiGES2k6zZjy8nImTZqUbKA9qKyszPqM0naOV+Uax6xyjWNWuWRX4zUVI40RGlM0PUZoTDVtS0VoSG9Pxbhjn1Rstm37emoX2yOkUm/dnnrT+zQVsMYIKd78/BsF8M2viel9407PxZ1e37zkvd0+sdl7bN/+xns336fpMdv95uT2FBdYYPfWCqBvs/U+6W1vEWO8BbgFYMyYMXH8+PEZD/duTJo0iWzPKG3neFWuccwq1zhmtTsNjSlqG1LUNaSoa2x6rG1IUd/45m07HpvtW99s/7r0axpS8Y3lxti0T+Mb682Xm56LNKS31TdGqqrzyCuop74xRWMqNu2XShETbGX5eYH8EMjLg/wQmtab/4RAXl6gIK/pced9CkIgLzS9T16z50II5Dfbvv25pveAvO37p98/L7Bjn/B2y+nPCTve643l7Z8fwhvvkxeAndab758X3njv7cuBplyBNz8fdrw2vU7TenjTe6e3AYf16ewR2HfgEeDqEMJEYCxQEWP09GFJkiTtdzFG6hsj1fWN1NY3Ul3fSE19iur6RqrrGqlpaKSm7s3ba9I/tQ0parc/NqSobWiktr7ZckMqvd60XNNs38bUvmuGBXmBwvw8CvO3P+ZRWBAozHtjuSAvj6L8PIoL8ygtLqAwP4+i9PbC/DzWrV1Nvz690uuB/PRjQV4eBflNJbEgPy/92PTe+duXm20vyGta3v5cfvP1HY955OeHt92el0fTY7p0SdtlrMCGEO4DxgPdQwjLgeuBQoAY46+Bx4HTgAXANuDCTGWRJElS69CYilTVNVBV20BVbVO5rKpr2PG4ra6RbbUNbKtvZFttY9P69u3px6q6RqrTyzU7Cuo7K5MhQHFBHiWF+RQX5FFckH4sfGO5Q3FB03Jh3tvuU1TQtL2ooKlcvukxvVyYftyxX0Feunym983PI28fHFGbNGkT48cf+q7fR8qUjBXYGOPH9/B8BK7K1OdLkiQpe9Q1pNhSU8+W6nq21jRQWZv+ab5c21RMK2sa2Lp9ead9ttU1tvgz8wK0LyqgfVF++qdpuVO7Qg7oWEL7onxKivJpV5hPSWFe+rHpp11hPu2Kmra/aVuz5e2F1COE0v6TE5M4SZIkKVmpVGRrTQNbauqpqG4qom8s77y94S371NSn9vgZBXmBspICSosL6FBcQFlJAV1Li+jXtT1lJU3btj9XWtxURku3F9TitxZVy6XU+lhgJUmS2piGxhSbq+vZvK2OjVX1bNpWt2N587Y6Nu20vGlb0/LuzrDNC1BWUkindoV0bFdAx5JCBvfo8Kb1junlsuJCOpS8UVK3l1ILp6Q9scBKkiTluBgjFdX1rK+sZd3WOtZX1r7xs329qqmkbqqqY0tNwy7fq6ggj67ti+jcvpAu7YsY3qvjjuXO7ZsKalMpLUyX0gI6tSuktKhgn1yDKUm7Y4GVJEnKUltr6lldUcO6rbWsq6xlfWVduqS+uaBuqKqlvvGth0fz8wJdS4vo3qGY7h2K6N+1PV3aF9KltGhHIe2603K7wnyPgkrKWhZYSZKk/awxFdlQWcvqLTWsrqh528c1FTVUvc2ERYX5gW6lxXQvayqmw3t13FFQe5QVp5eb1ru0L/KoqKRWxQIrSZK0D6VSkfWVtSzbVM3yTdv496I6Jm2Zy5otbxTTNVtr33LLloK8QHnHEso7FjO8VxknDu1Br44l9OpUQs+yEnqkC2undoUeIZXUZllgJUmS9kKMkfWVdSzftI3lm6pZln5cni6sKzZVU9vw5hl3OxQvp7xjMQd0ase4wd3p1ak4XU7b0atjCeWdiuleWuzRUknaAwusJEnSTiqq61m8vqpZOU2X1Y3bWLG5+i23hOlaWkSfLu0Y0asjp4wop0+XdvTp0p4+XdqxYPZUTj35pIT+JJLUulhgJUlSm1RT38iSDdtYtL6SheurWLSuikXrm342VNW9ad/O7Qvp26U9Q8vLeO/wnjvKad+u7enduR2lxbv+lWrFyx5VlaR9xQIrSZJarcZUZOXm6nRBTRfV9VUsXFfFyopqYrPLUHuWFTOweynvP6Scgd1LGdCtlH7dmgpqWUlhcn8ISdIOFlhJkpTz6htTLFxXxSurt/Dq6q0sWFvJovVVLNmwjbrGN073LSsuYFCPUo4a0IWB3fsysEcpg7qXMqB7KR12cxRVkpQd/KaWJEk5I8bIis3VvLp6K6+s3sqr6Z+F6yt33Ae1IC8woHtTMX3viJ4M6l7KwO4dGNi9lO4dipzBV5JymAVWkiRlpU1Vdbyyeivz12wvq1uYv6aSytqGHfv07tyOYb3KeO+IngzvVcbQ8jIG9+hAUUFegsklSZligZUkSYmKMbJ8UzUvLd/M7OUVzFvVdBrw2q21O/bp3L6QYeVlnDmqN8N6lTG8VxlDysvo6LWpktSmWGAlSdJ+tbqihlnLNzNreQWzVlQwe/lmNm2rB6AoP4+hvTrwniE9mo6opstqz7JiT/2VJFlgJUlS5myorE2X1IodpXX7kdX8vMDQ8jI+cEgvDu3TicP7dGZoeZmn/0qSdskCK0mS9oktNfXMWV7BS8srmL1iMy8tq2DF5moAQoBB3Us5/qDuHNqnE4f16cwhB3akpDA/4dSSpFxigZUkSe/I2i01vLh4I1MWbeSFRRt5dc3WHfdV7de1PUf068wFx/bn0N6dGdm7o/dSlSS9axZYSZK0RzFGlm7cxouLNvLioo1MWbyRxRu2AdC+KJ9R/bpw6sgDOLJfZw7t3YkupUUJJ5YktUYWWEmS9BapVOTVNVuZsnjjjtK6/drVzu0LOWpAVz45tj9HDezKIQd2pDDf61YlSZlngZUkSdQ1pJizsqLp6OqijUxdsomK6qaZgXt1LOGYQd04amBXxg7sykE9OpCX54zAkqT9zwIrSVIbFGPk9XVVPDt/Hc/MX8eLizZSXd8INE22dOrIXhw1oCtHD+xKny7tvIWNJCkrWGAlSWojttTUM3nBep6Zv55n56/bMUPwoO6lnDOmD8cM6saYAV3pUVaccFJJkt6eBVaSpFYqlYrMWVmx4yjr9KWbaUxFOhQXcOzgblwxfjAnDu1B367tk44qSVKLWGAlSWpF1m6t4bn563n2tXU899p6NlbVAXBo705cfuIgThjSg1H9uzjpkiQpJ1lgJUnKYfWNKaYu3sSzr63jmVfXMW/VFgC6dyjixKE9OHFoD44f0p3uHTwtWJKU+yywkiTlmJr6Rp6dv44n5qzmqZfXsKWmgYK8wOj+XbjmA8M4cWgPDj6gozMFS5JaHQusJEk5oLK2gadfWcsTc1bz9Ktr2VbXSKd2hZxycC/ef0g5xw7uRllJYdIxJUnKKAusJElZqmJbPX9/eQ1PzFnFs6+tp64hRfcORXz4yN6cOrIXxwzq5rWskqQ2xQIrSVIWWbe1lr/NW80Tc1bz/OsbaEhFDuxUwnlj+zNhZC9G9+9CvqcGS5LaKAusJEkJW7G5mifnNJXWKUs2EiMM7F7KJScMYsIhvTisTydCsLRKkmSBlSQpAWu21PDnGSt4fPYqXlpeAcDwXmV8/n1DOHXkAQwt72BplSRpJxZYSZL2k5r6Rp6cu5oHpq/gX6+tIxXh8D6duHbCcCaM7MXA7qVJR5QkKatZYCVJyqAYI1OXbOKBact5bNYqttY20LtzO6466SDOHNXH0ipJ0l6wwEqSlAHLNm7jwekreHDGcpZs2Eb7onxOHXkAZ43uzTEDu3mPVkmS3gELrCRJ+0hlbQOPz17FA9OW88KijYQA4wZ143PvHcKEkb0oLfavXUmS3g3/JpUk6V1oTEWef30DD0xfzhNzVlNd38jA7qV85f1D+cioPvTu3C7piJIktRoWWEmS3oHX11XywLTlPDRjBasqaigrKeAjo3pz1qg+jOrX2RmEJUnKAAusJEkt1NCY4h+vrOWOyYuZ/PoG8gKcMLQHXz9tBKccXE5JYX7SESVJatUssJIk7cHGqjr+MGUZd/9nCSs2V3NgpxKu+cAwPjq6Dz07liQdT5KkNsMCK0nSLsxZUcEdkxfzyEsrqW1IMW5QN771oRGcPKKcgvy8pONJktTmWGAlSWqmriHFE3NXc8fkxUxbsol2hfmcPboPnxo3gGG9ypKOJ0lSm2aBlSQJWLulhntfXMo9Lyxl3dZa+ndrz7c+dDBnj+5Dp3aFSceTJElYYCVJbViMkelLN3HH5CU8PnsVDanI+GE9uGDcAE4c2oO8PGcSliQpm1hgJUltTk19I4+8tJI7n1/MnBVbKCsu4FPjBnD+uP4M7F6adDxJkrQLFlhJUpuxqaqO2ycv5s7nF7NpWz1DenbgBx8eyUeO7E1psX8lSpKU7fzbWpLU6q3dWsPvnlvE3f9Zwra6Rk4eUc5njhvAuMHdCMHThCVJyhUWWElSq7V80zZueXYhE6cso6ExxYcOO5ArTxrM8F4dk44mSZLeAQusJKnVWbiukpsnvc5DM1YQApx5ZB+uGD+YAV7fKklSTrPASpJajZdXbeGmpxfw+OxVFObncd4x/bn0hEEc2Lld0tEkSdI+YIGVJOW8GUs3cdPTC3jq5bV0KC7g0hMGc9HxA+lRVpx0NEmStA9ZYCVJOSnGyPMLN3DT0wv494INdG5fyBdPHsqnjx1Ap/aFSceTJEkZYIGVJOWUGCP/fGUN//fPBUxfupkeZcV8/bThfGJsfzp4KxxJklo1/6aXJOWEGCNPzl3D/0yuYenWqfTu3I7vn3EIHx3Tl5LC/KTjSZKk/cACK0nKei8u2sj/++vLzFi6mV7tAz8++zA+fGRvCvPzko4mSZL2IwusJClrvbp6Kzc88Qr/eGUt5R2L+eGZh9Kj8nXeN6Zv0tEkSVICLLCSpKyzcnM1P/v7fB6YvpzS4gK+OmEYFx47kHZF+UyatDDpeJIkKSEWWElS1qjYVs+vJi3gtsmLIcJFxw/kyvEH0aW0KOlokiQpC2S0wIYQJgA3AvnA72KMP9zp+X7AHUDn9D7XxRgfz2QmSVL2qalv5I7Ji7np6QVsrW3gI0f25kunDKVPl/ZJR5MkSVkkYwU2hJAP3AScAiwHpoQQHokxzmu22zeBP8YYbw4hHAw8DgzIVCZJUnZpTEUemL6cn/19PqsqajhpWA++OmE4Iw7omHQ0SZKUhTJ5BPZoYEGMcSFACGEicAbQvMBGYPtvKZ2AlRnMI0nKEk33cl3Lj554hflrKjm8b2d+es4RjBvcLelokiQpi2WywPYGljVbXw6M3Wmf7wB/CyF8FigFTs5gHklSFpi2ZBM/+usrvLh4IwO7l/KrT47i1JG9CCEkHU2SJGW5EGPMzBuHcDYwIcZ4cXr9fGBsjPHqZvt8KZ3hJyGEccDvgZExxtRO73UpcClAeXn56IkTJ2Yk875SWVlJhw4dko4htYjjVfvLqsoUf3qtjmlrGulYFPjwQYWc0KeAgry9K66OWeUax6xyieNV2eCkk06aFmMc83bPZfII7Aqg+Y36+qS3NXcRMAEgxvh8CKEE6A6sbb5TjPEW4BaAMWPGxPHjx2co8r4xadIksj2jtJ3jVZlWWdvAL/7xGrdOXkRxQR5fOmUoFx0/kNLid/ZXkGNWucYxq1zieFW2y2SBnQIMCSEMpKm4ngt8Yqd9lgLvA24PIYwASoB1GcwkSdpPYoz8ZdYq/vuxeazZUsvHxvTlmgnD6N6hOOlokiQpR2WswMYYG0IIVwNP0nSLnFtjjHNDCN8DpsYYHwG+DPw2hPBFmiZ0+nTM1DnNkqT95rU1W/n2w3N5fuEGRvbuyM3njWZUvy5Jx5IkSTkuo/eBTd/T9fGdtn272fI84LhMZpAk7T87Thf+1yJKiwv4wYdH8vGj+5G/l9e5SpIkvZ2MFlhJUtsQY+TRWav4QbPThb86YRjdPF1YkiTtQxZYSdK78tqarVz/yFwmv+7pwpIkKbMssJKkd6SytoFf/uM1fv+vRbQvyuf7Hx7JJzxdWJIkZZAFVpK0V7afLvzfj73M6i01ni4sSZL2GwusJKnFFqxtml148usbOOTAjvzqvFGeLixJkvYbC6wkaY+q0rMLe7qwJElKkgVWkrRbT81bwzf/PMfThSVJUuIssJKkt7Wpqo7v/GUuD89cyfBeZdz0yVGM7u/pwpIkKTkWWEnSW/x19iq+9fAcNm+r5wsnD+HK8QdRVJCXdCxJktTGWWAlSTusr6zl+ofn8tjsVYzs3ZG7LhrLiAM6Jh1LkiQJsMBKknjj1jjXPzKXypoGrvnAMC49YRCF+R51lSRJ2cMCK0lt3NqtNXzrz3N4cu4aDu/TiR9/9HCGlpclHUuSJOktLLCS1EbFGHloxgq++5d5VNc38rVTh3PR8QMp8KirJEnKUhZYSWqDVlfU8I2HZvOPV9Yyun8Xbjj7MAb36JB0LEmSpN2ywEpSGxJj5P6py/n+Y/Oob0zxrQ8dzKePHUB+Xkg6miRJ0h5ZYCWpjVixuZqvPTibZ+ev4+iBXbnhrMMY0L006ViSJEktZoGVpFYuxsi9Ly7l/z3+CqkY+e7ph3D+Mf3J86irJEnKMRZYSWrFlm3cxrUPzGLy6xs4dnA3fnTWYfTt2j7pWJIkSe+IBVaSWqmHZ67gmw/NIQL/85FD+fjRfQnBo66SJCl3WWAlqZWprG3g2w/P4cHpKxjVrzM3nnukR10lSVKrYIGVpFZkxtJNfH7iTJZv2sbn3zeEz773IO/rKkmSWg0LrCS1Ao2pyM2TFvCzp16jV8cS/nDZOI4a0DXpWJIkSfuUBVaSctzKzdV84Q8zeXHRRv7r8AP5wYdH0qldYdKxJEmS9jkLrCTlsMdnr+K6B2bRmIr85KOHc+ao3k7UJEmSWi0LrCTloKraBr73l3n8YeoyDu/TiRvPPZIB3UuTjiVJkpRRFlhJyjGzl1fwuYkzWLyhiqtOGswXTh5KoRM1SZKkNsACK0k5IpWK3PLcQn7yt1fp3qGYey8+hnGDuyUdS5Ikab+xwEpSDlhdUcOX75/Jvxds4NSRvfh/Zx5K5/ZFSceSJEnar3ZbYEMIJcCHgPcABwLVwBzgsRjj3MzHkyT9be5qrn1gFjX1KX501qGcM6avEzVJkqQ2aZcFNoTwXZrK6yTgBWAtUAIMBX6YLrdfjjHO2g85JanNqa5r5AePzeOeF5YysndHbjz3SAb36JB0LEmSpMTs7gjsizHG63fx3E9DCD2BfhnIJElt3oK1lVx5zzTmr6nkshMH8eVThlFU4ERNkiSpbdtlgY0xPra7F8YY19J0VFaStA89Omsl1/5pFiWF+dx10dG8Z0iPpCNJkiRlhT1O4hRCGAN8A+if3j8AMcZ4WIazSVKbUteQ4n8ef5nbJy9mdP8u3PSJUfTqVJJ0LEmSpKzRklmI7wGuAWYDqczGkaS2aeXmaq66dzozlm7mouMHct2pw723qyRJ0k5aUmDXxRgfyXgSSWqjnp2/ji/8YSZ1DSl+9clRnHboAUlHkiRJykotKbDXhxB+B/wDqN2+Mcb4YMZSSVIbkEpFfvHP17jxH68xtGcZN583ikHOMixJkrRLLSmwFwLDgULeOIU4AhZYSXqHNlbV8YU/zOTZ+es488je/OAjI2lf1JKvZEmSpLarJb8tHRVjHJbxJJLURsxYuomr7pnO+so6/ucjh/Lxo/sSQkg6liRJUtZrSYGdHEI4OMY4L+NpJKkVizFy5/NL+MFj8yjvWMIDVxzLoX06JR1LkiQpZ7SkwB4DzAwhLKLpGlhvoyNJe6mqtoHrHpzNX15ayXuH9+Sn5xxO5/ZFSceSJEnKKS0psBMynkKSWrEFa7dy+d3TWbiukms+MIwrThxMXp6nDEuSJO2tPRbYGOMSgBBCT6Ak44kkqRV5eOYKvvbgbNoX5XP3RWM59qDuSUeSJEnKWXsssCGE04GfAAcCa4H+wMvAIZmNJkm5q7ahkf9+7GXufH4JRw3owi8/Popenfx/gJIkSe9GS04h/j5N18E+FWM8MoRwEnBeZmNJUu5aXVHD5XdPY+ayzVzynoF8dcJwCvPzko4lSZKU81pSYOtjjBtCCHkhhLwY49MhhJ9nOpgk5aJpSzZx+d3T2FbbwK/PG8WEkQckHUmSJKnVaEmB3RxC6AA8C9wTQlgLVGU2liTlnj9OWcY3/zyHAzqXcM/FYxlaXpZ0JEmSpFalJQX2DKAG+CLwSaAT8L1MhpKkXFLfmOIHj87jjueX8J4h3fnlx4/0FjmSJEkZ0JIC2z/GOC+9fAdACGE8MCkzkSQpd2ysquPKe6bxn4UbueQ9A7l2wnAKvN5VkiQpI1pSYP8YQrgLuIGm2+jcAIwBxmUymCRlu3krt3DpXVNZu7WWn55zOGeO6pN0JEmSpFatJYcJxgJ9gcnAFGAlcFwmQ0lStnts1irOunkyDY2R+y8bZ3mVJEnaD1o0CzFQDbSj6QjsohhjKqOpJClLpVKRnz01n1/+cwGj+nXm1+ePpmeZ93eVJEnaH1pyBHYKTQX2KOA9wMdDCPdnNJUkZaGtNfVcetdUfvnPBXxsTF/uu/QYy6skSdJ+1JIjsBfFGKeml1cBZ4QQzs9gJknKOovWV3HJnVNZtL6K755+CJ8a158QQtKxJEmS2pSWFNhpIYTzgEExxu+FEPoBr2Y4lyRljWfmr+Oz904nPy9w90VjGTe4W9KRJEmS2qSWnEL8K5pmHP54en0rcFPGEklSlogx8ptnXufC217kwM7teOTq4y2vkiRJCWrJEdixMcZRIYQZADHGTSGEogznkqRE1dQ3cu0Ds3h45ko+eOgB/Pijh9G+qCVfmZIkScqUFs1CHELIByJACKEH4CzEklqtlZurueyuacxZWcE1HxjGleMHe72rJElSFmhJgf0F8BDQM4Tw38DZwDczmkqSEjJtySYuu2sqNfUpfnv+GE4+uDzpSJIkSUrbY4GNMd4TQpgGvA8IwIdjjC+35M1DCBOAG4F84Hcxxh++zT7nAN+h6QjvSzHGT7Q8viTtOw/PXME1f5rFAZ1KmHjpGA7qWZZ0JEmSJDXTogu6YoyvAK/szRunTzu+CTgFWA5MCSE8EmOc12yfIcDXgOPS19b23JvPkKR9IcbIz556jV/84zWOHtiV35w3mi6lXuovSZKUbTI5I8nRwIIY40KAEMJE4AxgXrN9LgFuijFuAogxrs1gHkl6i5r6Rr5y/0s8OmsVZ4/uw/985FCKCloyQbskSZL2t0wW2N7Asmbry4GxO+0zFCCE8G+aTjP+TozxiQxmkqQd1m6t4dI7pzFz2WaunTCcy08c5GRNkiRJWaxFBTaE0B8YEmN8KoTQDiiIMW7dR58/BBgP9AGeDSEcGmPcvNPnXwpcClBeXs6kSZP2wUdnTmVlZdZnlLZrq+N12dYUP59Ww9a6yNVHFDOCZTzzzLI9v1CJa6tjVrnLMatc4nhVtttjgQ0hXEJTeewKDKapaP6apkmddmcF0LfZep/0tuaWAy/EGOuBRSGE+TQV2inNd4ox3gLcAjBmzJg4fvz4PcVO1KRJk8j2jNJ2bXG8Pv3KWn74z+l0KCnigYuP4tA+nZKOpL3QFsescptjVrnE8aps15ILva4CjgO2AMQYXwNaMtnSFGBICGFgCKEIOBd4ZKd9/kzT0VdCCN1pOqV4YUuCS9LeijFy278XcdEdUxjQvZSHrzre8ipJkpRDWnIKcW2MsW77dWEhhAKabnmzWzHGhhDC1cCTNF3femuMcW4I4XvA1BjjI+nn3h9CmAc0AtfEGDe8wz+LJO1SfWOK7/5lLnf/ZynvP7icn597BO2LMjkNgCRJkva1lvz29kwI4etAuxDCKcCVwF9a8uYxxseBx3fa9u1myxH4UvpHkjKiorqeq++dznOvreeyEwdx7QeGk5fnZE2SJEm5piUF9jrgImA2cBlNhfR3mQwlSfvK0g3b+MwdU1i8voobzjqMc47qu+cXSZIkKSvtscDGGFPAb9M/kpQzpizeyKV3TiUV4a6LxjJucLekI0mSJOldaMksxMcB3wH6p/cPNJ39Oyiz0STpnXtg2nK+9uBsendpx62fPoqB3UuTjiRJkqR3qSWnEP8e+CIwjaaJliQpa6VSkZ/+fT7/9/QCxg3qxs3njaJz+6KkY0mSJGkfaEmBrYgx/jXjSSTpXaqua+TL98/k8dmr+diYvnz/wyMpKmjJ3cIkSZKUC3ZZYEMIo9KLT4cQfgw8CNRufz7GOD3D2SSpxdZtreXiO6cya/lmvnHaCC5+z0C23/5LkiRJrcPujsD+ZKf1Mc2WI/DefR9HkvbegrVb+fRtU1hfWcuvzxvNBw7plXQkSZIkZcAuC2yM8SSAEMKgGOPC5s+FEJzASVJWeP71DVx211SKCvL4w6XjOLxv56QjSZIkKUNacnHYn95m2/37Oogk7a0Hpy/nU7e+QM+OJTx05XGWV0mSpFZud9fADgcOATqFEM5s9lRHoCTTwSRpV2KM3PiP1/j5U68xblA3fn3+aDq1K0w6liRJkjJsd9fADgM+BHQG/qvZ9q3AJRnMJEm7VNeQ4roHZ/Hg9BWcOao3PzzzMGcaliRJaiN2dw3sw8DDIYRxMcbn92MmSXpbFdX1XH7XNJ5fuIEvnjyUz73vIGcaliRJakP2eB9Yy6ukbLBs4zYuvH0KSzZU8dNzDufMUX2SjiRJkqT9bI8FVpKS9tKyzVx0xxTqGlLc+ZmxjBvcLelIkiRJSoAFVlJW+9vc1Xxu4gy6dyhm4qXHcFDPsqQjSZIkKSF7LLAhhC+9zeYKYFqMceY+TyRJabf+axHff2weh/XpzO8+NYYeZcVJR5IkSVKCWnIEdkz65y/p9Q8Bs4DLQwj3xxhvyFQ4SW1TYyry/UfncfvkxXzgkHJ+/rEjaVeUn3QsSZIkJawlBbYPMCrGWAkQQrgeeAw4AZgGWGAl7TPb6hr43H0zeOrltVx8/EC+dtoI8vOcaViSJEktK7A9gdpm6/VAeYyxOoRQu4vXSNJeW7u1hotun8rclRV874xD+NS4AUlHkiRJUhZpSYG9B3ghhPBwev2/gHtDCKXAvIwlk9SmzF+zlQtvm8LGqjp++6kxvG9EedKRJEmSlGVach/Y74cQngCOTW+6PMY4Nb38yYwlk9RmTF6wnsvumka7onzuv3wcI3t3SjqSJEmSslBLb6MzHVixff8QQr8Y49KMpZLUZjw4fTnXPjCLgd1Lue3Co+nduV3SkSRJkpSlWnIbnc8C1wNrgEYgABE4LLPRJLVmMUZ++c8F/PTv8zl2cDduPm80ndoVJh1LkiRJWawlR2A/DwyLMW7IdBhJbUN9Y4qvPzib+6ct58xRvfnhmYdRVJCXdCxJkiRluZYU2GVARaaDSGobttbUc+U903nutfV87n1D+OLJQwjB2+RIkiRpz1pSYBcCk0IIj9Hsdjoxxp9mLJWkVmlVRTUX3jaFBWsrueGswzjnqL5JR5IkSVIOaUmBXZr+KUr/SNJee3nVFi68bQqVtQ3cduFRvGdIj6QjSZIkKce05DY6390fQSS1Xs/OX8eV90ynQ3EB918+jhEHdEw6kiRJknLQLgtsCOHnMcYvhBD+QtOsw28SYzw9o8kktQp/nLqMrz84m4N6duC2C4/igE7eJkeSJEnvzO6OwN6Vfvzf/RFEUusSY+Rnf5/PL/65gPcM6c6vPjmKshJvkyNJkqR3bpcFNsY4Lf34zPZtIYQuQN8Y46z9kE1SjqprSHHdA7N4cMYKzhnTh//+yKEU5nubHEmSJL07e7wGNoQwCTg9ve80YG0I4d8xxi9lOJukHFRRXc8Vd09j8usb+PIpQ7n6vQd5mxxJkiTtEy2ZhbhTjHFLCOFi4M4Y4/UhBI/ASnqLFZurufC2F1m0voqfnnM4Z47qk3QkSZIktSItKbAFIYQDgHOAb2Q4j6QcNWdFBZ+5fQrV9Y3cceHRHHtQ96QjSZIkqZVpyUVp3wOeBBbEGKeEEAYBr2U2lqRc8vSraznnN89TmJ/HA1cca3mVJElSRrTkPrD3A/c3W18InJXJUJJyxz0vLOHbD89leK8ybvv0UfTsWJJ0JEmSJLVSezwCG0K4IYTQMYRQGEL4RwhhXQjhvP0RTlL2SqUi/++vL/ONh+ZwwpDu/OGycZZXSZIkZVRLTiF+f4xxC/AhYDFwEHBNJkNJym419Y189r4Z/OaZhZx3TD9++6kxdChuySX1kiRJ0jvXokmc0o8fBO6PMVZ4Swyp7dpQWcsld05lxrLNfOO0EVz8noHeJkeSJEn7RUsK7KMhhFeAauCKEEIPoCazsSRlo4XrKrnw9imsrqjhV58YxamHHpB0JEmSJLUhLZnE6boQwg1ARYyxMYRQBZyR+WiSssmUxRu55M6p5IfAfZcew6h+XZKOJEmSpDampRetHQicHEJoPkPLnRnIIykLPTxzBdfcP4s+Xdtx+6ePpl+39klHkiRJUhu0xwIbQrgeGA8cDDwOnAr8Cwus1OrFGPnVpNf58ZOvcvTArtxy/mg6ty9KOpYkSZLaqJYcgT0bOByYEWO8MIRQDtyd2ViSklbfmOKbD83hD1OXccYRB3LD2YdRXJCfdCxJkiS1YS0psNUxxlQIoSGE0BFYC/TNcC5JCdpSU89V90znudfW87n3HsQXTxnqTMOSJElKXEsK7NQQQmfgt8A0oBJ4PpOhJCVn5eZqPnP7FBasreSGsw/jnDH+/ypJkiRlh5bMQnxlevHXIYQngI4xxlmZjSUpCXNWVPCZ26dQXdfI7RcezfFDuicdSZIkSdqhRbMQhxDOBI4HIk0TOFlgpVbmn6+s4ep7Z9ClfRF3XTGWYb3Kko4kSZIkvUlLZiH+FXAQcF9602UhhJNjjFdlNJmk/eau5xdz/SNzOfjAjtx6wVH07Fiy5xdJkiRJ+1lLjsC+FxgRY4wAIYQ7gLkZTSVpv0ilIhNfqeWJxXM5eURPbjz3SEqLW3p7aEmSJGn/ymvBPguAfs3W+6a3Scph2+oauOKeaTyxuIELxvXnN+ePsbxKkiQpq7Xkt9Uy4OUQwos0XQN7NE0zEz8CEGM8PYP5JGXA6ooaLrpjCi+v2sInhhfxndMP8TY5kiRJynotKbDfzngKSfvN7OUVXHznFCprGvjdBWPIW/2y5VWSJEk5YZcFNoQQYpNndrdPZmJJyoQn5qzmi3+YSdfSIh648liG9+rIpNUvJx1LkiRJapHdXQP7dAjhsyGE5te/EkIoCiG8Nz2Z0wWZjSdpX4gxcvOk17n87mkM61XGn686juG9OiYdS5IkSdoruzuFeALwGeC+EMIgYBPQjqbS+zfg5zHGGZmPKOndqGtI8Y2HZnP/tOX81+EH8uOzD6OkMD/pWJIkSdJe22WBjTHWAL8CfhVCKAS6A9Uxxs37KZukd2lTVR2X3T2NFxdt5PPvG8IXTh7i9a6SJEnKWbu7BrYEuBw4CJgF3BpjbNhfwSS9O6+vq+Qzt09hVUUNN557BGcc0TvpSJIkSdK7srtrYO8AxgCzgdOAn+ztm4cQJoQQXg0hLAghXLeb/c4KIcQQwpi9/QxJb/XvBev5yE3/prKmgfsuGWt5lSRJUquwu2tgD44xHgoQQvg98OLevHEIIR+4CTgFWA5MCSE8EmOct9N+ZcDngRf25v0lvb37XlzKt/48h0E9Svn9BUfRt2v7pCNJkiRJ+8TujsDWb194h6cOHw0siDEujDHWAROBM95mv+8DPwJq3sFnSEprTEV+8Og8vvbgbI47qDsPXHGs5VWSJEmtyu6OwB4eQtiSXg5Au/R6AGKMcU/34OgNLGu2vhwY23yHEMIooG+M8bEQwjV7F13SdlW1DXx+4gyeenktnz52AN/84AgK8nf3/6ckSZKk3LO7WYgzep+NEEIe8FPg0y3Y91LgUoDy8nImTZqUyWjvWmVlZdZnVOuxoTrFz6fXsqIyxXkjihjfcR3/em5di1/veFWuccwq1zhmlUscr8p2uzsC+26tAPo2W++T3rZdGTASmJS+rUcv4JEQwukxxqnN3yjGeAtwC8CYMWPi+PHjMxj73Zs0aRLZnlGtw8xlm/nKHVOprc/jtgvHcOLQHnv9Ho5X5RrHrHKNY1a5xPGqbJfJAjsFGBJCGEhTcT0X+MT2J2OMFTTdWxaAEMIk4Cs7l1dJb+/RWSv58h9fokdZMfdeMpah5WVJR5IkSZIyKmMFNsbYEEK4GngSyKfpPrJzQwjfA6bGGB/J1GdLrVkqFfnJ31/lpqdfZ3T/Ltxy/mi6dShOOpYkSZKUcZk8AkuM8XHg8Z22fXsX+47PZBapNdhSU88XJ87kH6+s5dyj+vLdMw6huCCjl6tLkiRJWSOjBVbSvrNwXSWX3DmVJRu28f0zDuG8Y/qTvn5ckiRJahMssFIOmPTqWj573wwK8/O466KxjBvcLelIkiRJ0n5ngZWyWIyR3zy7kB898QrDe3XklvNH07dr+6RjSZIkSYmwwEpZqqa+kWsfmMXDM1fywUMP4McfPYz2Rf4nK0mSpLbL34alLLRyczWX3jWVuSu3cM0HhnHl+MFe7ypJkqQ2zwIrZZkpizdyxd3TqKlP8btPjeF9I8qTjiRJkiRlBQuslEXufWEp1z8yhz5d2jPx0tEc1LMs6UiSJElS1rDASlmgriHF9x6dy93/WcoJQ3vwy3OPpFP7wqRjSZIkSVnFAislbH1lLVfeM50XF23kshMG8dUJw8nP83pXSZIkaWcWWClBc1ZUcNld01hfWcvPP3YEHz6yd9KRJEmSpKxlgZUS8peXVnLNn16iS/si/nT5sRzap1PSkSRJkqSsZoGV9rPGVOR///YqN096nTH9u3DzeaPpUVacdCxJkiQp61lgpf1o3dZaPj9xBpNf38DHj+7Ld08fSVFBXtKxJEmSpJxggZX2kymLN3L1vdPZvK2eG84+jHPG9E06kiRJkpRTLLBShsUY+f2/FvH//voKfbu047Yrj+bgAzsmHUuSJEnKORZYKYO21NTz1ftn8cTc1XzgkHJ+/NHD6Vji/V0lSZKkd8ICK2XIy6u2cMXd01i2qZpvnDaCi98zkBC8v6skSZL0TllgpQz407TlfPPPs+lYUsh9lxzD0QO7Jh1JkiRJynkWWGkfqqlv5DuPzGXilGWMG9SNGz9+BD3LSpKOJUmSJLUKFlhpH1m6YRtX3DONuSu3cOX4wXzplKEU5HuLHEmSJGlfscBK+8BT89bwpT/OBOD3F4zhfSPKkw0kSZIktUIWWOldaGhM8b9/m8+vn3mdkb07cvMnR9O3a/ukY0mSJEmtkgVWeofWbq3hs/fO4IVFG/nE2H58+0MHU1KYn3QsSZIkqdWywErvwAsLN3D1fTPYWlPPT885nDNH9Uk6kiRJktTqWWClvRBj5JZnF3LDk6/Sr2t77rroaIb36ph0LEmSJKlNsMBKLbRuay1fuf8lnpm/jtMO7cWPzjqMspLCpGNJkiRJbYYFVmqBp19ZyzV/eomtNQ18/4xDOO+Y/oQQko4lSZIktSkWWGk3auob+eFfX+H2yYsZ3quMey85hqHlZUnHkiRJktokC6y0C/PXbOVz983gldVbufC4AVw7YbizDEuSJEkJssBKO4kxcvd/lvCDx16mrKSA2y48ipOG9Uw6liRJktTmWWClZjZU1nLtA7N46uW1jB/Wgx+ffTg9yoqTjiVJkiQJC6y0w3OvreNLf3yJim31XP9fB/PpYwc4UZMkSZKURSywavNqGxr53ydf5bfPLWJIzw7c+ZmjGXGA93aVJEmSso0FVm3agrWVfH7iDOau3ML5x/TnGx8c4URNkiRJUpaywKpNijEyccoyvvuXubQrzOe3nxrDKQeXJx1LkiRJ0m5YYNXmbKqq47oHZ/Hk3DUcf1B3fnLO4ZR3LEk6liRJkqQ9sMCqTZn8+nq+9IeX2FBVyzdOG8FFxw8kL8+JmiRJkqRcYIFVm1BT38hP/vYqv/vXIgZ2L+V3FxzHyN6dko4lSZIkaS9YYNXqTVm8ka/+aRaL1lfxybH9+MYHR9C+yKEvSZIk5Rp/i1erta2ugRueeJU7nl9M787tuPfisRx7UPekY0mSJEl6hyywapWef30D1z4wi6Ubt3HBuP58dcJwSosd7pIkSVIu8zd6tSqVtQ388K8vc/d/ltK/W3v+cOkxjB3ULelYkiRJkvYBC6xajedeW8d1D8xmZUU1Fx0/kK+8fxjtivKTjiVJkiRpH7HAKudtqannfx57mYlTljGoRyl/unwco/t3TTqWJEmSpH3MAquc9vSra/n6g7NZs6WGy04cxBdPHkpJoUddJUmSpNbIAqucVLGtnu89Oo8Hpi9nSM8O3HzlcRzRt3PSsSRJkiRlkAVWOefv89bwjYdms6GqjqtPOojPvu8gigs86ipJkiS1dhZY5YxNVXV85y9zeXjmSob3KuPWTx/FyN6dko4lSZIkaT+xwCrrxRh5fPZqrn9kDpu31fOFk4dw5fiDKCrISzqaJEmSpP3IAqustmBtJd95ZC7/WrCekb07ctdFYxlxQMekY0mSJElKgAVWWWlbXQO//OcCfvfcQkoK8/nu6YfwybH9KMj3qKskSZLUVllglVVijPx1zmq+/+g8VlXUcPboPlw7YTg9yoqTjiZJkiQpYRZYZY3X1zWdLvzca+sZcUBHfvnxIxkzoGvSsSRJkiRlCQusEufpwpIkSZJawgKrxMQYeSJ9uvDKihrOGtWH6071dGFJkiRJb88Cq0TsfLrwLzxdWJIkSdIeWGC1X22ra+D//rmA36ZPF/7Ofx3Mecf093RhSZIkSXtkgdV+4enCkiRJkt6tjBbYEMIE4EYgH/hdjPGHOz3/JeBioAFYB3wmxrgkk5m0/y1cV8n1ni4sSZIk6V3KWIENIeQDNwGnAMuBKSGER2KM85rtNgMYE2PcFkK4ArgB+FimMmn/Wl9Zyy//8Rr3vLCUdp4uLEmSJOldyuQR2KOBBTHGhQAhhInAGcCOAhtjfLrZ/v8BzstgHu0nlbUN/O65hfz22YXUNKQ496i+fOHkoZ4uLEmSJOldCTHGzLxxCGcDE2KMF6fXzwfGxhiv3sX+/wesjjH+4G2euxS4FKC8vHz0xIkTM5J5X6msrKRDhw5Jx9jvGlKRZ5Y38PCCOrbUwZjyfM4eWkSvUo+4ZrO2Ol6VuxyzyjWOWeUSx6uywUknnTQtxjjm7Z7LikmcQgjnAWOAE9/u+RjjLcAtAGPGjInjx4/ff+HegUmTJpHtGfelGCOPzV7F/z75Kos31HH0wK587dThHNmvS9LR1AJtbbwq9zlmlWscs8oljldlu0wW2BVA32brfdLb3iSEcDLwDeDEGGNtBvMoAyYvWM8Pn3iFWcsrGFZexm2fPorxw3oQQkg6miRJkqRWJpMFdgowJIQwkKbiei7wieY7hBCOBH5D06nGazOYRfvYvJVb+OETr/Ds/HX07tyOn3z0cD58ZG/y8yyukiRJkjIjYwU2xtgQQrgaeJKm2+jcGmOcG0L4HjA1xvgI8GOgA3B/+ojd0hjj6ZnKpHdv2cZt/PTv8/nzzBV0LCnkG6eN4Pxx/SkpzE86miRJkqRWLqPXwMYYHwce32nbt5stn5zJz9e+s7Gqjv/75wLu/s8SQoDLTxzM5ScOplO7wqSjSZIkSWojsmISJ2WvbXUN3Pbvxfx60utU1TXw0dF9+cIpQzigU7uko0mSJElqYyywelvVdY3c++JSfvPM66zdWsspB5fz1Q8MY0h5WdLRJEmSJLVRFli9yZaaeu56fgm//9ciNlbVMXZgV371yVGMGdA16WiSJEmS2jgLrICma1xv/dci7nh+MVtrGhg/rAdXn3SQxVWSJElS1rDAtnFrttTw22cXcs8LS6lpaGTCIb246qSDGNm7U9LRJEmSJOlNLLBt1LKN2/j1M69z/9TlNMbI6YcfyJXjB3uNqyRJkqSsZYFtYxasreRXkxbw8MyV5IfAWaP7cMWJg+nXrX3S0SRJkiRptyywbcScFRX8atIC/jpnNcUFeVwwbgCXnjCIXp1Kko4mSZIkSS1igW3lpi3ZyP/9cwFPv7qOsuICrhw/mM8cN5BuHYqTjiZJkiRJe8UC2wqlUpFnXlvHLc8s5PmFG+jSvpCvvH8o548bQKd2hUnHkyRJkqR3xALbimypqef+qcu56/nFLN6wjfKOxXzzgyP4xNh+tC/yX7UkSZKk3GaraQXmr9nKHZMX89CMFWyra2R0/y588ZShnDryAIoK8pKOJ0mSJEn7hAU2RzU0pnjq5bXc+fxiJr++gaKCPE4//EA+fewA7+EqSZIkqVWywOaYjVV1TJyylHv+s5QVm6s5sFMJX50wjHOP6kfX0qKk40mSJElSxlhgc8ScFRXcMXkxD7+0krqGFOMGdeNbHzqYk0f0pCDf04QlSZIktX4W2CxW15Dir3NWcefzS5i2ZBPtCvP56Og+XHDsAIaWlyUdT5IkSZL2KwtsFlq7pYZ7X1zKPS8sZd3WWgZ0a8+3PnQwZ4/u421wJEmSJLVZFtgsUVPfyN/nreGB6ct5dv46UhHGD+vBBccO4MQhPcjLC0lHlCRJkqREWWATFGNk+tJN/GnaCh6dtZKtNQ0c0KmEy08czEfH9GVg99KkI0qSJElS1rDAJmD5pm08NH0FD85YwaL1VbQrzOfUkb04c1Qfxg3uRr5HWyVJkiTpLSyw+0lVbQN/nbOaB6Yt5/mFGwAYO7ArV4wfzGmHHkCHYv9VSJIkSdLu2JoyKJWK/GfhBv40fTlPzFnNtrpG+ndrzxdPHsqZo3rTt2v7pCNKkiRJUs6wwGbA6qoU//vkqzw0YwUrNldTVlzA6YcfyFmj+zCmfxdC8BRhSZIkSdpbFth9aNnGbXx+4gymL60mLyzg+CE9+OqEYXzgkF6UFOYnHU+SJEmScpoFdh/q2bGY/LzAOUML+fLZJ1DesSTpSJIkSZLUauQlHaA1KS7I5/7Lj+W0QUWWV0mSJEnaxyywkiRJkqScYIGVJEmSJOUEC6wkSZIkKSdYYCVJkiRJOcECK0mSJEnKCRZYSZIkSVJOsMBKkiRJknKCBVaSJEmSlBMssJIkSZKknGCBlSRJkiTlBAusJEmSJCknWGAlSZIkSTnBAitJkiRJygkhxph0hr0SQlgHLEk6xx50B9YnHUJqIcerco1jVrnGMatc4nhVNugfY+zxdk/kXIHNBSGEqTHGMUnnkFrC8apc45hVrnHMKpc4XpXtPIVYkiRJkpQTLLCSJEmSpJxggc2MW5IOIO0Fx6tyjWNWucYxq1zieFVW8xpYSZIkSVJO8AisJEmSJCknWGD3oRDChBDCqyGEBSGE65LOI+1JCGFxCGF2CGFmCGFq0nmknYUQbg0hrA0hzGm2rWsI4e8hhNfSj12SzChtt4vx+p0Qwor09+zMEMJpSWaUmgsh9A0hPB1CmBdCmBtC+Hx6u9+zyloW2H0khJAP3AScChwMfDyEcHCyqaQWOSnGeIRT5itL3Q5M2GnbdcA/YoxDgH+k16VscDtvHa8AP0t/zx4RY3x8P2eSdqcB+HKM8WDgGOCq9O+vfs8qa1lg952jgQUxxoUxxjpgInBGwpkkKafFGJ8FNu60+QzgjvTyHcCH92cmaVd2MV6lrBVjXBVjnJ5e3gq8DPTG71llMQvsvtMbWNZsfXl6m5TNIvC3EMK0EMKlSYeRWqg8xrgqvbwaKE8yjNQCV4cQZqVPMfZUTGWlEMIA4EjgBfyeVRazwEpt2/ExxlE0nfp+VQjhhKQDSXsjNk2l73T6ymY3A4OBI4BVwE8STSO9jRBCB+AB4Asxxi3Nn/N7VtnGArvvrAD6Nlvvk94mZa0Y44r041rgIZpOhZey3ZoQwgEA6ce1CeeRdinGuCbG2BhjTAG/xe9ZZZkQQiFN5fWeGOOD6c1+zyprWWD3nSnAkBDCwBBCEXAu8EjCmaRdCiGUhhDKti8D7wfm7P5VUlZ4BLggvXwB8HCCWaTd2l4C0j6C37PKIiGEAPweeDnG+NNmT/k9q6wVms4K0L6Qnhr/50A+cGuM8b+TTSTtWghhEE1HXQEKgHsds8o2IYT7gPFAd2ANcD3wZ+CPQD9gCXBOjNGJc5S4XYzX8TSdPhyBxcBlza4tlBIVQjgeeA6YDaTSm79O03Wwfs8qK1lgJUmSJEk5wVOIJUmSJEk5wQIrSZIkScoJFlhJkiRJUk6wwEqSJEmScoIFVpIkSZKUEyywkiS9SyGEL4QQ2r+D11Xuxb7jQwiP7u1nSJLUmlhgJUl6974A7HWBzQYhhIKkM0iS1FIWWEmSWiiEUBpCeCyE8FIIYU4I4WMhhM8BBwJPhxCeTu9X2ew1Z4cQbk8vDwwhPB9CmB1C+EGzfe4MIXy42fo9IYQz3iZChxDCn0IIr6T3Cen93xdCmJF+31tDCMXp7YtDCN3Ty2NCCJPSy98JIdwVQvg3cFcI4ZAQwoshhJkhhFkhhCH79B+cJEn7iAVWkqSWmwCsjDEeHmMcCTwRY/wFsBI4KcZ40h5efyNwc4zxUGBVs+2/Bz4NEELoBBwLPPY2rz+SpqO9BwODgONCCCXA7cDH0u9bAFzRgj/LwcDJMcaPA5cDN8YYjwDGAMtb8HpJkvY7C6wkSS03GzglhPCjEMJ7YowVe/n644D70st3bd8YY3wGGBJC6AF8HHggxtjwNq9/Mca4PMaYAmYCA4BhwKIY4/z0PncAJ7QgyyMxxur08vPA10MI1wL9m22XJCmrWGAlSWqhdEkcRVOR/UEI4du72rXZcslunmvuTuA84ELg1l3sU9tsuZGmo62708Abf9fvnKNqR6AY7wVOB6qBx0MI793D+0qSlAgLrCRJLRRCOBDYFmO8G/gxTWUWYCtQ1mzXNSGEESGEPOAjzbb/Gzg3vfzJnd7+dppODybGOG8vYr0KDAghHJRePx94Jr28GBidXj5rV28QQhgELEyfDv0wcNhefL4kSfuNBVaSpJY7FHgxhDATuB7YPhHTLcAT2ydxAq4DHgUm8+ZrXT8PXBVCmA30bv7GMcY1wMvAbXsTKMZYQ9NR2/vT75sCfp1++rvAjSGEqTQdsd2Vc4A56T/XSJqOBkuSlHVCjLs6k0mSJO0v6fvIzgZGvYNrayVJahM8AitJUsJCCCfTdPT1l5ZXSZJ2zSOwkiRJkqSc4BFYSZIkSVJOsMBKkiRJknKCBVaSJEmSlBMssJIkSZKknGCBlSRJkiTlBAusJEmSJCkn/H+qIHF9px+6CQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the probability of passing the exam (according to the model)\n",
    "# as a function of the study hours!\n",
    "import matplotlib.pyplot as plt\n",
    "x2 = np.arange(0, 24, 0.5)\n",
    "yhat2 = sigmoid((x2 - xm) * w)\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(x2, yhat2)\n",
    "plt.grid(True)\n",
    "plt.xlabel('study hours')\n",
    "plt.ylabel('P(passing the exam)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Wisconsin Breast Cancer Problem\n",
    "\n",
    "<img src=\"../_img/wisconsin_illustration.jpg\" width=\"200\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Wisconsin Breast Cancer data set contains the attributes of 699 suspicious lesions in tissue microscopy images. The raw data is contained in [wisconsin_data.txt](../_data/wisconsin_data.txt), the description can be read in [wisconsin_names.txt](../_data/wisconsin_names.txt). The task is to estimate if the lesion is malicious (4) or benign (2), based on the image attributes of the lesion. Therefore the task is a binary classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**: Train a univariate logistic regression model for each input feature separately, and measure the *average* cross-entropy of the models! Use the full data set both for training and evaluation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names.\n",
    "names = [\n",
    "    'Sample_code_number',\n",
    "    'Clump_Thickness',\n",
    "    'Uniformity_of_Cell_Size',\n",
    "    'Uniformity_of_Cell_Shape',\n",
    "    'Marginal_Adhesion',\n",
    "    'Single_Epithelial_Cell_Size',\n",
    "    'Bare_Nuclei',\n",
    "    'Bland_Chromatin',\n",
    "    'Normal_Nucleoli',\n",
    "    'Mitoses',\n",
    "    'Class'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_code_number</th>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <th>Uniformity_of_Cell_Size</th>\n",
       "      <th>Uniformity_of_Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>776715</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>841769</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>888820</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sample_code_number  Clump_Thickness  Uniformity_of_Cell_Size  \\\n",
       "0               1000025                5                        1   \n",
       "1               1002945                5                        4   \n",
       "2               1015425                3                        1   \n",
       "3               1016277                6                        8   \n",
       "4               1017023                4                        1   \n",
       "..                  ...              ...                      ...   \n",
       "694              776715                3                        1   \n",
       "695              841769                2                        1   \n",
       "696              888820                5                       10   \n",
       "697              897471                4                        8   \n",
       "698              897471                4                        8   \n",
       "\n",
       "     Uniformity_of_Cell_Shape  Marginal_Adhesion  Single_Epithelial_Cell_Size  \\\n",
       "0                           1                  1                            2   \n",
       "1                           4                  5                            7   \n",
       "2                           1                  1                            2   \n",
       "3                           8                  1                            3   \n",
       "4                           1                  3                            2   \n",
       "..                        ...                ...                          ...   \n",
       "694                         1                  1                            3   \n",
       "695                         1                  1                            2   \n",
       "696                        10                  3                            7   \n",
       "697                         6                  4                            3   \n",
       "698                         8                  5                            4   \n",
       "\n",
       "     Bare_Nuclei  Bland_Chromatin  Normal_Nucleoli  Mitoses  Class  \n",
       "0            1.0                3                1        1      2  \n",
       "1           10.0                3                2        1      2  \n",
       "2            2.0                3                1        1      2  \n",
       "3            4.0                3                7        1      2  \n",
       "4            1.0                3                1        1      2  \n",
       "..           ...              ...              ...      ...    ...  \n",
       "694          2.0                1                1        1      2  \n",
       "695          1.0                1                1        1      2  \n",
       "696          3.0                8               10        2      4  \n",
       "697          4.0               10                6        1      4  \n",
       "698          5.0               10                4        1      4  \n",
       "\n",
       "[699 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('wisconsin_data.txt', sep=',', names=names, na_values='?')\n",
    "# we found some ? values, so we replaced it with nan\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 11 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Sample_code_number           699 non-null    int64  \n",
      " 1   Clump_Thickness              699 non-null    int64  \n",
      " 2   Uniformity_of_Cell_Size      699 non-null    int64  \n",
      " 3   Uniformity_of_Cell_Shape     699 non-null    int64  \n",
      " 4   Marginal_Adhesion            699 non-null    int64  \n",
      " 5   Single_Epithelial_Cell_Size  699 non-null    int64  \n",
      " 6   Bare_Nuclei                  683 non-null    float64\n",
      " 7   Bland_Chromatin              699 non-null    int64  \n",
      " 8   Normal_Nucleoli              699 non-null    int64  \n",
      " 9   Mitoses                      699 non-null    int64  \n",
      " 10  Class                        699 non-null    int64  \n",
      "dtypes: float64(1), int64(10)\n",
      "memory usage: 60.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., 10.,  2.,  4.,  3.,  9.,  7., nan,  5.,  8.,  6.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Bare_Nuclei.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_code_number</th>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <th>Uniformity_of_Cell_Size</th>\n",
       "      <th>Uniformity_of_Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>776715</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>841769</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>888820</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sample_code_number  Clump_Thickness  Uniformity_of_Cell_Size  \\\n",
       "0               1000025                5                        1   \n",
       "1               1002945                5                        4   \n",
       "2               1015425                3                        1   \n",
       "3               1016277                6                        8   \n",
       "4               1017023                4                        1   \n",
       "..                  ...              ...                      ...   \n",
       "694              776715                3                        1   \n",
       "695              841769                2                        1   \n",
       "696              888820                5                       10   \n",
       "697              897471                4                        8   \n",
       "698              897471                4                        8   \n",
       "\n",
       "     Uniformity_of_Cell_Shape  Marginal_Adhesion  Single_Epithelial_Cell_Size  \\\n",
       "0                           1                  1                            2   \n",
       "1                           4                  5                            7   \n",
       "2                           1                  1                            2   \n",
       "3                           8                  1                            3   \n",
       "4                           1                  3                            2   \n",
       "..                        ...                ...                          ...   \n",
       "694                         1                  1                            3   \n",
       "695                         1                  1                            2   \n",
       "696                        10                  3                            7   \n",
       "697                         6                  4                            3   \n",
       "698                         8                  5                            4   \n",
       "\n",
       "     Bare_Nuclei  Bland_Chromatin  Normal_Nucleoli  Mitoses  Class  \n",
       "0            1.0                3                1        1      2  \n",
       "1           10.0                3                2        1      2  \n",
       "2            2.0                3                1        1      2  \n",
       "3            4.0                3                7        1      2  \n",
       "4            1.0                3                1        1      2  \n",
       "..           ...              ...              ...      ...    ...  \n",
       "694          2.0                1                1        1      2  \n",
       "695          1.0                1                1        1      2  \n",
       "696          3.0                8               10        2      4  \n",
       "697          4.0               10                6        1      4  \n",
       "698          5.0               10                4        1      4  \n",
       "\n",
       "[699 rows x 11 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace the nan with the mean\n",
    "df['Bare_Nuclei'].fillna(df['Bare_Nuclei'].mean(), inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        , 10.        ,  2.        ,  4.        ,  3.        ,\n",
       "        9.        ,  7.        ,  3.54465593,  5.        ,  8.        ,\n",
       "        6.        ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Bare_Nuclei.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sample_code_number</th>\n",
       "      <td>699.0</td>\n",
       "      <td>1.071704e+06</td>\n",
       "      <td>617095.729819</td>\n",
       "      <td>61634.0</td>\n",
       "      <td>870688.5</td>\n",
       "      <td>1171710.0</td>\n",
       "      <td>1238298.0</td>\n",
       "      <td>13454352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <td>699.0</td>\n",
       "      <td>4.417740e+00</td>\n",
       "      <td>2.815741</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uniformity_of_Cell_Size</th>\n",
       "      <td>699.0</td>\n",
       "      <td>3.134478e+00</td>\n",
       "      <td>3.051459</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uniformity_of_Cell_Shape</th>\n",
       "      <td>699.0</td>\n",
       "      <td>3.207439e+00</td>\n",
       "      <td>2.971913</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <td>699.0</td>\n",
       "      <td>2.806867e+00</td>\n",
       "      <td>2.855379</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <td>699.0</td>\n",
       "      <td>3.216023e+00</td>\n",
       "      <td>2.214300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <td>699.0</td>\n",
       "      <td>3.544656e+00</td>\n",
       "      <td>3.601852</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <td>699.0</td>\n",
       "      <td>3.437768e+00</td>\n",
       "      <td>2.438364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <td>699.0</td>\n",
       "      <td>2.866953e+00</td>\n",
       "      <td>3.053634</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitoses</th>\n",
       "      <td>699.0</td>\n",
       "      <td>1.589413e+00</td>\n",
       "      <td>1.715078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>699.0</td>\n",
       "      <td>2.689557e+00</td>\n",
       "      <td>0.951273</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             count          mean            std      min  \\\n",
       "Sample_code_number           699.0  1.071704e+06  617095.729819  61634.0   \n",
       "Clump_Thickness              699.0  4.417740e+00       2.815741      1.0   \n",
       "Uniformity_of_Cell_Size      699.0  3.134478e+00       3.051459      1.0   \n",
       "Uniformity_of_Cell_Shape     699.0  3.207439e+00       2.971913      1.0   \n",
       "Marginal_Adhesion            699.0  2.806867e+00       2.855379      1.0   \n",
       "Single_Epithelial_Cell_Size  699.0  3.216023e+00       2.214300      1.0   \n",
       "Bare_Nuclei                  699.0  3.544656e+00       3.601852      1.0   \n",
       "Bland_Chromatin              699.0  3.437768e+00       2.438364      1.0   \n",
       "Normal_Nucleoli              699.0  2.866953e+00       3.053634      1.0   \n",
       "Mitoses                      699.0  1.589413e+00       1.715078      1.0   \n",
       "Class                        699.0  2.689557e+00       0.951273      2.0   \n",
       "\n",
       "                                  25%        50%        75%         max  \n",
       "Sample_code_number           870688.5  1171710.0  1238298.0  13454352.0  \n",
       "Clump_Thickness                   2.0        4.0        6.0        10.0  \n",
       "Uniformity_of_Cell_Size           1.0        1.0        5.0        10.0  \n",
       "Uniformity_of_Cell_Shape          1.0        1.0        5.0        10.0  \n",
       "Marginal_Adhesion                 1.0        1.0        4.0        10.0  \n",
       "Single_Epithelial_Cell_Size       2.0        2.0        4.0        10.0  \n",
       "Bare_Nuclei                       1.0        1.0        5.0        10.0  \n",
       "Bland_Chromatin                   2.0        3.0        5.0        10.0  \n",
       "Normal_Nucleoli                   1.0        1.0        4.0        10.0  \n",
       "Mitoses                           1.0        1.0        1.0        10.0  \n",
       "Class                             2.0        2.0        4.0         4.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target vector\n",
    "y = df['Class'].values//2-1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logreg(x, y, niter=10):\n",
    "    w = 0 # initial model parameter\n",
    "    yhat = sigmoid(x*w)\n",
    "    for it in range(niter):\n",
    "        ce = -(np.log(yhat)* y + np.log(1-yhat) * (1-y)).sum()\n",
    "        ce_i = ((yhat - y) * x).sum()\n",
    "        ce_ii= (yhat * (1-yhat) * x**2).sum()\n",
    "        w -= ce_i / ce_ii\n",
    "        yhat = sigmoid(x*w)\n",
    "        return w, yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def avg_ce(y, yhat):\n",
    "    ce = -(np.log(yhat)* y + np.log(1-yhat) * (1-y)).sum()\n",
    "    return ce/len(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clump_Thickness\n",
      "w = 0.039632874 CE(w) = 3.06038094\n",
      "CEm(w) = 0.687739208\n",
      "Uniformity_of_Cell_Size\n",
      "w = 0.146180893 CE(w) = 3.06038094\n",
      "CEm(w) = 0.639204697\n",
      "Uniformity_of_Cell_Shape\n",
      "w = 0.137765798 CE(w) = 3.06038094\n",
      "CEm(w) = 0.645652807\n",
      "Marginal_Adhesion\n",
      "w = 0.127165565 CE(w) = 3.06038094\n",
      "CEm(w) = 0.659383857\n",
      "Single_Epithelial_Cell_Size\n",
      "w = 0.057453999 CE(w) = 3.06038094\n",
      "CEm(w) = 0.6868162\n",
      "Bare_Nuclei\n",
      "w = 0.132577858 CE(w) = 3.06038094\n",
      "CEm(w) = 0.633926393\n",
      "Bland_Chromatin\n",
      "w = 0.077189590 CE(w) = 3.06038094\n",
      "CEm(w) = 0.679762996\n",
      "Normal_Nucleoli\n",
      "w = 0.134160274 CE(w) = 3.06038094\n",
      "CEm(w) = 0.651733288\n",
      "Mitoses\n",
      "w = 0.071746531 CE(w) = 3.06038094\n",
      "CEm(w) = 0.689591602\n"
     ]
    }
   ],
   "source": [
    "for column in names[1:-1]:\n",
    "    x = df[column]\n",
    "    w, yhat = fit_logreg(x, y)\n",
    "    cem = avg_ce(y, yhat)\n",
    "    print(column)\n",
    "    print(f'w = {w:.9f} CE(w) = {ce:.9}')\n",
    "    print(f'CEm(w) = {cem:.9}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clump_Thickness                AvgCE=0.390611001 w=0.905912818\n",
      "Uniformity_of_Cell_Size        AvgCE=0.199170002 w=1.572130112\n",
      "Uniformity_of_Cell_Shape       AvgCE=0.211668062 w=1.524221657\n",
      "Marginal_Adhesion              AvgCE=0.359316116 w=1.107418964\n",
      "Single_Epithelial_Cell_Size    AvgCE=0.351132841 w=1.537879946\n",
      "Bare_Nuclei                    AvgCE=0.265288430 w=0.979151501\n",
      "Bland_Chromatin                AvgCE=0.303804235 w=1.542319399\n",
      "Normal_Nucleoli                AvgCE=0.355869859 w=1.004452002\n",
      "Mitoses                        AvgCE=0.527654735 w=1.711238337\n"
     ]
    }
   ],
   "source": [
    "# 2nd solution Normalized input\n",
    "def logreg_predict(x, w):\n",
    "    return sigmoid(x * w)\n",
    "\n",
    "def logreg_fit(x, y, niter=10):\n",
    "    w = 0 # initial model parameter\n",
    "    for it in range(niter):\n",
    "        yhat = logreg_predict(x, w)\n",
    "        ce_i = ((yhat - y) * x).sum()\n",
    "        ce_ii = (yhat * (1 - yhat) * x**2).sum()\n",
    "        w -= ce_i / ce_ii # Newton step    \n",
    "    return w\n",
    "\n",
    "def avg_cross_entropy(y, yhat):\n",
    "    ce = -(np.log(yhat) * y + np.log(1 - yhat) * (1 - y)).sum()\n",
    "    return ce / len(y)\n",
    "    \n",
    "for column in names[1:-1]:\n",
    "    se = df[column]\n",
    "    x = (se - se.mean()).values # input vector\n",
    "    w = logreg_fit(x, y)\n",
    "    yhat = logreg_predict(x, w)\n",
    "    ace = avg_cross_entropy(y, yhat)\n",
    "    print(f'{column:30} AvgCE={ace:.9f} w={w:.9f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4**: Repeat the previous experiment using scikit-learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clump_Thickness                AvgCE=0.390611001 w=0.905912814\n",
      "Uniformity_of_Cell_Size        AvgCE=0.199170002 w=1.572130109\n",
      "Uniformity_of_Cell_Shape       AvgCE=0.211668062 w=1.524221656\n",
      "Marginal_Adhesion              AvgCE=0.359316116 w=1.107418964\n",
      "Single_Epithelial_Cell_Size    AvgCE=0.351132841 w=1.537879938\n",
      "Bare_Nuclei                    AvgCE=0.265288430 w=0.979151504\n",
      "Bland_Chromatin                AvgCE=0.303804235 w=1.542318627\n",
      "Normal_Nucleoli                AvgCE=0.355869859 w=1.004451975\n",
      "Mitoses                        AvgCE=0.527654735 w=1.711237945\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "for column in names[1:-1]:\n",
    "    se = df[column]\n",
    "    x = (se - se.mean()).values # input vector\n",
    "    cl = LogisticRegression(fit_intercept=False, C=1e12) # define model\n",
    "    X = x.reshape((-1,1))\n",
    "    cl.fit(X, y)                                         # train model\n",
    "    w = cl.coef_[0,0]                                    # extract moddel parameter\n",
    "    yhat = cl.predict_proba(X)[:,1]                      # make probability prediction\n",
    "    ace = log_loss(y, yhat)                              # compute average cross entropy\n",
    "    \n",
    "    print(f'{column:30} AvgCE={ace:.9f} w={w:.9f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5**: Introduce a 70-30% train-test split and re-run the experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([357, 648, 291, 420, 177, 456, 444,  83, 453, 354, 495, 575,  79,\n",
       "         23,  15, 381, 292, 275, 653, 314, 519, 137, 485, 483,  33, 662,\n",
       "        257,   9,  22, 543, 221, 404, 684, 334,  84, 335, 247, 582, 620,\n",
       "        203, 196, 660, 327, 399,  93, 587, 294, 265, 375, 184, 636, 512,\n",
       "        153,  75, 332,  68, 615, 188, 236,  88, 590, 117, 125, 571, 238,\n",
       "          0, 691, 530, 630, 608, 278, 116, 228, 697, 319, 274, 692, 144,\n",
       "        382, 426, 631, 500, 268, 465,  46, 261, 195, 698, 583, 107, 462,\n",
       "        609, 531, 100, 350, 624, 333, 179, 304, 349, 149, 124, 551, 605,\n",
       "        185, 428, 558, 689, 344, 644, 142, 141, 393, 320,  19, 172, 632,\n",
       "        312, 650,  12, 305,  25, 518, 169, 479, 411, 245, 298, 434, 272,\n",
       "        154, 126, 538, 341, 287, 113, 367, 173, 355,  57, 443, 222, 280,\n",
       "         17, 405, 322, 255, 417, 669, 190, 439, 616, 490,  94, 180, 301,\n",
       "        641, 511, 642, 451, 429,   5, 685,  45, 398, 525, 171,  16,  48,\n",
       "        675, 639,   3, 449, 412, 316, 643, 283, 581, 285, 677, 225,  26,\n",
       "        547, 263,  50, 364, 229,  37, 157, 237, 670, 374, 370, 175, 591,\n",
       "        480, 513, 194, 593, 601, 425, 445, 448, 674, 580, 599,  67, 534,\n",
       "        168, 447, 162, 309, 193, 478, 365, 383, 629, 535, 152, 488, 497,\n",
       "        226, 457, 557, 103, 421, 678, 527,  74, 115, 407, 673, 119,  53,\n",
       "        151, 403, 658, 207, 687, 487, 468, 537,   8, 572,  36, 452, 139,\n",
       "        253, 303, 523, 526, 368,  59, 111, 597, 503, 493, 262, 586, 297,\n",
       "        414, 150, 433, 576, 440, 266, 607, 359, 619,  38, 127, 423, 416,\n",
       "        307, 198, 351, 494, 146, 450, 647, 522, 419, 442, 621, 147, 585,\n",
       "        348, 463, 325, 186, 123, 602,  96, 143, 239, 394, 469, 197,  97,\n",
       "        371, 324, 279, 293, 400, 122, 183, 202, 438, 246, 415, 618, 129,\n",
       "        402, 549, 541, 219, 634, 529, 637, 536, 386, 676, 509, 267, 441,\n",
       "        496, 112, 232, 606, 373, 233, 550, 317, 410, 623, 358, 258, 282,\n",
       "        376, 384, 224, 683, 568, 472, 347, 505, 688, 645, 628, 594, 556,\n",
       "         85, 242, 159, 524,  35, 540, 170, 596, 588, 657,  95, 563, 240,\n",
       "        574, 460, 553, 611, 206, 392, 397, 589, 217,   4, 622, 546,  98,\n",
       "        573, 406, 502,  47,  32, 200, 134,  27, 613, 230, 489, 378, 288,\n",
       "        418, 391, 592, 498, 138,  62, 471, 128, 679, 520,  64,  14, 156,\n",
       "         40, 492, 379, 187, 216,  52, 337, 295, 251, 461, 455, 696, 269,\n",
       "        201, 161, 555, 401, 476, 105, 565, 389,   1, 652, 561,  80, 205,\n",
       "         34, 508, 427, 454, 366,  91, 339, 564, 345, 241,  13, 315, 600,\n",
       "        387, 273, 166, 693, 646, 484, 682, 504, 243, 566, 562, 189, 475,\n",
       "        510,  58, 474, 560, 252,  21, 313, 459, 160, 276, 191, 385, 413,\n",
       "        491, 343, 308, 661, 130, 663,  99, 372,  87, 458, 330, 214, 466,\n",
       "        121, 614,  20,  71, 106, 270, 435, 102]),\n",
       " array([158, 499, 396, 155, 321, 212, 234, 289, 300, 356, 672, 328, 199,\n",
       "         78, 598, 569, 446, 506, 626, 603, 360, 338, 668, 290, 284, 331,\n",
       "        477,  54, 248, 223, 133, 640, 136, 109, 181, 432, 554, 482, 516,\n",
       "        132, 176,  72, 254, 577, 649, 595, 666, 352,  76, 148, 346,  90,\n",
       "        681,  10,  63, 635, 656, 174, 256, 667,  31, 369, 570,  77, 532,\n",
       "        548, 211,  55, 135, 671, 340,   2, 227,  81, 473, 694, 665, 604,\n",
       "        120, 311, 204, 244, 686, 271, 131, 680,  60, 310,  30,  69, 651,\n",
       "        390,  44, 625,  70, 515, 654, 249, 209, 165, 470, 164, 507, 323,\n",
       "         65, 409,  49, 118, 192,  39, 259, 422,   6, 101, 542, 299, 395,\n",
       "        501, 318, 145, 486, 353, 208, 695, 361,  86, 664, 481, 633,  41,\n",
       "        108, 690,  56, 424, 514,  24, 218, 431, 281, 110,  82,  51, 220,\n",
       "        559, 544, 302, 552, 215, 235,  18, 250, 260, 430, 264,  61, 213,\n",
       "        377,  29, 182, 306, 388, 329, 437, 296, 584, 342, 436, 579, 326,\n",
       "        362, 617, 578, 231, 336, 655, 163, 286, 612, 517, 464, 277, 408,\n",
       "        104, 114, 627, 545, 467,  92,   7,  89, 528, 380, 521, 539, 363,\n",
       "        638, 140,  28,  43,  42,  73, 167, 210, 610,  66,  11, 659, 567,\n",
       "        178, 533]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "# another way of set test size is: train_test_split\n",
    "tr, te = next(ShuffleSplit(test_size=0.3, random_state=42).split(df))\n",
    "tr, te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clump_Thickness                AvgCE=0.335747286 w=0.826808279\n",
      "Uniformity_of_Cell_Size        AvgCE=0.176748276 w=1.515755629\n",
      "Uniformity_of_Cell_Shape       AvgCE=0.217456999 w=1.535220556\n",
      "Marginal_Adhesion              AvgCE=0.300066855 w=1.024555296\n",
      "Single_Epithelial_Cell_Size    AvgCE=0.350178198 w=1.527215223\n",
      "Bare_Nuclei                    AvgCE=0.311173420 w=1.008497031\n",
      "Bland_Chromatin                AvgCE=0.306641746 w=1.453926694\n",
      "Normal_Nucleoli                AvgCE=0.362623274 w=1.024082073\n",
      "Mitoses                        AvgCE=0.491826787 w=1.562289264\n"
     ]
    }
   ],
   "source": [
    "for column in names[1:-1]:\n",
    "    se = df[column]\n",
    "    x = (se - se.mean()).values # input vector\n",
    "    cl = LogisticRegression(fit_intercept=False, C=1e12) # define model\n",
    "    X = x.reshape((-1,1))\n",
    "    cl.fit(X[tr], y[tr])                                 # train model (on training set)\n",
    "    w = cl.coef_[0,0]                                    # extract moddel parameter\n",
    "    yhat = cl.predict_proba(X)[:,1]                      # make probability prediction\n",
    "    ace = log_loss(y[te], yhat[te])                      # compute average cross entropy (on test set)\n",
    "    \n",
    "    print(f'{column:30} AvgCE={ace:.9f} w={w:.9f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Logistic Regression\n",
    "\n",
    "The previous approach can be generalized to allows multiple input features.\n",
    "\n",
    "- model's prediction: $\\hat{y} = \\sigma(Xw)$<br>\n",
    "- objective function: $CE(w) = -\\log(\\hat{y})^Ty - \\log(1 - \\hat{y})^T(1 - y)$<br>\n",
    "- gradient vector: $\\frac{d}{dw} CE(w) = X^T(\\hat{y} - y)$<br>\n",
    "- Hessian matrix: $\\left(\\frac{d}{dw}\\right)^2 CE(w) = X^T \\mathrm{diag}\\left(\\hat{y}(1 - \\hat{y})\\right) X$\n",
    "- Newton-step: $w_{\\mathrm{new}} = w - \\left[\\left(\\frac{d}{dw}\\right)^2 CE(w)\\right]^{-1} \\left[\\frac{d}{dw} CE(w)\\right]$\n",
    "\n",
    "Similarly to linear regression, the bias term can be handled by introducing a constant 1 feature.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6**: Train a multivariate logistic regression model on the training set and measure its cross-entropy on the test set! Implement the training algorithm without using scikit-learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(699, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-190.        , -488.5       , -460.        , -356.        ,\n",
       "       -153.        , -591.23206442, -239.5       , -411.        ,\n",
       "        -68.5       ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input matrix\n",
    "X = df[names[1:-1]].values\n",
    "# target vector\n",
    "y = df['Class'].values//2-1\n",
    "print(X.shape)\n",
    "\n",
    "# initial model\n",
    "w = np.zeros(X.shape[1])\n",
    "\n",
    "# prediction\n",
    "yhat = sigmoid(X @ w)\n",
    "\n",
    "# gradient of cross-entropy\n",
    "g = X.T @ (yhat - y)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4794.        , 3386.75      , 3432.        , 2849.25      ,\n",
       "        3050.5       , 3775.85285505, 3323.        , 3017.25      ,\n",
       "        1522.        ],\n",
       "       [3386.75      , 3341.75      , 3192.        , 2610.25      ,\n",
       "        2648.        , 3258.81039531, 2864.25      , 2745.75      ,\n",
       "        1289.5       ],\n",
       "       [3432.        , 3192.        , 3339.        , 2584.75      ,\n",
       "        2629.        , 3312.26354319, 2857.5       , 2746.25      ,\n",
       "        1281.25      ],\n",
       "       [2849.25      , 2610.25      , 2584.75      , 2799.5       ,\n",
       "        2239.        , 2932.19875549, 2496.25      , 2324.25      ,\n",
       "        1136.5       ],\n",
       "       [3050.5       , 2648.        , 2629.        , 2239.        ,\n",
       "        2663.        , 2801.06039531, 2512.5       , 2353.25      ,\n",
       "        1210.75      ],\n",
       "       [3775.85285505, 3258.81039531, 3312.26354319, 2932.19875549,\n",
       "        2801.06039531, 4459.50834264, 3165.30819912, 2883.99121523,\n",
       "        1349.67862372],\n",
       "       [3323.        , 2864.25      , 2857.5       , 2496.25      ,\n",
       "        2512.5       , 3165.30819912, 3102.75      , 2587.5       ,\n",
       "        1206.        ],\n",
       "       [3017.25      , 2745.75      , 2746.25      , 2324.25      ,\n",
       "        2353.25      , 2883.99121523, 2587.5       , 3063.5       ,\n",
       "        1187.75      ],\n",
       "       [1522.        , 1289.5       , 1281.25      , 1136.5       ,\n",
       "        1210.75      , 1349.67862372, 1206.        , 1187.75      ,\n",
       "         954.75      ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hessian matrix of cross-entropy\n",
    "H = X.T * (yhat * (1 - yhat)) @ X\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5109304 ,  1.11234173,  0.27328331,  0.04948115, -0.97918294,\n",
       "        0.73256627, -0.72881045,  0.41669609, -0.28989454])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Newton-step\n",
    "w -= np.linalg.solve(H, g)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 484.50987921140165\n",
      "1 320.0112328042882\n",
      "2 285.73437841351625\n",
      "3 277.70418009292183\n",
      "4 277.0625947428168\n",
      "5 277.05704693001366\n",
      "6 277.0570464294203\n",
      "7 277.0570464294203\n",
      "8 277.0570464294204\n",
      "9 277.0570464294203\n"
     ]
    }
   ],
   "source": [
    "# Newton loop\n",
    "w = np.zeros(X.shape[1])\n",
    "niter = 10\n",
    "for it in range(niter):\n",
    "    # prediction\n",
    "    yhat = sigmoid(X @ w)\n",
    "    # cross-entropy\n",
    "    ce = -np.log(yhat) @ y - np.log(1 - yhat) @ (1 - y)\n",
    "    # gradient of cross-entropy\n",
    "    g = X.T @ (yhat - y)\n",
    "    # Hessian matrix of cross-entropy\n",
    "    H = X.T * (yhat * (1 - yhat)) @ X\n",
    "    print(it, ce)\n",
    "    # Newton-step\n",
    "    w -= np.linalg.solve(H, g)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y, yhat):\n",
    "    return -np.log(yhat) @ y - np.log(1 - yhat) @ (1 - y)\n",
    "\n",
    "def logreg_m_fit(X, y, niter=10):\n",
    "    w = np.zeros(X.shape[1])\n",
    "    for it in range(niter):\n",
    "        # prediction\n",
    "        yhat = sigmoid(X @ w)\n",
    "        # cross-entropy\n",
    "        ce = cross_entropy(y, yhat)\n",
    "        # gradient of cross-entropy\n",
    "        g = X.T @ (yhat - y)\n",
    "        # Hessian matrix of cross-entropy\n",
    "        H = X.T * (yhat * (1 - yhat)) @ X\n",
    "        print(it, ce)\n",
    "        # Newton-step\n",
    "        w -= np.linalg.solve(H, g)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 338.9489712938133\n",
      "1 219.31492649580565\n",
      "2 194.84385525659366\n",
      "3 189.2334455179607\n",
      "4 188.79436565306744\n",
      "5 188.79058752143467\n",
      "6 188.7905871820355\n",
      "7 188.79058718203555\n",
      "8 188.79058718203555\n",
      "9 188.79058718203552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.37775352,  0.81513883,  0.24794682, -0.00703306, -0.7267206 ,\n",
       "        0.585522  , -0.43993472,  0.32078896, -0.23507939])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = logreg_m_fit(X[tr], y[tr])\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.3437344981877"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "yhat = sigmoid(X @ w)\n",
    "cross_entropy(y[te], yhat[te])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.37775352,  0.81513883,  0.24794682, -0.00703306, -0.7267206 ,\n",
       "        0.585522  , -0.43993472,  0.32078896, -0.23507939])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7**: Use scikit-learn for training the model and compare the results against the previous experiment's results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.330792605335226 0.4105911971787714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cl = LogisticRegression(fit_intercept=False, C=1e12) # no bies, no regularization\n",
    "cl.fit(X[tr], y[tr])\n",
    "yhat = cl.predict_proba(X)[:,1]\n",
    "ce = cross_entropy(y[te], yhat[te])\n",
    "print (ce, ce / len(te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.37775325,  0.81513397,  0.24796104, -0.00703901, -0.72671579,\n",
       "        0.58551021, -0.43993414,  0.32079127, -0.23508148])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $K$-Fold Cross-Validation\n",
    "- Idea: Randomly split the data to $K$ roughly equal partitions and run $K$ experiments!\n",
    "- In the $i$-th experiment, partition $i$ is used as the test set and all other partitions as the training set.\n",
    "- In the end, the scores obtained from the $K$ experiments are averaged.\n",
    "- $K$-fold cross-validation is slower but more reliable than the simple train-test split.\n",
    "- In the *stratified* variant of the method, the same distribution of labels is enforced in every partition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../_img/cross_val.jpg\" width=\"350\" align=\"left\" style=\"opacity: 0.8\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8**: Replace the train-test split to 10-fold cross valiadtion and re-run the last experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "cv = KFold(10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for tr, te in cv.split(X):\n",
    "    cl = LogisticRegression(fit_intercept=False, C=1e12) # no bies, no regularization\n",
    "    cl.fit(X[tr], y[tr])\n",
    "    yhat = cl.predict_proba(X)[:,1]\n",
    "    score = log_loss(y[te], yhat[te])\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3103854498633047,\n",
       " 0.5013502260500776,\n",
       " 0.492728969735146,\n",
       " 0.34584544309166304,\n",
       " 0.5820155518006203,\n",
       " 0.3244320020003381,\n",
       " 0.4848963100207666,\n",
       " 0.3690964445150554,\n",
       " 0.38712987311278146,\n",
       " 0.41059119717877135]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4208471467368525"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
