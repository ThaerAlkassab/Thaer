{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate [Logistic Regression](https://en.wikipedia.org/wiki/Logistic_regression)\n",
    "\n",
    "- Logistic regression is an algorithm for **classification**.\n",
    "\n",
    "- Logistic regression builds a **linear model** that separates the two classes by a hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../_img/linear_classifier.jpg\" width=\"300\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, let' discuss first the **univariate** case, with a **binary target** variable and **no bias** term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../_img/logreg_1d.jpg\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Programming Exam Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>study_time</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>David Beckham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jessica Scott</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jack Johnson</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Scunner Campbell</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plain Jane</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Archie Gillis</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  study_time  result\n",
       "0     David Beckham         0.0       0\n",
       "1     Jessica Scott         7.0       1\n",
       "2      Jack Johnson         3.5       0\n",
       "3  Scunner Campbell         6.0       0\n",
       "4       Plain Jane          3.0       1\n",
       "5     Archie Gillis        15.0       1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = [\n",
    "    {'name': 'David Beckham',    'study_time': 0,   'result': 0},\n",
    "    {'name': 'Jessica Scott',    'study_time': 7,   'result': 1},\n",
    "    {'name': 'Jack Johnson',     'study_time': 3.5, 'result': 0},\n",
    "    {'name': 'Scunner Campbell', 'study_time': 6,   'result': 0},\n",
    "    {'name': 'Plain Jane ',      'study_time': 3,   'result': 1},\n",
    "    {'name': 'Archie Gillis',    'study_time': 15,  'result': 1},\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above toy data set contains 2 attributes of 6 students:\n",
    "- Hours spent on preparing for the exam.\n",
    "- Did the student pass the exam? (0=no, 1=yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**: Train a univariate logistic regression model that estimates the `result` column from the `study_time` column!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.75  1.25 -2.25  0.25 -2.75  9.25] [0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "x = df['study_time'].values # input vector\n",
    "y = df['result'].values     # target vector\n",
    "\n",
    "# subtract mean from inpute\n",
    "xm = x.mean()\n",
    "x -= xm\n",
    "\n",
    "print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sigmoid(t):\n",
    "    return 1/(1+np.exp(-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sigmoid (x)\n",
    "\n",
    "w = 0 # initial model parameter\n",
    "\n",
    "yhat = sigmoid(x*w)\n",
    "yhat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.75, 33.21875)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_i = ((yhat - y) * x).sum()\n",
    "\n",
    "ce_ii= (yhat * (1-yhat) * x**2).sum()\n",
    "\n",
    "ce_i, ce_ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2333019755409219"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st Newton's step\n",
    "\n",
    "w -= ce_i / ce_ii\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20726573, 0.57239452, 0.37170029, 0.51457724, 0.34488937,\n",
       "       0.896418  ])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = sigmoid(x*w)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4666039510818438"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd Newton's step\n",
    "\n",
    "w -= ce_i / ce_ii\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06398561, 0.64181602, 0.2592522 , 0.52912972, 0.21701265,\n",
       "       0.98682389])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = sigmoid(x*w)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = 0.233301976 CE(w) = 4.15888308\n",
      "[0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "w = 0.328737831 CE(w) = 3.15154714\n",
      "[0.20726573 0.57239452 0.37170029 0.51457724 0.34488937 0.896418  ]\n",
      "w = 0.358540912 CE(w) = 3.06529976\n",
      "[0.13121682 0.60130901 0.32307847 0.52053456 0.28822323 0.95438476]\n",
      "w = 0.360841429 CE(w) = 3.06040528\n",
      "[0.11288448 0.61020551 0.30859051 0.52239382 0.27170535 0.96499066]\n",
      "w = 0.360853783 CE(w) = 3.06038094\n",
      "[0.11156658 0.61088928 0.30748721 0.52253731 0.27045528 0.9657025 ]\n",
      "w = 0.360853783 CE(w) = 3.06038094\n",
      "[0.11155953 0.61089295 0.30748129 0.52253808 0.27044857 0.96570628]\n",
      "w = 0.360853783 CE(w) = 3.06038094\n",
      "[0.11155953 0.61089295 0.30748129 0.52253808 0.27044857 0.96570628]\n",
      "w = 0.360853783 CE(w) = 3.06038094\n",
      "[0.11155953 0.61089295 0.30748129 0.52253808 0.27044857 0.96570628]\n",
      "w = 0.360853783 CE(w) = 3.06038094\n",
      "[0.11155953 0.61089295 0.30748129 0.52253808 0.27044857 0.96570628]\n",
      "w = 0.360853783 CE(w) = 3.06038094\n",
      "[0.11155953 0.61089295 0.30748129 0.52253808 0.27044857 0.96570628]\n"
     ]
    }
   ],
   "source": [
    "# Newton steps in for loop\n",
    "for it in range(10):\n",
    "    yhat = sigmoid(x*w)\n",
    "    ce = -(np.log(yhat)* y + np.log(1-yhat) * (1-y)).sum()\n",
    "    ce_i = ((yhat - y) * x).sum()\n",
    "    ce_ii= (yhat * (1-yhat) * x**2).sum()\n",
    "    w -= ce_i / ce_ii\n",
    "    print(f'w = {w:.9f} CE(w) = {ce:.9}')\n",
    "    print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = -(np.log(yhat)* y + np.log(1-yhat) * (1-y)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'P(passing the exam)')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the probability of passing the exam (according to the model)\n",
    "# as a function of the study hours!\n",
    "import matplotlib.pyplot as plt\n",
    "x2 = np.arange(0, 24, 0.5)\n",
    "yhat2 = sigmoid((x2 - xm) * w)\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(x2, yhat2)\n",
    "plt.grid(True)\n",
    "plt.xlabel('study hours')\n",
    "plt.ylabel('P(passing the exam)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Wisconsin Breast Cancer Problem\n",
    "\n",
    "<img src=\"../_img/wisconsin_illustration.jpg\" width=\"200\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Wisconsin Breast Cancer data set contains the attributes of 699 suspicious lesions in tissue microscopy images. The raw data is contained in [wisconsin_data.txt](../_data/wisconsin_data.txt), the description can be read in [wisconsin_names.txt](../_data/wisconsin_names.txt). The task is to estimate if the lesion is malicious (4) or benign (2), based on the image attributes of the lesion. Therefore the task is a binary classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**: Train a univariate logistic regression model for each input feature separately, and measure the *average* cross-entropy of the models! Use the full data set both for training and evaluation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names.\n",
    "names = [\n",
    "    'Sample_code_number',\n",
    "    'Clump_Thickness',\n",
    "    'Uniformity_of_Cell_Size',\n",
    "    'Uniformity_of_Cell_Shape',\n",
    "    'Marginal_Adhesion',\n",
    "    'Single_Epithelial_Cell_Size',\n",
    "    'Bare_Nuclei',\n",
    "    'Bland_Chromatin',\n",
    "    'Normal_Nucleoli',\n",
    "    'Mitoses',\n",
    "    'Class'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_code_number</th>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <th>Uniformity_of_Cell_Size</th>\n",
       "      <th>Uniformity_of_Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>776715</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>841769</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>888820</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sample_code_number  Clump_Thickness  Uniformity_of_Cell_Size  \\\n",
       "0               1000025                5                        1   \n",
       "1               1002945                5                        4   \n",
       "2               1015425                3                        1   \n",
       "3               1016277                6                        8   \n",
       "4               1017023                4                        1   \n",
       "..                  ...              ...                      ...   \n",
       "694              776715                3                        1   \n",
       "695              841769                2                        1   \n",
       "696              888820                5                       10   \n",
       "697              897471                4                        8   \n",
       "698              897471                4                        8   \n",
       "\n",
       "     Uniformity_of_Cell_Shape  Marginal_Adhesion  Single_Epithelial_Cell_Size  \\\n",
       "0                           1                  1                            2   \n",
       "1                           4                  5                            7   \n",
       "2                           1                  1                            2   \n",
       "3                           8                  1                            3   \n",
       "4                           1                  3                            2   \n",
       "..                        ...                ...                          ...   \n",
       "694                         1                  1                            3   \n",
       "695                         1                  1                            2   \n",
       "696                        10                  3                            7   \n",
       "697                         6                  4                            3   \n",
       "698                         8                  5                            4   \n",
       "\n",
       "     Bare_Nuclei  Bland_Chromatin  Normal_Nucleoli  Mitoses  Class  \n",
       "0            1.0                3                1        1      2  \n",
       "1           10.0                3                2        1      2  \n",
       "2            2.0                3                1        1      2  \n",
       "3            4.0                3                7        1      2  \n",
       "4            1.0                3                1        1      2  \n",
       "..           ...              ...              ...      ...    ...  \n",
       "694          2.0                1                1        1      2  \n",
       "695          1.0                1                1        1      2  \n",
       "696          3.0                8               10        2      4  \n",
       "697          4.0               10                6        1      4  \n",
       "698          5.0               10                4        1      4  \n",
       "\n",
       "[699 rows x 11 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('wisconsin_data.txt', sep=',', names=names, na_values='?')\n",
    "# we found some ? values, so we replaced it with nan\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 11 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Sample_code_number           699 non-null    int64  \n",
      " 1   Clump_Thickness              699 non-null    int64  \n",
      " 2   Uniformity_of_Cell_Size      699 non-null    int64  \n",
      " 3   Uniformity_of_Cell_Shape     699 non-null    int64  \n",
      " 4   Marginal_Adhesion            699 non-null    int64  \n",
      " 5   Single_Epithelial_Cell_Size  699 non-null    int64  \n",
      " 6   Bare_Nuclei                  683 non-null    float64\n",
      " 7   Bland_Chromatin              699 non-null    int64  \n",
      " 8   Normal_Nucleoli              699 non-null    int64  \n",
      " 9   Mitoses                      699 non-null    int64  \n",
      " 10  Class                        699 non-null    int64  \n",
      "dtypes: float64(1), int64(10)\n",
      "memory usage: 60.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., 10.,  2.,  4.,  3.,  9.,  7., nan,  5.,  8.,  6.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Bare_Nuclei.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_code_number</th>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <th>Uniformity_of_Cell_Size</th>\n",
       "      <th>Uniformity_of_Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>776715</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>841769</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>888820</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sample_code_number  Clump_Thickness  Uniformity_of_Cell_Size  \\\n",
       "0               1000025                5                        1   \n",
       "1               1002945                5                        4   \n",
       "2               1015425                3                        1   \n",
       "3               1016277                6                        8   \n",
       "4               1017023                4                        1   \n",
       "..                  ...              ...                      ...   \n",
       "694              776715                3                        1   \n",
       "695              841769                2                        1   \n",
       "696              888820                5                       10   \n",
       "697              897471                4                        8   \n",
       "698              897471                4                        8   \n",
       "\n",
       "     Uniformity_of_Cell_Shape  Marginal_Adhesion  Single_Epithelial_Cell_Size  \\\n",
       "0                           1                  1                            2   \n",
       "1                           4                  5                            7   \n",
       "2                           1                  1                            2   \n",
       "3                           8                  1                            3   \n",
       "4                           1                  3                            2   \n",
       "..                        ...                ...                          ...   \n",
       "694                         1                  1                            3   \n",
       "695                         1                  1                            2   \n",
       "696                        10                  3                            7   \n",
       "697                         6                  4                            3   \n",
       "698                         8                  5                            4   \n",
       "\n",
       "     Bare_Nuclei  Bland_Chromatin  Normal_Nucleoli  Mitoses  Class  \n",
       "0            1.0                3                1        1      2  \n",
       "1           10.0                3                2        1      2  \n",
       "2            2.0                3                1        1      2  \n",
       "3            4.0                3                7        1      2  \n",
       "4            1.0                3                1        1      2  \n",
       "..           ...              ...              ...      ...    ...  \n",
       "694          2.0                1                1        1      2  \n",
       "695          1.0                1                1        1      2  \n",
       "696          3.0                8               10        2      4  \n",
       "697          4.0               10                6        1      4  \n",
       "698          5.0               10                4        1      4  \n",
       "\n",
       "[699 rows x 11 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace the nan with the mean\n",
    "df['Bare_Nuclei'].fillna(df['Bare_Nuclei'].mean(), inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        , 10.        ,  2.        ,  4.        ,  3.        ,\n",
       "        9.        ,  7.        ,  3.54465593,  5.        ,  8.        ,\n",
       "        6.        ])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Bare_Nuclei.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sample_code_number</th>\n",
       "      <td>699.0</td>\n",
       "      <td>1.071704e+06</td>\n",
       "      <td>617095.729819</td>\n",
       "      <td>61634.0</td>\n",
       "      <td>870688.5</td>\n",
       "      <td>1171710.0</td>\n",
       "      <td>1238298.0</td>\n",
       "      <td>13454352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <td>699.0</td>\n",
       "      <td>4.417740e+00</td>\n",
       "      <td>2.815741</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uniformity_of_Cell_Size</th>\n",
       "      <td>699.0</td>\n",
       "      <td>3.134478e+00</td>\n",
       "      <td>3.051459</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uniformity_of_Cell_Shape</th>\n",
       "      <td>699.0</td>\n",
       "      <td>3.207439e+00</td>\n",
       "      <td>2.971913</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <td>699.0</td>\n",
       "      <td>2.806867e+00</td>\n",
       "      <td>2.855379</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <td>699.0</td>\n",
       "      <td>3.216023e+00</td>\n",
       "      <td>2.214300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <td>699.0</td>\n",
       "      <td>3.544656e+00</td>\n",
       "      <td>3.601852</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <td>699.0</td>\n",
       "      <td>3.437768e+00</td>\n",
       "      <td>2.438364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <td>699.0</td>\n",
       "      <td>2.866953e+00</td>\n",
       "      <td>3.053634</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitoses</th>\n",
       "      <td>699.0</td>\n",
       "      <td>1.589413e+00</td>\n",
       "      <td>1.715078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>699.0</td>\n",
       "      <td>2.689557e+00</td>\n",
       "      <td>0.951273</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             count          mean            std      min  \\\n",
       "Sample_code_number           699.0  1.071704e+06  617095.729819  61634.0   \n",
       "Clump_Thickness              699.0  4.417740e+00       2.815741      1.0   \n",
       "Uniformity_of_Cell_Size      699.0  3.134478e+00       3.051459      1.0   \n",
       "Uniformity_of_Cell_Shape     699.0  3.207439e+00       2.971913      1.0   \n",
       "Marginal_Adhesion            699.0  2.806867e+00       2.855379      1.0   \n",
       "Single_Epithelial_Cell_Size  699.0  3.216023e+00       2.214300      1.0   \n",
       "Bare_Nuclei                  699.0  3.544656e+00       3.601852      1.0   \n",
       "Bland_Chromatin              699.0  3.437768e+00       2.438364      1.0   \n",
       "Normal_Nucleoli              699.0  2.866953e+00       3.053634      1.0   \n",
       "Mitoses                      699.0  1.589413e+00       1.715078      1.0   \n",
       "Class                        699.0  2.689557e+00       0.951273      2.0   \n",
       "\n",
       "                                  25%        50%        75%         max  \n",
       "Sample_code_number           870688.5  1171710.0  1238298.0  13454352.0  \n",
       "Clump_Thickness                   2.0        4.0        6.0        10.0  \n",
       "Uniformity_of_Cell_Size           1.0        1.0        5.0        10.0  \n",
       "Uniformity_of_Cell_Shape          1.0        1.0        5.0        10.0  \n",
       "Marginal_Adhesion                 1.0        1.0        4.0        10.0  \n",
       "Single_Epithelial_Cell_Size       2.0        2.0        4.0        10.0  \n",
       "Bare_Nuclei                       1.0        1.0        5.0        10.0  \n",
       "Bland_Chromatin                   2.0        3.0        5.0        10.0  \n",
       "Normal_Nucleoli                   1.0        1.0        4.0        10.0  \n",
       "Mitoses                           1.0        1.0        1.0        10.0  \n",
       "Class                             2.0        2.0        4.0         4.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target vector\n",
    "y = df['Class'].values//2-1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logreg(x, y, niter=10):\n",
    "    w = 0 # initial model parameter\n",
    "    yhat = sigmoid(x*w)\n",
    "    for it in range(niter):\n",
    "        ce = -(np.log(yhat)* y + np.log(1-yhat) * (1-y)).sum()\n",
    "        ce_i = ((yhat - y) * x).sum()\n",
    "        ce_ii= (yhat * (1-yhat) * x**2).sum()\n",
    "        w -= ce_i / ce_ii\n",
    "        yhat = sigmoid(x*w)\n",
    "        return w, yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def avg_ce(y, yhat):\n",
    "    ce = -(np.log(yhat)* y + np.log(1-yhat) * (1-y)).sum()\n",
    "    return ce/len(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clump_Thickness\n",
      "w = 0.039632874 CE(w) = 3.06038094\n",
      "CEm(w) = 0.687739208\n",
      "Uniformity_of_Cell_Size\n",
      "w = 0.146180893 CE(w) = 3.06038094\n",
      "CEm(w) = 0.639204697\n",
      "Uniformity_of_Cell_Shape\n",
      "w = 0.137765798 CE(w) = 3.06038094\n",
      "CEm(w) = 0.645652807\n",
      "Marginal_Adhesion\n",
      "w = 0.127165565 CE(w) = 3.06038094\n",
      "CEm(w) = 0.659383857\n",
      "Single_Epithelial_Cell_Size\n",
      "w = 0.057453999 CE(w) = 3.06038094\n",
      "CEm(w) = 0.6868162\n",
      "Bare_Nuclei\n",
      "w = 0.132577858 CE(w) = 3.06038094\n",
      "CEm(w) = 0.633926393\n",
      "Bland_Chromatin\n",
      "w = 0.077189590 CE(w) = 3.06038094\n",
      "CEm(w) = 0.679762996\n",
      "Normal_Nucleoli\n",
      "w = 0.134160274 CE(w) = 3.06038094\n",
      "CEm(w) = 0.651733288\n",
      "Mitoses\n",
      "w = 0.071746531 CE(w) = 3.06038094\n",
      "CEm(w) = 0.689591602\n"
     ]
    }
   ],
   "source": [
    "for column in names[1:-1]:\n",
    "    x = df[column]\n",
    "    w, yhat = fit_logreg(x, y)\n",
    "    cem = avg_ce(y, yhat)\n",
    "    print(column)\n",
    "    print(f'w = {w:.9f} CE(w) = {ce:.9}')\n",
    "    print(f'CEm(w) = {cem:.9}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clump_Thickness                AvgCE=0.390611001 w=0.905912818\n",
      "Uniformity_of_Cell_Size        AvgCE=0.199170002 w=1.572130112\n",
      "Uniformity_of_Cell_Shape       AvgCE=0.211668062 w=1.524221657\n",
      "Marginal_Adhesion              AvgCE=0.359316116 w=1.107418964\n",
      "Single_Epithelial_Cell_Size    AvgCE=0.351132841 w=1.537879946\n",
      "Bare_Nuclei                    AvgCE=0.265288430 w=0.979151501\n",
      "Bland_Chromatin                AvgCE=0.303804235 w=1.542319399\n",
      "Normal_Nucleoli                AvgCE=0.355869859 w=1.004452002\n",
      "Mitoses                        AvgCE=0.527654735 w=1.711238337\n"
     ]
    }
   ],
   "source": [
    "# 2nd solution Normalized input\n",
    "def logreg_predict(x, w):\n",
    "    return sigmoid(x * w)\n",
    "\n",
    "def logreg_fit(x, y, niter=10):\n",
    "    w = 0 # initial model parameter\n",
    "    for it in range(niter):\n",
    "        yhat = logreg_predict(x, w)\n",
    "        ce_i = ((yhat - y) * x).sum()\n",
    "        ce_ii = (yhat * (1 - yhat) * x**2).sum()\n",
    "        w -= ce_i / ce_ii # Newton step    \n",
    "    return w\n",
    "\n",
    "def avg_cross_entropy(y, yhat):\n",
    "    ce = -(np.log(yhat) * y + np.log(1 - yhat) * (1 - y)).sum()\n",
    "    return ce / len(y)\n",
    "    \n",
    "for column in names[1:-1]:\n",
    "    se = df[column]\n",
    "    x = (se - se.mean()).values # input vector\n",
    "    w = logreg_fit(x, y)\n",
    "    yhat = logreg_predict(x, w)\n",
    "    ace = avg_cross_entropy(y, yhat)\n",
    "    print(f'{column:30} AvgCE={ace:.9f} w={w:.9f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4**: Repeat the previous experiment using scikit-learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clump_Thickness                AvgCE=0.390611001 w=0.905912814\n",
      "Uniformity_of_Cell_Size        AvgCE=0.199170002 w=1.572130109\n",
      "Uniformity_of_Cell_Shape       AvgCE=0.211668062 w=1.524221656\n",
      "Marginal_Adhesion              AvgCE=0.359316116 w=1.107418964\n",
      "Single_Epithelial_Cell_Size    AvgCE=0.351132841 w=1.537879938\n",
      "Bare_Nuclei                    AvgCE=0.265288430 w=0.979151504\n",
      "Bland_Chromatin                AvgCE=0.303804235 w=1.542318627\n",
      "Normal_Nucleoli                AvgCE=0.355869859 w=1.004451975\n",
      "Mitoses                        AvgCE=0.527654735 w=1.711237945\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "for column in names[1:-1]:\n",
    "    se = df[column]\n",
    "    x = (se - se.mean()).values # input vector\n",
    "    cl = LogisticRegression(fit_intercept=False, C=1e12) # define model\n",
    "    X = x.reshape((-1,1))\n",
    "    cl.fit(X, y)                                         # train model\n",
    "    w = cl.coef_[0,0]                                    # extract moddel parameter\n",
    "    yhat = cl.predict_proba(X)[:,1]                      # make probability prediction\n",
    "    ace = log_loss(y, yhat)                              # compute average cross entropy\n",
    "    \n",
    "    print(f'{column:30} AvgCE={ace:.9f} w={w:.9f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5**: Introduce a 70-30% train-test split and re-run the experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([357, 648, 291, 420, 177, 456, 444,  83, 453, 354, 495, 575,  79,\n",
       "         23,  15, 381, 292, 275, 653, 314, 519, 137, 485, 483,  33, 662,\n",
       "        257,   9,  22, 543, 221, 404, 684, 334,  84, 335, 247, 582, 620,\n",
       "        203, 196, 660, 327, 399,  93, 587, 294, 265, 375, 184, 636, 512,\n",
       "        153,  75, 332,  68, 615, 188, 236,  88, 590, 117, 125, 571, 238,\n",
       "          0, 691, 530, 630, 608, 278, 116, 228, 697, 319, 274, 692, 144,\n",
       "        382, 426, 631, 500, 268, 465,  46, 261, 195, 698, 583, 107, 462,\n",
       "        609, 531, 100, 350, 624, 333, 179, 304, 349, 149, 124, 551, 605,\n",
       "        185, 428, 558, 689, 344, 644, 142, 141, 393, 320,  19, 172, 632,\n",
       "        312, 650,  12, 305,  25, 518, 169, 479, 411, 245, 298, 434, 272,\n",
       "        154, 126, 538, 341, 287, 113, 367, 173, 355,  57, 443, 222, 280,\n",
       "         17, 405, 322, 255, 417, 669, 190, 439, 616, 490,  94, 180, 301,\n",
       "        641, 511, 642, 451, 429,   5, 685,  45, 398, 525, 171,  16,  48,\n",
       "        675, 639,   3, 449, 412, 316, 643, 283, 581, 285, 677, 225,  26,\n",
       "        547, 263,  50, 364, 229,  37, 157, 237, 670, 374, 370, 175, 591,\n",
       "        480, 513, 194, 593, 601, 425, 445, 448, 674, 580, 599,  67, 534,\n",
       "        168, 447, 162, 309, 193, 478, 365, 383, 629, 535, 152, 488, 497,\n",
       "        226, 457, 557, 103, 421, 678, 527,  74, 115, 407, 673, 119,  53,\n",
       "        151, 403, 658, 207, 687, 487, 468, 537,   8, 572,  36, 452, 139,\n",
       "        253, 303, 523, 526, 368,  59, 111, 597, 503, 493, 262, 586, 297,\n",
       "        414, 150, 433, 576, 440, 266, 607, 359, 619,  38, 127, 423, 416,\n",
       "        307, 198, 351, 494, 146, 450, 647, 522, 419, 442, 621, 147, 585,\n",
       "        348, 463, 325, 186, 123, 602,  96, 143, 239, 394, 469, 197,  97,\n",
       "        371, 324, 279, 293, 400, 122, 183, 202, 438, 246, 415, 618, 129,\n",
       "        402, 549, 541, 219, 634, 529, 637, 536, 386, 676, 509, 267, 441,\n",
       "        496, 112, 232, 606, 373, 233, 550, 317, 410, 623, 358, 258, 282,\n",
       "        376, 384, 224, 683, 568, 472, 347, 505, 688, 645, 628, 594, 556,\n",
       "         85, 242, 159, 524,  35, 540, 170, 596, 588, 657,  95, 563, 240,\n",
       "        574, 460, 553, 611, 206, 392, 397, 589, 217,   4, 622, 546,  98,\n",
       "        573, 406, 502,  47,  32, 200, 134,  27, 613, 230, 489, 378, 288,\n",
       "        418, 391, 592, 498, 138,  62, 471, 128, 679, 520,  64,  14, 156,\n",
       "         40, 492, 379, 187, 216,  52, 337, 295, 251, 461, 455, 696, 269,\n",
       "        201, 161, 555, 401, 476, 105, 565, 389,   1, 652, 561,  80, 205,\n",
       "         34, 508, 427, 454, 366,  91, 339, 564, 345, 241,  13, 315, 600,\n",
       "        387, 273, 166, 693, 646, 484, 682, 504, 243, 566, 562, 189, 475,\n",
       "        510,  58, 474, 560, 252,  21, 313, 459, 160, 276, 191, 385, 413,\n",
       "        491, 343, 308, 661, 130, 663,  99, 372,  87, 458, 330, 214, 466,\n",
       "        121, 614,  20,  71, 106, 270, 435, 102]),\n",
       " array([158, 499, 396, 155, 321, 212, 234, 289, 300, 356, 672, 328, 199,\n",
       "         78, 598, 569, 446, 506, 626, 603, 360, 338, 668, 290, 284, 331,\n",
       "        477,  54, 248, 223, 133, 640, 136, 109, 181, 432, 554, 482, 516,\n",
       "        132, 176,  72, 254, 577, 649, 595, 666, 352,  76, 148, 346,  90,\n",
       "        681,  10,  63, 635, 656, 174, 256, 667,  31, 369, 570,  77, 532,\n",
       "        548, 211,  55, 135, 671, 340,   2, 227,  81, 473, 694, 665, 604,\n",
       "        120, 311, 204, 244, 686, 271, 131, 680,  60, 310,  30,  69, 651,\n",
       "        390,  44, 625,  70, 515, 654, 249, 209, 165, 470, 164, 507, 323,\n",
       "         65, 409,  49, 118, 192,  39, 259, 422,   6, 101, 542, 299, 395,\n",
       "        501, 318, 145, 486, 353, 208, 695, 361,  86, 664, 481, 633,  41,\n",
       "        108, 690,  56, 424, 514,  24, 218, 431, 281, 110,  82,  51, 220,\n",
       "        559, 544, 302, 552, 215, 235,  18, 250, 260, 430, 264,  61, 213,\n",
       "        377,  29, 182, 306, 388, 329, 437, 296, 584, 342, 436, 579, 326,\n",
       "        362, 617, 578, 231, 336, 655, 163, 286, 612, 517, 464, 277, 408,\n",
       "        104, 114, 627, 545, 467,  92,   7,  89, 528, 380, 521, 539, 363,\n",
       "        638, 140,  28,  43,  42,  73, 167, 210, 610,  66,  11, 659, 567,\n",
       "        178, 533]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "# another way of set test size is: train_test_split\n",
    "tr, te = next(ShuffleSplit(test_size=0.3, random_state=42).split(df))\n",
    "tr, te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clump_Thickness                AvgCE=0.335747286 w=0.826808279\n",
      "Uniformity_of_Cell_Size        AvgCE=0.176748276 w=1.515755629\n",
      "Uniformity_of_Cell_Shape       AvgCE=0.217456999 w=1.535220556\n",
      "Marginal_Adhesion              AvgCE=0.300066855 w=1.024555296\n",
      "Single_Epithelial_Cell_Size    AvgCE=0.350178198 w=1.527215223\n",
      "Bare_Nuclei                    AvgCE=0.311173420 w=1.008497031\n",
      "Bland_Chromatin                AvgCE=0.306641746 w=1.453926694\n",
      "Normal_Nucleoli                AvgCE=0.362623274 w=1.024082073\n",
      "Mitoses                        AvgCE=0.491826787 w=1.562289264\n"
     ]
    }
   ],
   "source": [
    "for column in names[1:-1]:\n",
    "    se = df[column]\n",
    "    x = (se - se.mean()).values # input vector\n",
    "    cl = LogisticRegression(fit_intercept=False, C=1e12) # define model\n",
    "    X = x.reshape((-1,1))\n",
    "    cl.fit(X[tr], y[tr])                                 # train model (on training set)\n",
    "    w = cl.coef_[0,0]                                    # extract moddel parameter\n",
    "    yhat = cl.predict_proba(X)[:,1]                      # make probability prediction\n",
    "    ace = log_loss(y[te], yhat[te])                      # compute average cross entropy (on test set)\n",
    "    \n",
    "    print(f'{column:30} AvgCE={ace:.9f} w={w:.9f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Logistic Regression\n",
    "\n",
    "The previous approach can be generalized to allows multiple input features.\n",
    "\n",
    "- model's prediction: $\\hat{y} = \\sigma(Xw)$<br>\n",
    "- objective function: $CE(w) = -\\log(\\hat{y})^Ty - \\log(1 - \\hat{y})^T(1 - y)$<br>\n",
    "- gradient vector: $\\frac{d}{dw} CE(w) = X^T(\\hat{y} - y)$<br>\n",
    "- Hessian matrix: $\\left(\\frac{d}{dw}\\right)^2 CE(w) = X^T \\mathrm{diag}\\left(\\hat{y}(1 - \\hat{y})\\right) X$\n",
    "- Newton-step: $w_{\\mathrm{new}} = w - \\left[\\left(\\frac{d}{dw}\\right)^2 CE(w)\\right]^{-1} \\left[\\frac{d}{dw} CE(w)\\right]$\n",
    "\n",
    "Similarly to linear regression, the bias term can be handled by introducing a constant 1 feature.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6**: Train a multivariate logistic regression model on the training set and measure its cross-entropy on the test set! Implement the training algorithm without using scikit-learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7**: Use scikit-learn for training the model and compare the results against the previous experiment's results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $K$-Fold Cross-Validation\n",
    "- Idea: Randomly split the data to $K$ roughly equal partitions and run $K$ experiments!\n",
    "- In the $i$-th experiment, partition $i$ is used as the test set and all other partitions as the training set.\n",
    "- In the end, the scores obtained from the $K$ experiments are averaged.\n",
    "- $K$-fold cross-validation is slower but more reliable than the simple train-test split.\n",
    "- In the *stratified* variant of the method, the same distribution of labels is enforced in every partition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../_img/cross_val.jpg\" width=\"350\" align=\"left\" style=\"opacity: 0.8\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8**: Replace the train-test split to 10-fold cross valiadtion and re-run the last experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
