{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/aldebaro/ai6g/blob/main/06_channel_compression_auto_encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc42cc4f",
   "metadata": {},
   "source": [
    "**Inteligência Artificial e Aprendizado de Máquina Aplicados a Redes 5G e 6G**.\n",
    "*Aldebaro Klautau* (UFPA). Minicurso 5 do SBrT - 25 de setembro de 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository if running in Colab and install all the dependencies\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "    import sys\n",
    "    import os\n",
    "    try:\n",
    "      !git clone https://github.com/aldebaro/ai6g.git\n",
    "    except:\n",
    "      print(\"ai6g is already in the contents\")\n",
    "    %cd ai6g\n",
    "    !ln -s /content/drive/MyDrive/ai6g_files/files_06_channel/* ./files_06_channel\n",
    "    !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inteligência Artificial e Aprendizado de Máquina Aplicados a Redes 5G e 6G**.\n",
    "*Aldebaro Klautau* (UFPA). Minicurso 5 do SBrT - 25 de setembro de 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90331bNe5Ucu"
   },
   "source": [
    "# Channel Compression with CSInet\n",
    "\n",
    "This notebook contains the cells responsible for training the autoencoder/CNN model called CsiNet, which is used for CSI compression. The original code is at https://github.com/sydney222/Python_CsiNet and the corresponding paper is:\n",
    "C. -K. Wen, W. -T. Shih and S. Jin, \"Deep Learning for Massive MIMO CSI Feedback,\" in IEEE Wireless Communications Letters, vol. 7, no. 5, pp. 748-751, Oct. 2018, doi: 10.1109/LWC.2018.2818160."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborators\n",
    "- *Lucas Damasceno* - M.Sc. student in Electrical Engineering (UFPA) | Researcher at LASSE - Telecommunications, Automation and Electronics R&D Center\n",
    "- *Marcos Davi* - M.Sc. student in Electrical Engineering (UFPA) | Researcher at LASSE - Telecommunications, Automation and Electronics R&D Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2erDuVef6_KO"
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Dense, BatchNormalization, Reshape, Conv2D, add, LeakyReLU\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.callbacks import TensorBoard, Callback\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqXCkcfo7OPL"
   },
   "outputs": [],
   "source": [
    "# Set image and network params\n",
    "envir = 'indoor' #'indoor' or 'outdoor'\n",
    "\n",
    "# Using TensorFlow with CPU or GPU\n",
    "GPU_Availability = 0 # 0 for CPU or 1 for GPU\n",
    "\n",
    "# Image params\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "img_channels = 2 \n",
    "img_total = img_height*img_width*img_channels\n",
    "\n",
    "# Network params\n",
    "residual_num = 1 #original value = 2\n",
    "#compress rate=1/4->dim.=512, compress rate=1/16->dim.=128, compress rate=1/32->dim.=64, compress rate=1/64->dim.=32\n",
    "encoded_dim = 32 #original value = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mnOkmZjU7RI6"
   },
   "outputs": [],
   "source": [
    "# Build the autoencoder model (CNN model) of CsiNet\n",
    "if GPU_Availability == 0:\n",
    "    dataFormat = 'channels_last'\n",
    "    reshapeFormat = [img_height, img_width, img_channels]\n",
    "else:\n",
    "    dataFormat = 'channels_first'\n",
    "    reshapeFormat = [img_channels, img_height, img_width]\n",
    "\n",
    "def residual_network(x, residual_num, encoded_dim):\n",
    "  def add_common_layers(y):\n",
    "    y = BatchNormalization()(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    \n",
    "    return y\n",
    "  \n",
    "  def residual_block_decoded(y):\n",
    "    shortcut = y\n",
    "    y = Conv2D(8, kernel_size=(3, 3), padding='same', data_format=dataFormat)(y)\n",
    "    y = add_common_layers(y)\n",
    "    \n",
    "    y = Conv2D(16, kernel_size=(3, 3), padding='same', data_format=dataFormat)(y)\n",
    "    y = add_common_layers(y)\n",
    "    \n",
    "    y = Conv2D(2, kernel_size=(3, 3), padding='same', data_format=dataFormat)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "\n",
    "    y = add([shortcut, y])\n",
    "    y = LeakyReLU()(y)\n",
    "\n",
    "    return y\n",
    "  \n",
    "  x = Conv2D(2, (3, 3), padding='same', data_format=dataFormat)(x)\n",
    "  x = add_common_layers(x)\n",
    "  \n",
    "  x = Reshape((img_total,))(x)\n",
    "  encoded = Dense(encoded_dim, activation='linear')(x)\n",
    "  \n",
    "  x = Dense(img_total, activation='linear')(encoded)\n",
    "  x = Reshape((reshapeFormat[0], reshapeFormat[1], reshapeFormat[2],))(x)\n",
    "  for i in range(residual_num):\n",
    "    x = residual_block_decoded(x)\n",
    "  \n",
    "  x = Conv2D(2, (3, 3), activation='sigmoid', padding='same', data_format=dataFormat)(x)\n",
    "  \n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H8DnkqPe8IXw"
   },
   "outputs": [],
   "source": [
    "# Set autoencoder model params and display the network model\n",
    "image_tensor = Input(shape=(reshapeFormat[0], reshapeFormat[1], reshapeFormat[2]))\n",
    "network_output = residual_network(image_tensor, residual_num, encoded_dim)\n",
    "autoencoder = Model(inputs=[image_tensor], outputs=[network_output])\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "print(autoencoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "meKKoN-f8Z80"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "mat = sio.loadmat('./files_06_channel/data/DATA_Htrainin_10k.mat') \n",
    "x_train = mat['HT'] # array\n",
    "mat = sio.loadmat('./files_06_channel/data/DATA_Hvalin_3k.mat')\n",
    "x_val = mat['HT'] # array\n",
    "mat = sio.loadmat('./files_06_channel/data/DATA_Htestin_2k.mat')\n",
    "x_test = mat['HT'] # array\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train = np.reshape(x_train, (len(x_train), reshapeFormat[0], reshapeFormat[1], reshapeFormat[2]))\n",
    "x_val = np.reshape(x_val, (len(x_val), reshapeFormat[0], reshapeFormat[1], reshapeFormat[2]))\n",
    "x_test = np.reshape(x_test, (len(x_test), reshapeFormat[0], reshapeFormat[1], reshapeFormat[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qm9CimNI9h4c"
   },
   "outputs": [],
   "source": [
    "# Create a class to save the loss history of the model\n",
    "class LossHistory(Callback):\n",
    "  def on_train_begin(self, logs={}):\n",
    "    self.losses_train = []\n",
    "    self.losses_val = []\n",
    "  \n",
    "  def on_batch_end(self, batch, logs={}):\n",
    "    self.losses_train.append(logs.get('loss'))    \n",
    "    \n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    self.losses_val.append(logs.get('val_loss'))\n",
    "\n",
    "history = LossHistory()\n",
    "file = 'CsiNet_'+(envir)+'_dim'+str(encoded_dim)+time.strftime('_%m_%d')\n",
    "path = './files_06_channel/result/TensorBoard_%s' %file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PVFELTj_9uKl"
   },
   "outputs": [],
   "source": [
    "# Train the model with the specified params and save the train loss and val loss in a csv file\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=10, #original value = 1000\n",
    "                batch_size=20, #original value = 200\n",
    "                shuffle=True,\n",
    "                validation_data=(x_val, x_val),\n",
    "                callbacks=[history,\n",
    "                           TensorBoard(log_dir = path)])\n",
    "\n",
    "filename = './files_06_channel/result/trainloss_%s.csv'%file\n",
    "loss_history = np.array(history.losses_train)\n",
    "np.savetxt(filename, loss_history, delimiter=\",\")\n",
    "\n",
    "filename = './files_06_channel/result/valloss_%s.csv'%file\n",
    "loss_history = np.array(history.losses_val)\n",
    "np.savetxt(filename, loss_history, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3jnfm6hJ-zpt"
   },
   "outputs": [],
   "source": [
    "# Testing data\n",
    "tStart = time.time()\n",
    "x_hat = autoencoder.predict(x_test)\n",
    "tEnd = time.time()\n",
    "print (\"It cost %f sec\" % ((tEnd - tStart)/x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJcp8f_5--Zp"
   },
   "outputs": [],
   "source": [
    "# Calculating the NMSE and rho\n",
    "mat = sio.loadmat('./files_06_channel/data/DATA_HtestFin_all_2k.mat')\n",
    "X_test = mat['HF_all']\n",
    "\n",
    "x_test = np.reshape(x_test, (len(x_test), img_channels, img_height, img_width))\n",
    "x_hat = np.reshape(x_hat, (len(x_hat), img_channels, img_height, img_width))\n",
    "\n",
    "X_test = np.reshape(X_test, (len(X_test), img_height, 125))\n",
    "\n",
    "x_test_real = np.reshape(x_test[:, 0, :, :], (len(x_test), -1))\n",
    "x_test_imag = np.reshape(x_test[:, 1, :, :], (len(x_test), -1))\n",
    "x_test_C = x_test_real-0.5 + 1j*(x_test_imag-0.5)\n",
    "\n",
    "x_hat_real = np.reshape(x_hat[:, 0, :, :], (len(x_hat), -1))\n",
    "x_hat_imag = np.reshape(x_hat[:, 1, :, :], (len(x_hat), -1))\n",
    "x_hat_C = x_hat_real-0.5 + 1j*(x_hat_imag-0.5)\n",
    "\n",
    "x_hat_F = np.reshape(x_hat_C, (len(x_hat_C), img_height, img_width))\n",
    "X_hat = np.fft.fft(np.concatenate((x_hat_F, np.zeros((len(x_hat_C), img_height, 257-img_width))), axis=2), axis=2)\n",
    "X_hat = X_hat[:, :, 0:125]\n",
    "\n",
    "n1 = np.sqrt(np.sum(np.conj(X_test)*X_test, axis=1))\n",
    "n1 = np.real(n1) # cast to real given that the imaginary part is zero\n",
    "n1 = n1.astype('float64')\n",
    "\n",
    "n2 = np.sqrt(np.sum(np.conj(X_hat)*X_hat, axis=1))\n",
    "n2 = np.real(n2) # cast to real given that the imaginary part is zero\n",
    "n2 = n2.astype('float64')\n",
    "\n",
    "aa = abs(np.sum(np.conj(X_test)*X_hat, axis=1))\n",
    "rho = np.mean(aa/(n1*n2), axis=1)\n",
    "X_hat = np.reshape(X_hat, (len(X_hat), -1))\n",
    "X_test = np.reshape(X_test, (len(X_test), -1))\n",
    "power = np.sum(abs(x_test_C)**2, axis=1)\n",
    "power_d = np.sum(abs(X_hat)**2, axis=1)\n",
    "mse = np.sum(abs(x_test_C-x_hat_C)**2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y8k1F4iE_Pdw"
   },
   "outputs": [],
   "source": [
    "print(\"In \"+envir+\" environment\")\n",
    "print(\"When dimension is\", encoded_dim)\n",
    "print(\"NMSE is \", 10*math.log10(np.mean(mse/power)))\n",
    "print(\"Correlation is \", np.mean(rho))\n",
    "\n",
    "filename = \"./files_06_channel/result/decoded_%s.csv\"%file\n",
    "x_hat1 = np.reshape(x_hat, (len(x_hat), -1))\n",
    "np.savetxt(filename, x_hat1, delimiter=\",\")\n",
    "filename = \"./files_06_channel/result/rho_%s.csv\"%file\n",
    "np.savetxt(filename, rho, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2p7tvVn7_WeS"
   },
   "outputs": [],
   "source": [
    "# Display the original and reconstructed pseudo-gray plots of the magnitude of channel H\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "  # display original\n",
    "  ax = plt.subplot(2, n, i + 1 )\n",
    "  x_testplo = abs(x_test[i, 0, :, :]-0.5 + 1j*(x_test[i, 1, :, :]-0.5))\n",
    "  plt.imshow(np.max(np.max(x_testplo))-x_testplo.T)\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "  ax.invert_yaxis()\n",
    "  \n",
    "  # display reconstructed\n",
    "  ax = plt.subplot(2, n, i + 1 + n)\n",
    "  decoded_imgsplo = abs(x_hat[i, 0, :, :]-0.5\n",
    "                        + 1j*(x_hat[i, 1, :, :]-0.5))\n",
    "  plt.imshow(np.max(np.max(decoded_imgsplo))-decoded_imgsplo.T)\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "  ax.invert_yaxis()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TmfCljB0_9oE"
   },
   "outputs": [],
   "source": [
    "# Save the autoencoder model as JSON and the weights as HDF5 \n",
    "model_json = autoencoder.to_json()\n",
    "outfile = \"./files_06_channel/result/sbrt_model_%s.json\"%file\n",
    "with open(outfile, \"w\") as json_file:\n",
    "  json_file.write(model_json)\n",
    "outfile = \"./files_06_channel/result/sbrt_model_%s.h5\"%file\n",
    "autoencoder.save_weights(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e85753",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "- [Lucas Damasceno - LASSE/UFPA](https://github.com/LucasDamascenoS)\n",
    "- Marcos Davi - LASSE/UFPA"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.14 ('ai6g-xssCGMI2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "dac2514730ec6dd4fc1d04cb6927967d7376870f25ae7edf50b318831380a3e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
