{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/aldebaro/ai6g/blob/main/03_channel_estimation_hybrid_mimo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inteligência Artificial e Aprendizado de Máquina Aplicados a Redes 5G e 6G**.\n",
    "*Aldebaro Klautau* (UFPA). Minicurso 5 do SBrT - 25 de setembro de 2022.\n",
    "Authors: XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install and import all the Needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository if running in Colab and install all the dependencies\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "    import sys\n",
    "    import os\n",
    "    try:\n",
    "      !git clone https://github.com/aldebaro/ai6g.git\n",
    "    except:\n",
    "      print(\"ai6g is already in the contents\")\n",
    "    %cd ai6g\n",
    "    !ln -s /content/drive/MyDrive/ai6g_files/files_03_channel/* ./files_03_channel\n",
    "    !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "import h5py \n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Reshape,\n",
    "    Conv2D,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    BatchNormalization,\n",
    ")\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FILES={\n",
    "    1:\"./files_03_channel/Pilots_SNR_(-5dB)_64x16(80pilots)_single_sub.hdf5\",\n",
    "    2:\"./files_03_channel/Pilots_SNR_(-5dB)_8x4(80pilots)_single_sub.hdf5\",\n",
    "    3:\"./files_03_channel/Pilots_SNR_(0dB)_8x4(80pilots)_single_sub.hdf5\",\n",
    "    \"64x16\":\"./files_03_channel/Channels_64x16_single_sub.hdf5\",\n",
    "    \"8x4\":\"./files_03_channel/Channels_8x4_single_sub.hdf5\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the following values according to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOSEN_DATASET = 2\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50 #original value 1000\n",
    "\n",
    "\n",
    "# Change these values acording to the dataset\n",
    "NR = 8 \n",
    "NT = 4 \n",
    "LR = 4 \n",
    "CHANNELS_USED_TRAIN = 9000\n",
    "SUBCARIERS_USED = 1\n",
    "TOTAL_CHANNELS = 10000\n",
    "NUM_SYM_PILOTS = 80\n",
    "CHANNELS_USED_TEST = TOTAL_CHANNELS - CHANNELS_USED_TRAIN\n",
    "\n",
    "trained_model = \"./files_03_channel/outputs/model.h5\" #output file with neural net model\n",
    "\n",
    "input_shape = (NUM_SYM_PILOTS * LR, SUBCARIERS_USED)\n",
    "output_shape = (NR, NT, SUBCARIERS_USED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECTING THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CHOSEN_DATASET == 1:\n",
    "    CHOSEN_CHANNELS = FILES[\"64x16\"]\n",
    "elif CHOSEN_DATASET > 1 and CHOSEN_DATASET <=3:\n",
    "    CHOSEN_CHANNELS = FILES[\"8x4\"]\n",
    "\n",
    "\n",
    "# Directory of the Channels Matrix file\n",
    "CHANNELS_FILE = h5py.File(CHOSEN_CHANNELS, \"r\")\n",
    "\n",
    "\n",
    "# Directory of the Pilots Matrix file\n",
    "PILOTS_FILE = h5py.File(FILES[CHOSEN_DATASET], \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will be used as a metric in keras to calculate the NMSE(Normalized Mean Squared Error) for each train or validation example that will be iterated in the training process, providing clear metrics to the whole process and enabling the use of early_stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring the function to calculate NMSE for each batch\n",
    "def NMSEtrainComplex(y_true, y_pred):\n",
    "    sub = y_pred[:, :, :] - y_true[:, :, :]\n",
    "    H_k = y_true[:, :, :]\n",
    "    nmse = tf.norm(sub, ord=\"fro\", axis=(1, 2)) ** 2\n",
    "    den = tf.norm(H_k, ord=\"fro\", axis=(1, 2)) ** 2\n",
    "\n",
    "    result = (nmse / den)\n",
    "\n",
    "    return 10*tf.experimental.numpy.log10(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the NN model will be crated, a chain of Dense layers is being used with relu activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_6 (Flatten)         (None, 320)               0         \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 320)              1280      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 512)               164352    \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 32)                16416     \n",
      "                                                                 \n",
      " reshape_6 (Reshape)         (None, 8, 4, 1)           0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 446,752\n",
      "Trainable params: 445,088\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense((512), activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense((512), activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "#disable the layers below to save computational cost\n",
    "#model.add(Dense((512), activation=\"relu\"))\n",
    "#model.add(Dropout(0.1))\n",
    "#model.add(Dense((512), activation=\"relu\"))\n",
    "#model.add(Dropout(0.1))\n",
    "#model.add(Dense((512), activation=\"relu\"))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(np.prod(output_shape), activation=\"linear\"))\n",
    "model.add(Reshape(output_shape))\n",
    "model.compile(\n",
    "    loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[NMSEtrainComplex]\n",
    "    )\n",
    "print(model.summary()) #show the network topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.7860 - NMSEtrainComplex: 0.6141 - val_loss: 0.3159 - val_NMSEtrainComplex: -3.0464 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3653 - NMSEtrainComplex: -2.3629 - val_loss: 0.2584 - val_NMSEtrainComplex: -4.0090 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.2890 - NMSEtrainComplex: -3.4071 - val_loss: 0.2401 - val_NMSEtrainComplex: -4.3724 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.2544 - NMSEtrainComplex: -3.9940 - val_loss: 0.2317 - val_NMSEtrainComplex: -4.5368 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.2350 - NMSEtrainComplex: -4.3519 - val_loss: 0.2242 - val_NMSEtrainComplex: -4.6522 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.2226 - NMSEtrainComplex: -4.5813 - val_loss: 0.2215 - val_NMSEtrainComplex: -4.7028 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.2119 - NMSEtrainComplex: -4.7964 - val_loss: 0.2169 - val_NMSEtrainComplex: -4.7995 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.2031 - NMSEtrainComplex: -4.9812 - val_loss: 0.2144 - val_NMSEtrainComplex: -4.9075 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.1944 - NMSEtrainComplex: -5.1882 - val_loss: 0.2082 - val_NMSEtrainComplex: -4.9916 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.1861 - NMSEtrainComplex: -5.3721 - val_loss: 0.2054 - val_NMSEtrainComplex: -5.0971 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.1788 - NMSEtrainComplex: -5.5573 - val_loss: 0.1999 - val_NMSEtrainComplex: -5.2506 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.1720 - NMSEtrainComplex: -5.7327 - val_loss: 0.1970 - val_NMSEtrainComplex: -5.3120 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.1640 - NMSEtrainComplex: -5.9550 - val_loss: 0.1902 - val_NMSEtrainComplex: -5.4926 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.1580 - NMSEtrainComplex: -6.1260 - val_loss: 0.1853 - val_NMSEtrainComplex: -5.5986 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.1519 - NMSEtrainComplex: -6.2979 - val_loss: 0.1816 - val_NMSEtrainComplex: -5.7225 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.1481 - NMSEtrainComplex: -6.4251 - val_loss: 0.1785 - val_NMSEtrainComplex: -5.8023 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.1416 - NMSEtrainComplex: -6.6061 - val_loss: 0.1728 - val_NMSEtrainComplex: -6.0044 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.1363 - NMSEtrainComplex: -6.7888 - val_loss: 0.1709 - val_NMSEtrainComplex: -6.0290 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.1338 - NMSEtrainComplex: -6.8618 - val_loss: 0.1692 - val_NMSEtrainComplex: -6.0909 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.1293 - NMSEtrainComplex: -7.0273 - val_loss: 0.1683 - val_NMSEtrainComplex: -6.1188 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.1277 - NMSEtrainComplex: -7.0712 - val_loss: 0.1646 - val_NMSEtrainComplex: -6.2451 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.1227 - NMSEtrainComplex: -7.2484 - val_loss: 0.1628 - val_NMSEtrainComplex: -6.2928 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.1203 - NMSEtrainComplex: -7.3427 - val_loss: 0.1611 - val_NMSEtrainComplex: -6.3343 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.1181 - NMSEtrainComplex: -7.4098 - val_loss: 0.1609 - val_NMSEtrainComplex: -6.3617 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.1166 - NMSEtrainComplex: -7.4801 - val_loss: 0.1611 - val_NMSEtrainComplex: -6.3594 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.1135 - NMSEtrainComplex: -7.5942 - val_loss: 0.1599 - val_NMSEtrainComplex: -6.4095 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.1122 - NMSEtrainComplex: -7.6554 - val_loss: 0.1592 - val_NMSEtrainComplex: -6.4346 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.1096 - NMSEtrainComplex: -7.7403 - val_loss: 0.1586 - val_NMSEtrainComplex: -6.4538 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "220/225 [============================>.] - ETA: 0s - loss: 0.1105 - NMSEtrainComplex: -7.7111\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.1106 - NMSEtrainComplex: -7.7078 - val_loss: 0.1605 - val_NMSEtrainComplex: -6.4445 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.1017 - NMSEtrainComplex: -8.0808 - val_loss: 0.1531 - val_NMSEtrainComplex: -6.6824 - lr: 5.0000e-04\n",
      "Epoch 31/50\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.0985 - NMSEtrainComplex: -8.2134 - val_loss: 0.1514 - val_NMSEtrainComplex: -6.7019 - lr: 5.0000e-04\n",
      "Epoch 32/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.0966 - NMSEtrainComplex: -8.2861 - val_loss: 0.1523 - val_NMSEtrainComplex: -6.7093 - lr: 5.0000e-04\n",
      "Epoch 33/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.0958 - NMSEtrainComplex: -8.3269 - val_loss: 0.1526 - val_NMSEtrainComplex: -6.6784 - lr: 5.0000e-04\n",
      "Epoch 34/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.0930 - NMSEtrainComplex: -8.4617 - val_loss: 0.1518 - val_NMSEtrainComplex: -6.6941 - lr: 5.0000e-04\n",
      "Epoch 35/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.0928 - NMSEtrainComplex: -8.4580 - val_loss: 0.1504 - val_NMSEtrainComplex: -6.7250 - lr: 5.0000e-04\n",
      "Epoch 36/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.0930 - NMSEtrainComplex: -8.4508 - val_loss: 0.1521 - val_NMSEtrainComplex: -6.6804 - lr: 5.0000e-04\n",
      "Epoch 37/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.0913 - NMSEtrainComplex: -8.5377 - val_loss: 0.1523 - val_NMSEtrainComplex: -6.6743 - lr: 5.0000e-04\n",
      "Epoch 38/50\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.0902 - NMSEtrainComplex: -8.5910 - val_loss: 0.1526 - val_NMSEtrainComplex: -6.6584 - lr: 5.0000e-04\n",
      "Epoch 39/50\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.0906 - NMSEtrainComplex: -8.5661 - val_loss: 0.1518 - val_NMSEtrainComplex: -6.6953 - lr: 5.0000e-04\n",
      "Epoch 40/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.0899 - NMSEtrainComplex: -8.6026 - val_loss: 0.1523 - val_NMSEtrainComplex: -6.6820 - lr: 5.0000e-04\n",
      "Epoch 41/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.0889 - NMSEtrainComplex: -8.6397 - val_loss: 0.1527 - val_NMSEtrainComplex: -6.6781 - lr: 5.0000e-04\n",
      "Epoch 42/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.0888 - NMSEtrainComplex: -8.6546 - val_loss: 0.1524 - val_NMSEtrainComplex: -6.6934 - lr: 5.0000e-04\n",
      "Epoch 43/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.0873 - NMSEtrainComplex: -8.7354 - val_loss: 0.1526 - val_NMSEtrainComplex: -6.6928 - lr: 5.0000e-04\n",
      "Epoch 44/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.0889 - NMSEtrainComplex: -8.6494 - val_loss: 0.1523 - val_NMSEtrainComplex: -6.6962 - lr: 5.0000e-04\n",
      "Epoch 45/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.0882 - NMSEtrainComplex: -8.6691 - val_loss: 0.1523 - val_NMSEtrainComplex: -6.7018 - lr: 5.0000e-04\n",
      "Epoch 46/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.0868 - NMSEtrainComplex: -8.7460 - val_loss: 0.1522 - val_NMSEtrainComplex: -6.6843 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.0865 - NMSEtrainComplex: -8.7635 - val_loss: 0.1527 - val_NMSEtrainComplex: -6.6682 - lr: 5.0000e-04\n",
      "Epoch 48/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.0850 - NMSEtrainComplex: -8.8390 - val_loss: 0.1522 - val_NMSEtrainComplex: -6.6911 - lr: 5.0000e-04\n",
      "Epoch 49/50\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.0870 - NMSEtrainComplex: -8.7328 - val_loss: 0.1529 - val_NMSEtrainComplex: -6.6796 - lr: 5.0000e-04\n",
      "Epoch 50/50\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.0854 - NMSEtrainComplex: -8.8210 - val_loss: 0.1523 - val_NMSEtrainComplex: -6.7056 - lr: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_inputData = PILOTS_FILE[\"pilots\"][:CHANNELS_USED_TRAIN, :, :SUBCARIERS_USED]\n",
    "training_outputData = CHANNELS_FILE[\"channels\"][:CHANNELS_USED_TRAIN, :, :, :SUBCARIERS_USED]\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "        training_inputData,\n",
    "        training_outputData,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=1,\n",
    "        shuffle=True,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[\n",
    "            EarlyStopping(\n",
    "                monitor=\"val_NMSEtrainComplex\",\n",
    "                min_delta=5e-3,\n",
    "                patience=40,\n",
    "                restore_best_weights=True,\n",
    "            ),\n",
    "            ReduceLROnPlateau(\n",
    "                factor=0.5,\n",
    "                min_delta=5e-2,\n",
    "                patience=20,\n",
    "                cooldown=5,\n",
    "                verbose=1,\n",
    "                min_lr=1e-7,\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "model.save(trained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading trained model from ./files_03_channel/outputs/model.h5\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1456 - NMSEtrainComplex: -6.7385\n",
      "Loss and NMSE (in dB): [0.1455831229686737, -6.738473892211914]\n"
     ]
    }
   ],
   "source": [
    "#need to inform about the custom metric, to allow it to be incorporated in the file\n",
    "print(\"Reading trained model from\", trained_model)\n",
    "mlModel = load_model(trained_model, custom_objects={\"NMSEtrainComplex\": NMSEtrainComplex})\n",
    "\n",
    "TEST_INPUT = PILOTS_FILE[\"pilots\"][CHANNELS_USED_TRAIN:, :, :SUBCARIERS_USED]\n",
    "TEST_OUTPUT = CHANNELS_FILE[\"channels\"][CHANNELS_USED_TRAIN:, :, :, :SUBCARIERS_USED]\n",
    "\n",
    "results = mlModel.evaluate(TEST_INPUT,TEST_OUTPUT)\n",
    "print(\"Loss and NMSE (in dB):\", results)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e85753",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "- Prof. Francisco Muller - LASSE/UFPA\n",
    "- Daniel Oliveira - LASSE/UFPA\n",
    "- Claudio Mello - LASSE/UFPA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('3.8.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "5aaf80bf5bb851baa857fc3e2a05055a4723060c18483edce1107b583200cb68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
