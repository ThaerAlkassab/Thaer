{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc2b9442",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/aldebaro/ai6g/blob/main/10_channel_estimation_using_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc42cc4f",
   "metadata": {},
   "source": [
    "**Inteligência Artificial e Aprendizado de Máquina Aplicados a Redes 5G e 6G**.\n",
    "*Aldebaro Klautau* (UFPA). Minicurso 5 do SBrT - 25 de setembro de 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd70863d",
   "metadata": {},
   "source": [
    "Original code from https://github.com/YudiDong/Channel_Estimation_cGAN/\n",
    "This repository above describes the implementation of the paper: \n",
    "Yudi Dong, Huaxia Wang, and Yu-Dong Yao, “Channel Estimation for One-Bit Multiuser Massive MIMO Using Conditional GAN.” ArXiv:2006.11435 [Eess], June 2020. arXiv.org, http://arxiv.org/abs/2006.11435.\n",
    "IEEE Communications Letters, 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7b0527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository if running in Colab and install all the dependencies\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "    import sys\n",
    "    import os\n",
    "    try:\n",
    "      !git clone https://github.com/aldebaro/ai6g.git\n",
    "    except:\n",
    "      print(\"ai6g is already in the contents\")\n",
    "    %cd ai6g\n",
    "    !ln -s /content/drive/MyDrive/ai6g_files/files_10_channel/* ./files_10_channel\n",
    "    !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf9bd068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from files_10_channel.GAN.cGANGenerator import Generator\n",
    "from files_10_channel.GAN.cGANDiscriminator import Discriminator\n",
    "from files_10_channel.GAN.data_preprocess import load_image_train, load_image_test, load_image_test_y\n",
    "from tempfile import TemporaryFile\n",
    "from scipy.io import loadmat, savemat\n",
    "import datetime\n",
    "import h5py\n",
    "#import hdf5storage\n",
    "#import skfuzzy as fuzz\n",
    "from scipy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5021b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#plot inside Jupyter notebook\n",
    "#Read more at https://stackoverflow.com/questions/43027980/purpose-of-matplotlib-inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33e8cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Setting\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.enable_eager_execution(config=config)\n",
    "layers = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07295e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "#path = \"../Data_Generation/Gan_Data/Gan_0_dBIndoor2p4_64ant_32users_8pilot.mat\" #original path\n",
    "path = \"./files_10_channel/cgan_data/Gan_0_dBIndoor2p4_64ant_32users_8pilot.mat\"\n",
    "\n",
    "# batch = 1 produces good results on U-NET\n",
    "BATCH_SIZE = 1              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae2e0b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "# optimizer\n",
    "generator_optimizer = tf.compat.v1.train.AdamOptimizer(2e-4, beta1=0.5)\n",
    "discriminator_optimizer = tf.compat.v1.train.RMSPropOptimizer(2e-5)\n",
    "#discriminator_optimizer = tf.compat.v1.train.AdamOptimizer(2e-4, beta1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7760ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Average NMSE as Frobenius norms.\n",
    "Calculate for a 4D tensor such as\n",
    "(664, 64, 32, 2)\n",
    "by first converting the matrices into complex-valued matrices.\n",
    "Aldebaro, Sep. 2022\n",
    "'''\n",
    "def nmse_average(y_true, y_pred):\n",
    "    num_matrices, N, M, realimag = y_true.shape\n",
    "    assert(realimag == 2)\n",
    "    all_nmses = np.zeros(num_matrices,)\n",
    "    for i in range(num_matrices):\n",
    "        #convert to complex matrices\n",
    "        true_matrix = np.empty( (N,M), dtype=np.complex128)\n",
    "        true_matrix.real = y_true[i,:,:,0]\n",
    "        true_matrix.imag = y_true[i,:,:,1]\n",
    "\n",
    "        pred_matrix = np.empty( (N,M), dtype=np.complex128)\n",
    "        pred_matrix.real = y_pred[i,:,:,0]\n",
    "        pred_matrix.imag = y_pred[i,:,:,1]\n",
    "\n",
    "        error = true_matrix - pred_matrix\n",
    "        numerator = norm(error, ord='fro') ** 2\n",
    "        denominator = norm(true_matrix, ord='fro') ** 2\n",
    "        if denominator == 0 and numerator == 0:\n",
    "            all_nmses[i] = 0\n",
    "        else:\n",
    "            all_nmses[i] = numerator / denominator\n",
    "    return np.mean(all_nmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e38ada44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Discriminator loss:\n",
    "The discriminator loss function takes 2 inputs; real images, generated images\n",
    "real_loss is a sigmoid cross entropy loss of the real images and an array of ones(since the real images)\n",
    "generated_loss is a sigmoid cross entropy loss of the generated images and an array of zeros(since the fake images)\n",
    "Then the total_loss is the sum of real_loss and the generated_loss\n",
    "\"\"\"\n",
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    \"\"\"disc_real_output = [real_target]\n",
    "       disc_generated_output = [generated_target]\n",
    "    \"\"\"\n",
    "    real_loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf.ones_like(disc_real_output), logits=disc_real_output)  # label=1\n",
    "    generated_loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf.zeros_like(disc_generated_output), logits=disc_generated_output)  # label=0\n",
    "    total_disc_loss = tf.reduce_mean(real_loss) + tf.reduce_mean(generated_loss)\n",
    "    return total_disc_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a25af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generator loss:\n",
    "It is a sigmoid cross entropy loss of the generated images and an array of ones.\n",
    "The paper also includes L2 loss between the generated image and the target image.\n",
    "This allows the generated image to become structurally similar to the target image.\n",
    "The formula to calculate the total generator loss = gan_loss + LAMBDA * l2_loss, where LAMBDA = 100. \n",
    "This value was decided by the authors of the paper.\n",
    "\"\"\"\n",
    "def generator_loss(disc_generated_output, gen_output, target, l2_weight=100):\n",
    "    \"\"\"\n",
    "        disc_generated_output: output of Discriminator when input is from Generator\n",
    "        gen_output:  output of Generator (i.e., estimated H)\n",
    "        target:  target image\n",
    "        l2_weight: weight of L2 loss\n",
    "    \"\"\"\n",
    "    # GAN loss\n",
    "    gen_loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf.ones_like(disc_generated_output), logits=disc_generated_output)\n",
    "    # L2 loss\n",
    "    l2_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "    total_gen_loss = tf.reduce_mean(gen_loss) + l2_weight * l2_loss\n",
    "    return total_gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0c1877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generated_image(model, test_input, tar, t=0):\n",
    "    \"\"\"Dispaly  the results of Generator\"\"\"\n",
    "    prediction = model(test_input)\n",
    "    #plt.figure(figsize=(15, 15))\n",
    "    display_list = [np.squeeze(test_input[:,:,:,0]), np.squeeze(tar[:,:,:,0]), np.squeeze(prediction[:,:,:,0])]\n",
    "    \n",
    "\n",
    "    title = ['Input Y', 'Target H', 'Prediction H']\n",
    "    \n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(display_list[i]) \n",
    "        plt.axis(\"off\")\n",
    "    plt.savefig(os.path.join(\"generated_img\", \"img_\"+str(t)+\".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f95307ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(input_image, target):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_output = generator(input_image)                      # input -> generated_target\n",
    "        disc_real_output = discriminator(target)  # [input, target] -> disc output\n",
    "        disc_generated_output = discriminator(gen_output)  # [input, generated_target] -> disc output\n",
    "        # print(\"*\", gen_output.shape, disc_real_output.shape, disc_generated_output.shape)\n",
    "\n",
    "        # calculate loss\n",
    "        gen_loss = generator_loss(disc_generated_output, gen_output, target)   # gen loss\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)  # disc loss\n",
    "\n",
    "    # gradient\n",
    "    generator_gradient = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    discriminator_gradient = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    # apply gradient\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradient, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradient, discriminator.trainable_variables))\n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93186162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    nm = []\n",
    "    ep = []\n",
    "    start_time = datetime.datetime.now()\n",
    "    for epoch in range(epochs):\n",
    "        print(\"-----\\nEPOCH:\", epoch)\n",
    "        # train\n",
    "        for bi, (target, input_image) in enumerate(load_image_train(path)):\n",
    "            elapsed_time = datetime.datetime.now() - start_time\n",
    "            gen_loss, disc_loss = train_step(input_image, target)\n",
    "            print(\"Batch/Epoch:\", bi, '/' , epoch, \", Generator loss:\", gen_loss.numpy(), \", Discriminator loss:\", disc_loss.numpy(), ', time:',  elapsed_time)\n",
    "            #AK\n",
    "            #if bi > 10:\n",
    "            #    break\n",
    "        # generated and see the progress\n",
    "        for bii, (tar, inp) in enumerate(load_image_test(path)):            \n",
    "            if bii == 100:\n",
    "                generated_image(generator, inp, tar, t=epoch+1  )\n",
    "\n",
    "        # save checkpoint\n",
    "        # if (epoch + 1) % 2 == 0:\n",
    "        ep.append(epoch + 1)\n",
    "        #generator.save_weights(os.path.join(BASE_PATH, \"weights/generator_\"+str(epoch)+\".h5\"))\n",
    "        #discriminator.save_weights(os.path.join(BASE_PATH, \"weights/discriminator_\"+str(epoch)+\".h5\"))\n",
    "        \n",
    "        realim, inpuim = load_image_test_y(path)   \n",
    "        prediction = generator(inpuim)\n",
    "        \n",
    "        #AK\n",
    "        #nm.append(fuzz.average_nmse(np.squeeze(realim), np.squeeze(prediction)))\n",
    "        nm.append(nmse_average(np.squeeze(realim), np.squeeze(prediction)))\n",
    "        \n",
    "        if epoch == epochs-1:\n",
    "            nmse_epoch = TemporaryFile()\n",
    "            np.save(nmse_epoch, nm)\n",
    "        \n",
    "        # Save the predicted Channel \n",
    "        matfiledata = {} # make a dictionary to store the MAT data in\n",
    "        matfiledata[u'predict_Gan_0_dB_Indoor2p4_64ant_32users_8pilot'] = np.array(prediction) # *** u prefix for variable name = unicode format, no issues thru Python 3.5; advise keeping u prefix indicator format based on feedback despite docs ***\n",
    "        #hdf5storage.write(matfiledata, '.', 'Results\\Eest_cGAN_'+str(epoch + 1)+'_0db_Indoor2p4_64ant_32users_8pilot.mat', matlab_compatible=True)\n",
    "        \n",
    "        if False:\n",
    "            plt.figure()\n",
    "            plt.plot(ep,nm,'^-r')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('NMSE')\n",
    "            plt.show();\n",
    "    \n",
    "    return nm, ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22ecdd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "EPOCH: 0\n",
      "Batch/Epoch: 0 / 0 , Generator loss: 60.316246 , Discriminator loss: 1.3874917 , time: 0:00:00.037897\n",
      "Batch/Epoch: 1 / 0 , Generator loss: 59.68959 , Discriminator loss: 1.387989 , time: 0:00:07.376702\n",
      "Batch/Epoch: 2 / 0 , Generator loss: 60.363815 , Discriminator loss: 1.3868561 , time: 0:00:07.539037\n",
      "Batch/Epoch: 3 / 0 , Generator loss: 58.72411 , Discriminator loss: 1.3867085 , time: 0:00:07.700752\n",
      "Batch/Epoch: 4 / 0 , Generator loss: 58.08365 , Discriminator loss: 1.387644 , time: 0:00:07.860328\n",
      "Batch/Epoch: 5 / 0 , Generator loss: 59.343224 , Discriminator loss: 1.3870995 , time: 0:00:08.021952\n",
      "Batch/Epoch: 6 / 0 , Generator loss: 58.43833 , Discriminator loss: 1.3877201 , time: 0:00:08.183464\n",
      "Batch/Epoch: 7 / 0 , Generator loss: 59.23421 , Discriminator loss: 1.3857973 , time: 0:00:08.344078\n",
      "Batch/Epoch: 8 / 0 , Generator loss: 60.30627 , Discriminator loss: 1.3870388 , time: 0:00:08.505603\n",
      "Batch/Epoch: 9 / 0 , Generator loss: 60.512455 , Discriminator loss: 1.3875512 , time: 0:00:08.666174\n",
      "Batch/Epoch: 10 / 0 , Generator loss: 59.898727 , Discriminator loss: 1.3863192 , time: 0:00:08.827773\n",
      "Batch/Epoch: 11 / 0 , Generator loss: 58.976105 , Discriminator loss: 1.3889389 , time: 0:00:08.988864\n",
      "Batch/Epoch: 12 / 0 , Generator loss: 59.421886 , Discriminator loss: 1.3882391 , time: 0:00:09.148438\n",
      "Batch/Epoch: 13 / 0 , Generator loss: 61.371605 , Discriminator loss: 1.3855559 , time: 0:00:09.306016\n",
      "Batch/Epoch: 14 / 0 , Generator loss: 61.15827 , Discriminator loss: 1.3849237 , time: 0:00:09.464719\n",
      "Batch/Epoch: 15 / 0 , Generator loss: 59.66848 , Discriminator loss: 1.3886843 , time: 0:00:09.622905\n",
      "Batch/Epoch: 16 / 0 , Generator loss: 59.5171 , Discriminator loss: 1.3862374 , time: 0:00:09.784272\n",
      "Batch/Epoch: 17 / 0 , Generator loss: 59.83838 , Discriminator loss: 1.3869855 , time: 0:00:09.943880\n",
      "Batch/Epoch: 18 / 0 , Generator loss: 61.78867 , Discriminator loss: 1.3875436 , time: 0:00:10.104415\n",
      "Batch/Epoch: 19 / 0 , Generator loss: 59.50407 , Discriminator loss: 1.3878398 , time: 0:00:10.264613\n",
      "Batch/Epoch: 20 / 0 , Generator loss: 59.004417 , Discriminator loss: 1.3875675 , time: 0:00:10.423327\n",
      "Batch/Epoch: 21 / 0 , Generator loss: 59.889923 , Discriminator loss: 1.3871269 , time: 0:00:10.579903\n",
      "Batch/Epoch: 22 / 0 , Generator loss: 61.38592 , Discriminator loss: 1.3874238 , time: 0:00:10.737483\n",
      "Batch/Epoch: 23 / 0 , Generator loss: 59.82069 , Discriminator loss: 1.3880529 , time: 0:00:10.894058\n",
      "Batch/Epoch: 24 / 0 , Generator loss: 58.570797 , Discriminator loss: 1.3872843 , time: 0:00:11.052652\n",
      "Batch/Epoch: 25 / 0 , Generator loss: 59.582973 , Discriminator loss: 1.3878791 , time: 0:00:11.214173\n",
      "Batch/Epoch: 26 / 0 , Generator loss: 59.45871 , Discriminator loss: 1.3860569 , time: 0:00:11.374744\n",
      "Batch/Epoch: 27 / 0 , Generator loss: 60.118393 , Discriminator loss: 1.3870597 , time: 0:00:11.535235\n",
      "Batch/Epoch: 28 / 0 , Generator loss: 58.918438 , Discriminator loss: 1.3885555 , time: 0:00:11.694221\n",
      "Batch/Epoch: 29 / 0 , Generator loss: 58.52426 , Discriminator loss: 1.3836539 , time: 0:00:11.853771\n",
      "Batch/Epoch: 30 / 0 , Generator loss: 56.60827 , Discriminator loss: 1.3873503 , time: 0:00:12.017837\n",
      "Batch/Epoch: 31 / 0 , Generator loss: 50.869747 , Discriminator loss: 1.385582 , time: 0:00:12.177066\n",
      "Batch/Epoch: 32 / 0 , Generator loss: 46.352005 , Discriminator loss: 1.3846133 , time: 0:00:12.335057\n",
      "Batch/Epoch: 33 / 0 , Generator loss: 35.470036 , Discriminator loss: 1.3875699 , time: 0:00:12.494635\n",
      "Batch/Epoch: 34 / 0 , Generator loss: 46.426556 , Discriminator loss: 1.3866725 , time: 0:00:12.699759\n",
      "Batch/Epoch: 35 / 0 , Generator loss: 42.02008 , Discriminator loss: 1.3889782 , time: 0:00:12.885294\n",
      "Batch/Epoch: 36 / 0 , Generator loss: 38.9463 , Discriminator loss: 1.3842714 , time: 0:00:13.043878\n",
      "Batch/Epoch: 37 / 0 , Generator loss: 38.8242 , Discriminator loss: 1.38586 , time: 0:00:13.202573\n",
      "Batch/Epoch: 38 / 0 , Generator loss: 38.936916 , Discriminator loss: 1.3859582 , time: 0:00:13.361412\n",
      "Batch/Epoch: 39 / 0 , Generator loss: 38.698635 , Discriminator loss: 1.3850601 , time: 0:00:13.520013\n",
      "Batch/Epoch: 40 / 0 , Generator loss: 39.962116 , Discriminator loss: 1.3858547 , time: 0:00:13.681202\n",
      "Batch/Epoch: 41 / 0 , Generator loss: 48.784187 , Discriminator loss: 1.3852439 , time: 0:00:13.842010\n",
      "Batch/Epoch: 42 / 0 , Generator loss: 36.48243 , Discriminator loss: 1.3865831 , time: 0:00:14.005228\n",
      "Batch/Epoch: 43 / 0 , Generator loss: 44.4398 , Discriminator loss: 1.3870032 , time: 0:00:14.227663\n",
      "Batch/Epoch: 44 / 0 , Generator loss: 38.236 , Discriminator loss: 1.3874588 , time: 0:00:14.389523\n",
      "Batch/Epoch: 45 / 0 , Generator loss: 37.427223 , Discriminator loss: 1.3854797 , time: 0:00:14.547102\n",
      "Batch/Epoch: 46 / 0 , Generator loss: 35.087593 , Discriminator loss: 1.3848107 , time: 0:00:14.707776\n",
      "Batch/Epoch: 47 / 0 , Generator loss: 34.922012 , Discriminator loss: 1.3858056 , time: 0:00:14.870341\n",
      "Batch/Epoch: 48 / 0 , Generator loss: 35.598606 , Discriminator loss: 1.3869028 , time: 0:00:15.030912\n",
      "Batch/Epoch: 49 / 0 , Generator loss: 36.646755 , Discriminator loss: 1.3857716 , time: 0:00:15.195473\n",
      "Batch/Epoch: 50 / 0 , Generator loss: 37.40044 , Discriminator loss: 1.3848021 , time: 0:00:15.365774\n",
      "Batch/Epoch: 51 / 0 , Generator loss: 38.38762 , Discriminator loss: 1.3863823 , time: 0:00:15.529611\n",
      "Batch/Epoch: 52 / 0 , Generator loss: 38.02865 , Discriminator loss: 1.3844483 , time: 0:00:15.695168\n",
      "Batch/Epoch: 53 / 0 , Generator loss: 32.361767 , Discriminator loss: 1.3847091 , time: 0:00:15.861097\n",
      "Batch/Epoch: 54 / 0 , Generator loss: 33.71776 , Discriminator loss: 1.3869796 , time: 0:00:16.023176\n",
      "Batch/Epoch: 55 / 0 , Generator loss: 32.131245 , Discriminator loss: 1.3885608 , time: 0:00:16.186698\n",
      "Batch/Epoch: 56 / 0 , Generator loss: 36.86092 , Discriminator loss: 1.385287 , time: 0:00:16.356250\n",
      "Batch/Epoch: 57 / 0 , Generator loss: 37.038277 , Discriminator loss: 1.3854861 , time: 0:00:16.523852\n",
      "Batch/Epoch: 58 / 0 , Generator loss: 38.58914 , Discriminator loss: 1.385359 , time: 0:00:16.682161\n",
      "Batch/Epoch: 59 / 0 , Generator loss: 33.305367 , Discriminator loss: 1.3852137 , time: 0:00:16.840889\n",
      "Batch/Epoch: 60 / 0 , Generator loss: 33.563538 , Discriminator loss: 1.3857734 , time: 0:00:17.000414\n",
      "Batch/Epoch: 61 / 0 , Generator loss: 34.421444 , Discriminator loss: 1.3862469 , time: 0:00:17.159777\n",
      "Batch/Epoch: 62 / 0 , Generator loss: 30.386328 , Discriminator loss: 1.3865178 , time: 0:00:17.319619\n",
      "Batch/Epoch: 63 / 0 , Generator loss: 33.119953 , Discriminator loss: 1.3874574 , time: 0:00:17.480724\n",
      "Batch/Epoch: 64 / 0 , Generator loss: 36.215252 , Discriminator loss: 1.3872238 , time: 0:00:17.685209\n",
      "Batch/Epoch: 65 / 0 , Generator loss: 34.42372 , Discriminator loss: 1.3864546 , time: 0:00:17.845566\n",
      "Batch/Epoch: 66 / 0 , Generator loss: 34.705578 , Discriminator loss: 1.3865008 , time: 0:00:18.004852\n",
      "Batch/Epoch: 67 / 0 , Generator loss: 42.320137 , Discriminator loss: 1.3853343 , time: 0:00:18.164855\n",
      "Batch/Epoch: 68 / 0 , Generator loss: 31.200083 , Discriminator loss: 1.3864908 , time: 0:00:18.330067\n",
      "Batch/Epoch: 69 / 0 , Generator loss: 37.628944 , Discriminator loss: 1.3866262 , time: 0:00:18.496224\n",
      "Batch/Epoch: 70 / 0 , Generator loss: 34.047768 , Discriminator loss: 1.3861563 , time: 0:00:18.660815\n",
      "Batch/Epoch: 71 / 0 , Generator loss: 28.875196 , Discriminator loss: 1.3856051 , time: 0:00:18.859259\n",
      "Batch/Epoch: 72 / 0 , Generator loss: 34.95453 , Discriminator loss: 1.3862216 , time: 0:00:19.017222\n",
      "Batch/Epoch: 73 / 0 , Generator loss: 35.314003 , Discriminator loss: 1.3867738 , time: 0:00:19.179127\n",
      "Batch/Epoch: 74 / 0 , Generator loss: 31.998463 , Discriminator loss: 1.3849459 , time: 0:00:19.338878\n",
      "Batch/Epoch: 75 / 0 , Generator loss: 32.66759 , Discriminator loss: 1.3853853 , time: 0:00:19.498504\n",
      "Batch/Epoch: 76 / 0 , Generator loss: 35.623173 , Discriminator loss: 1.3863397 , time: 0:00:19.658080\n",
      "Batch/Epoch: 77 / 0 , Generator loss: 31.093822 , Discriminator loss: 1.386617 , time: 0:00:19.816605\n",
      "Batch/Epoch: 78 / 0 , Generator loss: 32.602077 , Discriminator loss: 1.3861845 , time: 0:00:19.978031\n",
      "Batch/Epoch: 79 / 0 , Generator loss: 34.752205 , Discriminator loss: 1.3859055 , time: 0:00:20.138298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch/Epoch: 80 / 0 , Generator loss: 36.659016 , Discriminator loss: 1.3829944 , time: 0:00:20.296250\n",
      "Batch/Epoch: 81 / 0 , Generator loss: 36.10641 , Discriminator loss: 1.3851666 , time: 0:00:20.455155\n",
      "Batch/Epoch: 82 / 0 , Generator loss: 33.085648 , Discriminator loss: 1.3854561 , time: 0:00:20.614169\n",
      "Batch/Epoch: 83 / 0 , Generator loss: 35.08235 , Discriminator loss: 1.3845623 , time: 0:00:20.776236\n",
      "Batch/Epoch: 84 / 0 , Generator loss: 33.60189 , Discriminator loss: 1.385317 , time: 0:00:20.935378\n",
      "Batch/Epoch: 85 / 0 , Generator loss: 31.869806 , Discriminator loss: 1.3844669 , time: 0:00:21.097236\n",
      "Batch/Epoch: 86 / 0 , Generator loss: 30.237343 , Discriminator loss: 1.3851749 , time: 0:00:21.257516\n",
      "Batch/Epoch: 87 / 0 , Generator loss: 31.267702 , Discriminator loss: 1.387356 , time: 0:00:21.417260\n",
      "Batch/Epoch: 88 / 0 , Generator loss: 36.31647 , Discriminator loss: 1.3879606 , time: 0:00:21.575832\n",
      "Batch/Epoch: 89 / 0 , Generator loss: 34.50454 , Discriminator loss: 1.3852893 , time: 0:00:21.733753\n",
      "Batch/Epoch: 90 / 0 , Generator loss: 36.58955 , Discriminator loss: 1.3854961 , time: 0:00:21.895115\n",
      "Batch/Epoch: 91 / 0 , Generator loss: 35.13256 , Discriminator loss: 1.3869432 , time: 0:00:22.055080\n",
      "Batch/Epoch: 92 / 0 , Generator loss: 36.907085 , Discriminator loss: 1.3849506 , time: 0:00:22.214193\n",
      "Batch/Epoch: 93 / 0 , Generator loss: 32.8117 , Discriminator loss: 1.3859929 , time: 0:00:22.373128\n",
      "Batch/Epoch: 94 / 0 , Generator loss: 35.373386 , Discriminator loss: 1.3844213 , time: 0:00:22.530300\n",
      "Batch/Epoch: 95 / 0 , Generator loss: 34.30311 , Discriminator loss: 1.3853443 , time: 0:00:22.691871\n",
      "Batch/Epoch: 96 / 0 , Generator loss: 35.984066 , Discriminator loss: 1.3826218 , time: 0:00:22.852547\n",
      "Batch/Epoch: 97 / 0 , Generator loss: 30.57548 , Discriminator loss: 1.386172 , time: 0:00:23.020093\n",
      "Batch/Epoch: 98 / 0 , Generator loss: 29.115364 , Discriminator loss: 1.3858293 , time: 0:00:23.180439\n",
      "Batch/Epoch: 99 / 0 , Generator loss: 30.844288 , Discriminator loss: 1.3865879 , time: 0:00:23.340038\n",
      "Batch/Epoch: 100 / 0 , Generator loss: 35.927383 , Discriminator loss: 1.38588 , time: 0:00:23.498031\n",
      "Batch/Epoch: 101 / 0 , Generator loss: 31.632708 , Discriminator loss: 1.3858129 , time: 0:00:23.655612\n",
      "Batch/Epoch: 102 / 0 , Generator loss: 36.672867 , Discriminator loss: 1.3839428 , time: 0:00:23.812582\n",
      "Batch/Epoch: 103 / 0 , Generator loss: 34.343708 , Discriminator loss: 1.3861692 , time: 0:00:23.972602\n",
      "Batch/Epoch: 104 / 0 , Generator loss: 31.243433 , Discriminator loss: 1.3853619 , time: 0:00:24.131479\n",
      "Batch/Epoch: 105 / 0 , Generator loss: 35.638016 , Discriminator loss: 1.3851645 , time: 0:00:24.289022\n",
      "Batch/Epoch: 106 / 0 , Generator loss: 28.648024 , Discriminator loss: 1.3852516 , time: 0:00:24.449592\n",
      "Batch/Epoch: 107 / 0 , Generator loss: 28.858334 , Discriminator loss: 1.3852026 , time: 0:00:24.608366\n",
      "Batch/Epoch: 108 / 0 , Generator loss: 32.166096 , Discriminator loss: 1.3852551 , time: 0:00:24.767579\n",
      "Batch/Epoch: 109 / 0 , Generator loss: 35.287403 , Discriminator loss: 1.3863287 , time: 0:00:24.926155\n",
      "Batch/Epoch: 110 / 0 , Generator loss: 34.5109 , Discriminator loss: 1.3856025 , time: 0:00:25.087597\n",
      "Batch/Epoch: 111 / 0 , Generator loss: 32.04801 , Discriminator loss: 1.3854761 , time: 0:00:25.247658\n",
      "Batch/Epoch: 112 / 0 , Generator loss: 34.831753 , Discriminator loss: 1.3854783 , time: 0:00:25.406401\n",
      "Batch/Epoch: 113 / 0 , Generator loss: 30.872778 , Discriminator loss: 1.3860555 , time: 0:00:25.566972\n",
      "Batch/Epoch: 114 / 0 , Generator loss: 33.178665 , Discriminator loss: 1.3851306 , time: 0:00:25.726534\n",
      "Batch/Epoch: 115 / 0 , Generator loss: 32.72285 , Discriminator loss: 1.3854096 , time: 0:00:25.886562\n",
      "Batch/Epoch: 116 / 0 , Generator loss: 32.887638 , Discriminator loss: 1.3836131 , time: 0:00:26.047319\n",
      "Batch/Epoch: 117 / 0 , Generator loss: 32.690536 , Discriminator loss: 1.3860179 , time: 0:00:26.205455\n",
      "Batch/Epoch: 118 / 0 , Generator loss: 28.214752 , Discriminator loss: 1.3849301 , time: 0:00:26.365424\n",
      "Batch/Epoch: 119 / 0 , Generator loss: 33.09078 , Discriminator loss: 1.3834462 , time: 0:00:26.524055\n",
      "Batch/Epoch: 120 / 0 , Generator loss: 34.789295 , Discriminator loss: 1.3850482 , time: 0:00:26.685499\n",
      "Batch/Epoch: 121 / 0 , Generator loss: 35.699654 , Discriminator loss: 1.3860343 , time: 0:00:26.843951\n",
      "Batch/Epoch: 122 / 0 , Generator loss: 31.10817 , Discriminator loss: 1.3855809 , time: 0:00:27.001569\n",
      "Batch/Epoch: 123 / 0 , Generator loss: 29.062634 , Discriminator loss: 1.3845109 , time: 0:00:27.162407\n",
      "Batch/Epoch: 124 / 0 , Generator loss: 29.96492 , Discriminator loss: 1.3847623 , time: 0:00:27.321982\n",
      "Batch/Epoch: 125 / 0 , Generator loss: 29.714584 , Discriminator loss: 1.3865609 , time: 0:00:27.478996\n",
      "Batch/Epoch: 126 / 0 , Generator loss: 28.00802 , Discriminator loss: 1.384567 , time: 0:00:27.638698\n",
      "Batch/Epoch: 127 / 0 , Generator loss: 35.270508 , Discriminator loss: 1.3849136 , time: 0:00:27.797139\n",
      "Batch/Epoch: 128 / 0 , Generator loss: 34.79363 , Discriminator loss: 1.3830707 , time: 0:00:27.957096\n",
      "Batch/Epoch: 129 / 0 , Generator loss: 33.8243 , Discriminator loss: 1.3831174 , time: 0:00:28.116028\n",
      "Batch/Epoch: 130 / 0 , Generator loss: 32.36196 , Discriminator loss: 1.3826959 , time: 0:00:28.276754\n",
      "Batch/Epoch: 131 / 0 , Generator loss: 33.00716 , Discriminator loss: 1.3824592 , time: 0:00:28.437941\n",
      "Batch/Epoch: 132 / 0 , Generator loss: 34.556366 , Discriminator loss: 1.3826977 , time: 0:00:28.596529\n",
      "Batch/Epoch: 133 / 0 , Generator loss: 31.867168 , Discriminator loss: 1.3848528 , time: 0:00:28.754109\n",
      "Batch/Epoch: 134 / 0 , Generator loss: 32.097984 , Discriminator loss: 1.3832011 , time: 0:00:28.912998\n",
      "Batch/Epoch: 135 / 0 , Generator loss: 32.607075 , Discriminator loss: 1.384253 , time: 0:00:29.070509\n",
      "Batch/Epoch: 136 / 0 , Generator loss: 37.567856 , Discriminator loss: 1.3836468 , time: 0:00:29.233658\n",
      "Batch/Epoch: 137 / 0 , Generator loss: 29.85533 , Discriminator loss: 1.3854201 , time: 0:00:29.392564\n",
      "Batch/Epoch: 138 / 0 , Generator loss: 27.833403 , Discriminator loss: 1.3840566 , time: 0:00:29.554160\n",
      "Batch/Epoch: 139 / 0 , Generator loss: 35.12693 , Discriminator loss: 1.3830824 , time: 0:00:29.714627\n",
      "Batch/Epoch: 140 / 0 , Generator loss: 35.08146 , Discriminator loss: 1.3832858 , time: 0:00:29.872203\n",
      "Batch/Epoch: 141 / 0 , Generator loss: 27.644407 , Discriminator loss: 1.3844278 , time: 0:00:30.029414\n",
      "Batch/Epoch: 142 / 0 , Generator loss: 29.263075 , Discriminator loss: 1.3851504 , time: 0:00:30.190659\n",
      "Batch/Epoch: 143 / 0 , Generator loss: 30.970308 , Discriminator loss: 1.3835158 , time: 0:00:30.350741\n",
      "Batch/Epoch: 144 / 0 , Generator loss: 32.725903 , Discriminator loss: 1.3807936 , time: 0:00:30.509713\n",
      "Batch/Epoch: 145 / 0 , Generator loss: 29.457085 , Discriminator loss: 1.3838888 , time: 0:00:30.669290\n",
      "Batch/Epoch: 146 / 0 , Generator loss: 32.82126 , Discriminator loss: 1.3814884 , time: 0:00:30.826868\n",
      "Batch/Epoch: 147 / 0 , Generator loss: 35.870678 , Discriminator loss: 1.3812084 , time: 0:00:30.986665\n",
      "Batch/Epoch: 148 / 0 , Generator loss: 31.783304 , Discriminator loss: 1.3824012 , time: 0:00:31.144453\n",
      "Batch/Epoch: 149 / 0 , Generator loss: 35.34804 , Discriminator loss: 1.380615 , time: 0:00:31.306829\n",
      "Batch/Epoch: 150 / 0 , Generator loss: 31.996904 , Discriminator loss: 1.3813596 , time: 0:00:31.466679\n",
      "Batch/Epoch: 151 / 0 , Generator loss: 29.02204 , Discriminator loss: 1.383693 , time: 0:00:31.627241\n",
      "Batch/Epoch: 152 / 0 , Generator loss: 31.837046 , Discriminator loss: 1.3825667 , time: 0:00:31.785820\n",
      "Batch/Epoch: 153 / 0 , Generator loss: 32.399536 , Discriminator loss: 1.3812652 , time: 0:00:31.944476\n",
      "-----\n",
      "EPOCH: 1\n",
      "Batch/Epoch: 0 / 1 , Generator loss: 35.325882 , Discriminator loss: 1.3808067 , time: 0:00:33.424747\n",
      "Batch/Epoch: 1 / 1 , Generator loss: 36.41591 , Discriminator loss: 1.3789096 , time: 0:00:33.598281\n",
      "Batch/Epoch: 2 / 1 , Generator loss: 30.41519 , Discriminator loss: 1.3805454 , time: 0:00:33.762840\n",
      "Batch/Epoch: 3 / 1 , Generator loss: 27.768162 , Discriminator loss: 1.3810525 , time: 0:00:33.926981\n",
      "Batch/Epoch: 4 / 1 , Generator loss: 34.319515 , Discriminator loss: 1.3781891 , time: 0:00:34.085638\n",
      "Batch/Epoch: 5 / 1 , Generator loss: 30.134808 , Discriminator loss: 1.3814714 , time: 0:00:34.247172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch/Epoch: 6 / 1 , Generator loss: 26.350533 , Discriminator loss: 1.3816946 , time: 0:00:34.406770\n",
      "Batch/Epoch: 7 / 1 , Generator loss: 32.899643 , Discriminator loss: 1.3789756 , time: 0:00:34.565321\n",
      "Batch/Epoch: 8 / 1 , Generator loss: 34.815166 , Discriminator loss: 1.378186 , time: 0:00:34.723937\n",
      "Batch/Epoch: 9 / 1 , Generator loss: 28.153986 , Discriminator loss: 1.3810728 , time: 0:00:34.882474\n",
      "Batch/Epoch: 10 / 1 , Generator loss: 33.911945 , Discriminator loss: 1.3762538 , time: 0:00:35.042081\n",
      "Batch/Epoch: 11 / 1 , Generator loss: 32.053196 , Discriminator loss: 1.3771514 , time: 0:00:35.204613\n",
      "Batch/Epoch: 12 / 1 , Generator loss: 33.51436 , Discriminator loss: 1.376061 , time: 0:00:35.363199\n",
      "Batch/Epoch: 13 / 1 , Generator loss: 28.608067 , Discriminator loss: 1.3801572 , time: 0:00:35.523964\n",
      "Batch/Epoch: 14 / 1 , Generator loss: 35.75014 , Discriminator loss: 1.3776048 , time: 0:00:35.683034\n",
      "Batch/Epoch: 15 / 1 , Generator loss: 28.871748 , Discriminator loss: 1.378077 , time: 0:00:35.840524\n",
      "Batch/Epoch: 16 / 1 , Generator loss: 28.110088 , Discriminator loss: 1.3792169 , time: 0:00:36.000185\n",
      "Batch/Epoch: 17 / 1 , Generator loss: 31.087027 , Discriminator loss: 1.3749903 , time: 0:00:36.160235\n",
      "Batch/Epoch: 18 / 1 , Generator loss: 28.458082 , Discriminator loss: 1.3756073 , time: 0:00:36.320861\n",
      "Batch/Epoch: 19 / 1 , Generator loss: 35.5177 , Discriminator loss: 1.3734217 , time: 0:00:36.482775\n",
      "Batch/Epoch: 20 / 1 , Generator loss: 31.020264 , Discriminator loss: 1.3715535 , time: 0:00:36.646281\n",
      "Batch/Epoch: 21 / 1 , Generator loss: 28.58555 , Discriminator loss: 1.3770607 , time: 0:00:36.806166\n",
      "Batch/Epoch: 22 / 1 , Generator loss: 28.073898 , Discriminator loss: 1.373362 , time: 0:00:36.964442\n",
      "Batch/Epoch: 23 / 1 , Generator loss: 29.12874 , Discriminator loss: 1.3733513 , time: 0:00:37.124981\n",
      "Batch/Epoch: 24 / 1 , Generator loss: 35.122814 , Discriminator loss: 1.3708179 , time: 0:00:37.284665\n",
      "Batch/Epoch: 25 / 1 , Generator loss: 27.85668 , Discriminator loss: 1.3743587 , time: 0:00:37.443200\n",
      "Batch/Epoch: 26 / 1 , Generator loss: 29.66952 , Discriminator loss: 1.3740487 , time: 0:00:37.603033\n",
      "Batch/Epoch: 27 / 1 , Generator loss: 32.1051 , Discriminator loss: 1.3686757 , time: 0:00:37.762577\n",
      "Batch/Epoch: 28 / 1 , Generator loss: 35.646423 , Discriminator loss: 1.3667121 , time: 0:00:37.923185\n",
      "Batch/Epoch: 29 / 1 , Generator loss: 27.797827 , Discriminator loss: 1.3735738 , time: 0:00:38.085730\n",
      "Batch/Epoch: 30 / 1 , Generator loss: 29.257257 , Discriminator loss: 1.3623832 , time: 0:00:38.246318\n",
      "Batch/Epoch: 31 / 1 , Generator loss: 29.434004 , Discriminator loss: 1.3714082 , time: 0:00:38.406200\n",
      "Batch/Epoch: 32 / 1 , Generator loss: 33.7403 , Discriminator loss: 1.3662543 , time: 0:00:38.568765\n",
      "Batch/Epoch: 33 / 1 , Generator loss: 28.351774 , Discriminator loss: 1.3660595 , time: 0:00:38.732297\n",
      "Batch/Epoch: 34 / 1 , Generator loss: 34.15217 , Discriminator loss: 1.3595092 , time: 0:00:38.891901\n",
      "Batch/Epoch: 35 / 1 , Generator loss: 28.400597 , Discriminator loss: 1.3691893 , time: 0:00:39.050445\n",
      "Batch/Epoch: 36 / 1 , Generator loss: 27.351202 , Discriminator loss: 1.3669107 , time: 0:00:39.212137\n",
      "Batch/Epoch: 37 / 1 , Generator loss: 30.840958 , Discriminator loss: 1.3604555 , time: 0:00:39.372709\n",
      "Batch/Epoch: 38 / 1 , Generator loss: 32.199066 , Discriminator loss: 1.3537211 , time: 0:00:39.531911\n",
      "Batch/Epoch: 39 / 1 , Generator loss: 34.618973 , Discriminator loss: 1.352633 , time: 0:00:39.693286\n",
      "Batch/Epoch: 40 / 1 , Generator loss: 34.11089 , Discriminator loss: 1.3504913 , time: 0:00:39.853726\n",
      "Batch/Epoch: 41 / 1 , Generator loss: 30.705254 , Discriminator loss: 1.3458128 , time: 0:00:40.014297\n",
      "Batch/Epoch: 42 / 1 , Generator loss: 26.661373 , Discriminator loss: 1.3589338 , time: 0:00:40.178409\n",
      "Batch/Epoch: 43 / 1 , Generator loss: 32.142315 , Discriminator loss: 1.3462027 , time: 0:00:40.341214\n",
      "Batch/Epoch: 44 / 1 , Generator loss: 28.791058 , Discriminator loss: 1.3600869 , time: 0:00:40.500787\n",
      "Batch/Epoch: 45 / 1 , Generator loss: 33.05714 , Discriminator loss: 1.3401011 , time: 0:00:40.661498\n",
      "Batch/Epoch: 46 / 1 , Generator loss: 30.965302 , Discriminator loss: 1.3395944 , time: 0:00:40.820008\n",
      "Batch/Epoch: 47 / 1 , Generator loss: 33.223183 , Discriminator loss: 1.3352141 , time: 0:00:40.980296\n",
      "Batch/Epoch: 48 / 1 , Generator loss: 35.006046 , Discriminator loss: 1.3312659 , time: 0:00:41.138254\n",
      "Batch/Epoch: 49 / 1 , Generator loss: 32.504097 , Discriminator loss: 1.3233268 , time: 0:00:41.295693\n",
      "Batch/Epoch: 50 / 1 , Generator loss: 32.5157 , Discriminator loss: 1.3283674 , time: 0:00:41.454272\n",
      "Batch/Epoch: 51 / 1 , Generator loss: 31.903446 , Discriminator loss: 1.3249309 , time: 0:00:41.610625\n",
      "Batch/Epoch: 52 / 1 , Generator loss: 35.857853 , Discriminator loss: 1.3124312 , time: 0:00:41.771198\n",
      "Batch/Epoch: 53 / 1 , Generator loss: 27.536842 , Discriminator loss: 1.3361807 , time: 0:00:41.933802\n",
      "Batch/Epoch: 54 / 1 , Generator loss: 33.258022 , Discriminator loss: 1.3183126 , time: 0:00:42.094998\n",
      "Batch/Epoch: 55 / 1 , Generator loss: 33.33907 , Discriminator loss: 1.3110163 , time: 0:00:42.252540\n",
      "Batch/Epoch: 56 / 1 , Generator loss: 26.359116 , Discriminator loss: 1.3433433 , time: 0:00:42.414359\n",
      "Batch/Epoch: 57 / 1 , Generator loss: 37.202126 , Discriminator loss: 1.3134832 , time: 0:00:42.579954\n",
      "Batch/Epoch: 58 / 1 , Generator loss: 32.34938 , Discriminator loss: 1.324976 , time: 0:00:42.743481\n",
      "Batch/Epoch: 59 / 1 , Generator loss: 32.8609 , Discriminator loss: 1.2883835 , time: 0:00:42.903595\n",
      "Batch/Epoch: 60 / 1 , Generator loss: 29.035223 , Discriminator loss: 1.3219687 , time: 0:00:43.065166\n",
      "Batch/Epoch: 61 / 1 , Generator loss: 30.830824 , Discriminator loss: 1.3175688 , time: 0:00:43.223628\n",
      "Batch/Epoch: 62 / 1 , Generator loss: 34.436962 , Discriminator loss: 1.2717681 , time: 0:00:43.390782\n",
      "Batch/Epoch: 63 / 1 , Generator loss: 32.401443 , Discriminator loss: 1.2977586 , time: 0:00:43.549360\n",
      "Batch/Epoch: 64 / 1 , Generator loss: 33.63658 , Discriminator loss: 1.2601676 , time: 0:00:43.709879\n",
      "Batch/Epoch: 65 / 1 , Generator loss: 28.318914 , Discriminator loss: 1.2986538 , time: 0:00:43.867011\n",
      "Batch/Epoch: 66 / 1 , Generator loss: 33.227448 , Discriminator loss: 1.2498386 , time: 0:00:44.025557\n",
      "Batch/Epoch: 67 / 1 , Generator loss: 31.773096 , Discriminator loss: 1.2749745 , time: 0:00:44.185872\n",
      "Batch/Epoch: 68 / 1 , Generator loss: 27.739243 , Discriminator loss: 1.2907491 , time: 0:00:44.349323\n",
      "Batch/Epoch: 69 / 1 , Generator loss: 31.015514 , Discriminator loss: 1.2602322 , time: 0:00:44.525886\n",
      "Batch/Epoch: 70 / 1 , Generator loss: 29.972536 , Discriminator loss: 1.3033267 , time: 0:00:44.693724\n",
      "Batch/Epoch: 71 / 1 , Generator loss: 32.728107 , Discriminator loss: 1.25273 , time: 0:00:44.851885\n",
      "Batch/Epoch: 72 / 1 , Generator loss: 34.24318 , Discriminator loss: 1.249677 , time: 0:00:45.015063\n",
      "Batch/Epoch: 73 / 1 , Generator loss: 32.22415 , Discriminator loss: 1.2343171 , time: 0:00:45.174639\n",
      "Batch/Epoch: 74 / 1 , Generator loss: 31.806112 , Discriminator loss: 1.2201456 , time: 0:00:45.334201\n",
      "Batch/Epoch: 75 / 1 , Generator loss: 34.58557 , Discriminator loss: 1.2101611 , time: 0:00:45.492505\n",
      "Batch/Epoch: 76 / 1 , Generator loss: 32.64621 , Discriminator loss: 1.2284226 , time: 0:00:45.652141\n",
      "Batch/Epoch: 77 / 1 , Generator loss: 33.274483 , Discriminator loss: 1.2026877 , time: 0:00:45.809720\n",
      "Batch/Epoch: 78 / 1 , Generator loss: 26.426744 , Discriminator loss: 1.2519898 , time: 0:00:45.968846\n",
      "Batch/Epoch: 79 / 1 , Generator loss: 32.55445 , Discriminator loss: 1.1972146 , time: 0:00:46.126459\n",
      "Batch/Epoch: 80 / 1 , Generator loss: 27.369495 , Discriminator loss: 1.2361832 , time: 0:00:46.286032\n",
      "Batch/Epoch: 81 / 1 , Generator loss: 31.290768 , Discriminator loss: 1.2238381 , time: 0:00:46.445527\n",
      "Batch/Epoch: 82 / 1 , Generator loss: 30.810389 , Discriminator loss: 1.1665127 , time: 0:00:46.604764\n",
      "Batch/Epoch: 83 / 1 , Generator loss: 29.129124 , Discriminator loss: 1.2159979 , time: 0:00:46.767323\n",
      "Batch/Epoch: 84 / 1 , Generator loss: 33.286022 , Discriminator loss: 1.1619165 , time: 0:00:46.926967\n",
      "Batch/Epoch: 85 / 1 , Generator loss: 30.363253 , Discriminator loss: 1.1746562 , time: 0:00:47.084962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch/Epoch: 86 / 1 , Generator loss: 34.532806 , Discriminator loss: 1.1392593 , time: 0:00:47.245535\n",
      "Batch/Epoch: 87 / 1 , Generator loss: 33.466343 , Discriminator loss: 1.1026995 , time: 0:00:47.403923\n",
      "Batch/Epoch: 88 / 1 , Generator loss: 35.574722 , Discriminator loss: 1.1145604 , time: 0:00:47.564121\n",
      "Batch/Epoch: 89 / 1 , Generator loss: 34.200523 , Discriminator loss: 1.0989624 , time: 0:00:47.722706\n",
      "Batch/Epoch: 90 / 1 , Generator loss: 29.78461 , Discriminator loss: 1.1382211 , time: 0:00:47.882013\n",
      "Batch/Epoch: 91 / 1 , Generator loss: 34.876137 , Discriminator loss: 1.084928 , time: 0:00:48.040270\n",
      "Batch/Epoch: 92 / 1 , Generator loss: 32.45695 , Discriminator loss: 1.0887117 , time: 0:00:48.201842\n",
      "Batch/Epoch: 93 / 1 , Generator loss: 29.188702 , Discriminator loss: 1.1644825 , time: 0:00:48.360112\n",
      "Batch/Epoch: 94 / 1 , Generator loss: 30.23494 , Discriminator loss: 1.0820928 , time: 0:00:48.519606\n",
      "Batch/Epoch: 95 / 1 , Generator loss: 31.96641 , Discriminator loss: 1.0398387 , time: 0:00:48.679366\n",
      "Batch/Epoch: 96 / 1 , Generator loss: 30.498709 , Discriminator loss: 1.0627313 , time: 0:00:48.872097\n",
      "Batch/Epoch: 97 / 1 , Generator loss: 34.644802 , Discriminator loss: 1.0171602 , time: 0:00:49.043661\n",
      "Batch/Epoch: 98 / 1 , Generator loss: 28.514902 , Discriminator loss: 1.0917995 , time: 0:00:49.207848\n",
      "Batch/Epoch: 99 / 1 , Generator loss: 33.09318 , Discriminator loss: 0.9671186 , time: 0:00:49.368328\n",
      "Batch/Epoch: 100 / 1 , Generator loss: 34.678658 , Discriminator loss: 0.9846513 , time: 0:00:49.531288\n",
      "Batch/Epoch: 101 / 1 , Generator loss: 27.312721 , Discriminator loss: 1.1148006 , time: 0:00:49.690862\n",
      "Batch/Epoch: 102 / 1 , Generator loss: 32.00571 , Discriminator loss: 0.9859397 , time: 0:00:49.852608\n",
      "Batch/Epoch: 103 / 1 , Generator loss: 32.26144 , Discriminator loss: 0.9438641 , time: 0:00:50.016552\n",
      "Batch/Epoch: 104 / 1 , Generator loss: 30.967464 , Discriminator loss: 0.9814476 , time: 0:00:50.176862\n",
      "Batch/Epoch: 105 / 1 , Generator loss: 33.544193 , Discriminator loss: 0.9237268 , time: 0:00:50.338151\n",
      "Batch/Epoch: 106 / 1 , Generator loss: 34.773438 , Discriminator loss: 0.91007054 , time: 0:00:50.498119\n",
      "Batch/Epoch: 107 / 1 , Generator loss: 29.569448 , Discriminator loss: 1.0303376 , time: 0:00:50.661683\n",
      "Batch/Epoch: 108 / 1 , Generator loss: 27.317347 , Discriminator loss: 1.0334305 , time: 0:00:50.820983\n",
      "Batch/Epoch: 109 / 1 , Generator loss: 34.48079 , Discriminator loss: 0.87245435 , time: 0:00:50.980588\n",
      "Batch/Epoch: 110 / 1 , Generator loss: 28.254704 , Discriminator loss: 1.0223804 , time: 0:00:51.141126\n",
      "Batch/Epoch: 111 / 1 , Generator loss: 30.673176 , Discriminator loss: 0.88296163 , time: 0:00:51.299870\n",
      "Batch/Epoch: 112 / 1 , Generator loss: 27.919357 , Discriminator loss: 0.959211 , time: 0:00:51.462435\n",
      "Batch/Epoch: 113 / 1 , Generator loss: 30.645346 , Discriminator loss: 0.88627255 , time: 0:00:51.623945\n",
      "Batch/Epoch: 114 / 1 , Generator loss: 32.554756 , Discriminator loss: 0.8423294 , time: 0:00:51.783891\n",
      "Batch/Epoch: 115 / 1 , Generator loss: 29.855785 , Discriminator loss: 0.9676739 , time: 0:00:51.942651\n",
      "Batch/Epoch: 116 / 1 , Generator loss: 29.822382 , Discriminator loss: 0.98379195 , time: 0:00:52.104260\n",
      "Batch/Epoch: 117 / 1 , Generator loss: 35.444553 , Discriminator loss: 0.8241776 , time: 0:00:52.264202\n",
      "Batch/Epoch: 118 / 1 , Generator loss: 32.596222 , Discriminator loss: 0.8005632 , time: 0:00:52.423830\n",
      "Batch/Epoch: 119 / 1 , Generator loss: 28.142132 , Discriminator loss: 0.8583547 , time: 0:00:52.592952\n",
      "Batch/Epoch: 120 / 1 , Generator loss: 31.830715 , Discriminator loss: 0.7957418 , time: 0:00:52.755988\n",
      "Batch/Epoch: 121 / 1 , Generator loss: 33.969738 , Discriminator loss: 0.7165926 , time: 0:00:52.914565\n",
      "Batch/Epoch: 122 / 1 , Generator loss: 28.909842 , Discriminator loss: 0.89299905 , time: 0:00:53.080122\n",
      "Batch/Epoch: 123 / 1 , Generator loss: 33.252495 , Discriminator loss: 0.7156145 , time: 0:00:53.240342\n",
      "Batch/Epoch: 124 / 1 , Generator loss: 33.437206 , Discriminator loss: 0.70065427 , time: 0:00:53.401910\n",
      "Batch/Epoch: 125 / 1 , Generator loss: 31.203913 , Discriminator loss: 0.70881164 , time: 0:00:53.560038\n",
      "Batch/Epoch: 126 / 1 , Generator loss: 34.531864 , Discriminator loss: 0.6421239 , time: 0:00:53.719097\n",
      "Batch/Epoch: 127 / 1 , Generator loss: 34.287804 , Discriminator loss: 0.60851675 , time: 0:00:53.876759\n",
      "Batch/Epoch: 128 / 1 , Generator loss: 30.151262 , Discriminator loss: 0.7206637 , time: 0:00:54.037334\n",
      "Batch/Epoch: 129 / 1 , Generator loss: 34.112335 , Discriminator loss: 0.6101363 , time: 0:00:54.200529\n",
      "Batch/Epoch: 130 / 1 , Generator loss: 30.09023 , Discriminator loss: 0.78375983 , time: 0:00:54.362841\n",
      "Batch/Epoch: 131 / 1 , Generator loss: 28.604528 , Discriminator loss: 0.79503274 , time: 0:00:54.524669\n",
      "Batch/Epoch: 132 / 1 , Generator loss: 35.147762 , Discriminator loss: 0.570596 , time: 0:00:54.687663\n",
      "Batch/Epoch: 133 / 1 , Generator loss: 28.932455 , Discriminator loss: 0.66596526 , time: 0:00:54.847757\n",
      "Batch/Epoch: 134 / 1 , Generator loss: 31.338001 , Discriminator loss: 0.5981407 , time: 0:00:55.009325\n",
      "Batch/Epoch: 135 / 1 , Generator loss: 36.010654 , Discriminator loss: 0.53317976 , time: 0:00:55.170755\n",
      "Batch/Epoch: 136 / 1 , Generator loss: 32.491684 , Discriminator loss: 0.53596973 , time: 0:00:55.330950\n",
      "Batch/Epoch: 137 / 1 , Generator loss: 31.631062 , Discriminator loss: 0.50299245 , time: 0:00:55.488783\n",
      "Batch/Epoch: 138 / 1 , Generator loss: 34.054203 , Discriminator loss: 0.471445 , time: 0:00:55.648324\n",
      "Batch/Epoch: 139 / 1 , Generator loss: 32.740894 , Discriminator loss: 0.52141 , time: 0:00:55.818438\n",
      "Batch/Epoch: 140 / 1 , Generator loss: 28.255753 , Discriminator loss: 0.7169846 , time: 0:00:55.983996\n",
      "Batch/Epoch: 141 / 1 , Generator loss: 30.248291 , Discriminator loss: 0.5518211 , time: 0:00:56.147221\n",
      "Batch/Epoch: 142 / 1 , Generator loss: 30.60408 , Discriminator loss: 0.6042885 , time: 0:00:56.312747\n",
      "Batch/Epoch: 143 / 1 , Generator loss: 35.337234 , Discriminator loss: 0.48467916 , time: 0:00:56.479196\n",
      "Batch/Epoch: 144 / 1 , Generator loss: 33.811497 , Discriminator loss: 0.4687609 , time: 0:00:56.646192\n",
      "Batch/Epoch: 145 / 1 , Generator loss: 28.870604 , Discriminator loss: 0.6145108 , time: 0:00:56.809761\n",
      "Batch/Epoch: 146 / 1 , Generator loss: 27.36586 , Discriminator loss: 0.5699287 , time: 0:00:56.972418\n",
      "Batch/Epoch: 147 / 1 , Generator loss: 33.517593 , Discriminator loss: 0.43035582 , time: 0:00:57.132028\n",
      "Batch/Epoch: 148 / 1 , Generator loss: 31.937143 , Discriminator loss: 0.4181215 , time: 0:00:57.292564\n",
      "Batch/Epoch: 149 / 1 , Generator loss: 33.463345 , Discriminator loss: 0.41263372 , time: 0:00:57.453135\n",
      "Batch/Epoch: 150 / 1 , Generator loss: 30.41314 , Discriminator loss: 0.45460904 , time: 0:00:57.614326\n",
      "Batch/Epoch: 151 / 1 , Generator loss: 32.87323 , Discriminator loss: 0.41138703 , time: 0:00:57.775301\n",
      "Batch/Epoch: 152 / 1 , Generator loss: 31.669662 , Discriminator loss: 0.40172732 , time: 0:00:57.934906\n",
      "Batch/Epoch: 153 / 1 , Generator loss: 34.37047 , Discriminator loss: 0.34138054 , time: 0:00:58.095477\n",
      "-----\n",
      "EPOCH: 2\n",
      "Batch/Epoch: 0 / 2 , Generator loss: 32.794075 , Discriminator loss: 0.34913912 , time: 0:00:58.443279\n",
      "Batch/Epoch: 1 / 2 , Generator loss: 35.076492 , Discriminator loss: 0.3093885 , time: 0:00:58.601821\n",
      "Batch/Epoch: 2 / 2 , Generator loss: 35.711292 , Discriminator loss: 0.30525932 , time: 0:00:58.768378\n",
      "Batch/Epoch: 3 / 2 , Generator loss: 29.988245 , Discriminator loss: 0.48136228 , time: 0:00:58.936355\n",
      "Batch/Epoch: 4 / 2 , Generator loss: 32.065212 , Discriminator loss: 0.30442777 , time: 0:00:59.094215\n",
      "Batch/Epoch: 5 / 2 , Generator loss: 34.823635 , Discriminator loss: 0.25627145 , time: 0:00:59.261769\n",
      "Batch/Epoch: 6 / 2 , Generator loss: 34.844063 , Discriminator loss: 0.2737578 , time: 0:00:59.424335\n",
      "Batch/Epoch: 7 / 2 , Generator loss: 34.00063 , Discriminator loss: 0.30414665 , time: 0:00:59.582911\n",
      "Batch/Epoch: 8 / 2 , Generator loss: 29.84375 , Discriminator loss: 0.3936049 , time: 0:00:59.742222\n",
      "Batch/Epoch: 9 / 2 , Generator loss: 30.018595 , Discriminator loss: 0.2982826 , time: 0:00:59.907729\n",
      "Batch/Epoch: 10 / 2 , Generator loss: 30.638596 , Discriminator loss: 0.26356357 , time: 0:01:00.069273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch/Epoch: 11 / 2 , Generator loss: 34.914154 , Discriminator loss: 0.2134228 , time: 0:01:00.227850\n",
      "Batch/Epoch: 12 / 2 , Generator loss: 31.68418 , Discriminator loss: 0.2714193 , time: 0:01:00.387445\n",
      "Batch/Epoch: 13 / 2 , Generator loss: 29.330093 , Discriminator loss: 0.30655587 , time: 0:01:00.547083\n",
      "Batch/Epoch: 14 / 2 , Generator loss: 28.535908 , Discriminator loss: 0.33818612 , time: 0:01:00.708665\n",
      "Batch/Epoch: 15 / 2 , Generator loss: 29.27991 , Discriminator loss: 0.28728506 , time: 0:01:00.869272\n",
      "Batch/Epoch: 16 / 2 , Generator loss: 31.304268 , Discriminator loss: 0.28151393 , time: 0:01:01.026804\n",
      "Batch/Epoch: 17 / 2 , Generator loss: 35.45731 , Discriminator loss: 0.19902945 , time: 0:01:01.190367\n",
      "Batch/Epoch: 18 / 2 , Generator loss: 33.69579 , Discriminator loss: 0.21019569 , time: 0:01:01.353900\n",
      "Batch/Epoch: 19 / 2 , Generator loss: 35.178673 , Discriminator loss: 0.1782992 , time: 0:01:01.515433\n",
      "Batch/Epoch: 20 / 2 , Generator loss: 28.030304 , Discriminator loss: 0.28535557 , time: 0:01:01.676035\n",
      "Batch/Epoch: 21 / 2 , Generator loss: 33.644997 , Discriminator loss: 0.17527112 , time: 0:01:01.837285\n",
      "Batch/Epoch: 22 / 2 , Generator loss: 33.06083 , Discriminator loss: 0.18200637 , time: 0:01:01.997931\n",
      "Batch/Epoch: 23 / 2 , Generator loss: 30.099276 , Discriminator loss: 0.32306284 , time: 0:01:02.156546\n",
      "Batch/Epoch: 24 / 2 , Generator loss: 29.889013 , Discriminator loss: 0.23136163 , time: 0:01:02.316284\n",
      "Batch/Epoch: 25 / 2 , Generator loss: 33.893555 , Discriminator loss: 0.18480837 , time: 0:01:02.478533\n",
      "Batch/Epoch: 26 / 2 , Generator loss: 30.132797 , Discriminator loss: 0.23084511 , time: 0:01:02.641612\n",
      "Batch/Epoch: 27 / 2 , Generator loss: 29.575455 , Discriminator loss: 0.3158603 , time: 0:01:02.803171\n",
      "Batch/Epoch: 28 / 2 , Generator loss: 29.152958 , Discriminator loss: 0.22984773 , time: 0:01:02.963079\n",
      "Batch/Epoch: 29 / 2 , Generator loss: 31.812408 , Discriminator loss: 0.2727003 , time: 0:01:03.124653\n",
      "Batch/Epoch: 30 / 2 , Generator loss: 35.875946 , Discriminator loss: 0.16583616 , time: 0:01:03.285011\n",
      "Batch/Epoch: 31 / 2 , Generator loss: 35.022522 , Discriminator loss: 0.13482788 , time: 0:01:03.446516\n",
      "Batch/Epoch: 32 / 2 , Generator loss: 36.622868 , Discriminator loss: 0.12638287 , time: 0:01:03.606655\n",
      "Batch/Epoch: 33 / 2 , Generator loss: 32.69189 , Discriminator loss: 0.12895867 , time: 0:01:03.766633\n",
      "Batch/Epoch: 34 / 2 , Generator loss: 32.75911 , Discriminator loss: 0.12713505 , time: 0:01:03.927166\n",
      "Batch/Epoch: 35 / 2 , Generator loss: 31.59345 , Discriminator loss: 0.124073 , time: 0:01:04.087226\n",
      "Batch/Epoch: 36 / 2 , Generator loss: 34.124027 , Discriminator loss: 0.117108166 , time: 0:01:04.247828\n",
      "Batch/Epoch: 37 / 2 , Generator loss: 34.061996 , Discriminator loss: 0.10490614 , time: 0:01:04.410069\n",
      "Batch/Epoch: 38 / 2 , Generator loss: 34.20296 , Discriminator loss: 0.0978882 , time: 0:01:04.570137\n",
      "Batch/Epoch: 39 / 2 , Generator loss: 36.928276 , Discriminator loss: 0.08351847 , time: 0:01:04.732701\n",
      "Batch/Epoch: 40 / 2 , Generator loss: 32.117794 , Discriminator loss: 0.10122604 , time: 0:01:04.893239\n",
      "Batch/Epoch: 41 / 2 , Generator loss: 35.723686 , Discriminator loss: 0.09181651 , time: 0:01:05.053286\n",
      "Batch/Epoch: 42 / 2 , Generator loss: 36.225227 , Discriminator loss: 0.06979129 , time: 0:01:05.213385\n",
      "Batch/Epoch: 43 / 2 , Generator loss: 29.55439 , Discriminator loss: 0.35000938 , time: 0:01:05.371516\n",
      "Batch/Epoch: 44 / 2 , Generator loss: 30.45397 , Discriminator loss: 0.12918511 , time: 0:01:05.530094\n",
      "Batch/Epoch: 45 / 2 , Generator loss: 28.562885 , Discriminator loss: 0.21625909 , time: 0:01:05.688702\n",
      "Batch/Epoch: 46 / 2 , Generator loss: 32.710464 , Discriminator loss: 0.10342474 , time: 0:01:05.847037\n",
      "Batch/Epoch: 47 / 2 , Generator loss: 36.43719 , Discriminator loss: 0.10661097 , time: 0:01:06.006186\n",
      "Batch/Epoch: 48 / 2 , Generator loss: 34.933918 , Discriminator loss: 0.10107842 , time: 0:01:06.164515\n",
      "Batch/Epoch: 49 / 2 , Generator loss: 29.640509 , Discriminator loss: 0.23068771 , time: 0:01:06.326347\n",
      "Batch/Epoch: 50 / 2 , Generator loss: 33.27577 , Discriminator loss: 0.12135427 , time: 0:01:06.487278\n",
      "Batch/Epoch: 51 / 2 , Generator loss: 37.964455 , Discriminator loss: 0.080827534 , time: 0:01:06.645855\n",
      "Batch/Epoch: 52 / 2 , Generator loss: 35.79596 , Discriminator loss: 0.065931976 , time: 0:01:06.805342\n",
      "Batch/Epoch: 53 / 2 , Generator loss: 33.17231 , Discriminator loss: 0.115761355 , time: 0:01:06.964936\n",
      "Batch/Epoch: 54 / 2 , Generator loss: 29.663769 , Discriminator loss: 0.14194897 , time: 0:01:07.125738\n",
      "Batch/Epoch: 55 / 2 , Generator loss: 37.519424 , Discriminator loss: 0.09744845 , time: 0:01:07.339898\n",
      "Batch/Epoch: 56 / 2 , Generator loss: 36.55956 , Discriminator loss: 0.09023836 , time: 0:01:07.503463\n",
      "Batch/Epoch: 57 / 2 , Generator loss: 34.65212 , Discriminator loss: 0.08309685 , time: 0:01:07.665585\n",
      "Batch/Epoch: 58 / 2 , Generator loss: 38.018833 , Discriminator loss: 0.086945504 , time: 0:01:07.824200\n",
      "Batch/Epoch: 59 / 2 , Generator loss: 36.540726 , Discriminator loss: 0.08280906 , time: 0:01:07.982759\n",
      "Batch/Epoch: 60 / 2 , Generator loss: 33.80539 , Discriminator loss: 0.08053174 , time: 0:01:08.143307\n",
      "Batch/Epoch: 61 / 2 , Generator loss: 32.93888 , Discriminator loss: 0.3253796 , time: 0:01:08.305905\n",
      "Batch/Epoch: 62 / 2 , Generator loss: 34.06765 , Discriminator loss: 0.09490341 , time: 0:01:08.469435\n",
      "Batch/Epoch: 63 / 2 , Generator loss: 31.081905 , Discriminator loss: 0.1018676 , time: 0:01:08.635388\n",
      "Batch/Epoch: 64 / 2 , Generator loss: 35.181293 , Discriminator loss: 0.09368355 , time: 0:01:08.799639\n",
      "Batch/Epoch: 65 / 2 , Generator loss: 36.069244 , Discriminator loss: 0.09881905 , time: 0:01:08.961207\n",
      "Batch/Epoch: 66 / 2 , Generator loss: 36.080544 , Discriminator loss: 0.0855319 , time: 0:01:09.118610\n",
      "Batch/Epoch: 67 / 2 , Generator loss: 28.616734 , Discriminator loss: 0.32755983 , time: 0:01:09.277188\n",
      "Batch/Epoch: 68 / 2 , Generator loss: 36.73778 , Discriminator loss: 0.14437513 , time: 0:01:09.437791\n",
      "Batch/Epoch: 69 / 2 , Generator loss: 32.109505 , Discriminator loss: 0.158459 , time: 0:01:09.596353\n",
      "Batch/Epoch: 70 / 2 , Generator loss: 29.718334 , Discriminator loss: 0.1475785 , time: 0:01:09.755582\n",
      "Batch/Epoch: 71 / 2 , Generator loss: 34.10827 , Discriminator loss: 0.1671039 , time: 0:01:09.915617\n",
      "Batch/Epoch: 72 / 2 , Generator loss: 27.928337 , Discriminator loss: 0.47991583 , time: 0:01:10.076196\n",
      "Batch/Epoch: 73 / 2 , Generator loss: 36.017906 , Discriminator loss: 0.20714565 , time: 0:01:10.239750\n",
      "Batch/Epoch: 74 / 2 , Generator loss: 31.020432 , Discriminator loss: 0.14075685 , time: 0:01:10.402317\n",
      "Batch/Epoch: 75 / 2 , Generator loss: 35.877235 , Discriminator loss: 0.086721376 , time: 0:01:10.599820\n",
      "Batch/Epoch: 76 / 2 , Generator loss: 32.18354 , Discriminator loss: 0.2873701 , time: 0:01:10.763618\n",
      "Batch/Epoch: 77 / 2 , Generator loss: 34.67133 , Discriminator loss: 0.44972003 , time: 0:01:10.923391\n",
      "Batch/Epoch: 78 / 2 , Generator loss: 37.61679 , Discriminator loss: 0.12353491 , time: 0:01:11.086906\n",
      "Batch/Epoch: 79 / 2 , Generator loss: 33.23399 , Discriminator loss: 0.10958392 , time: 0:01:11.247160\n",
      "Batch/Epoch: 80 / 2 , Generator loss: 33.481586 , Discriminator loss: 0.4573553 , time: 0:01:11.407720\n",
      "Batch/Epoch: 81 / 2 , Generator loss: 32.98437 , Discriminator loss: 0.11794058 , time: 0:01:11.570287\n",
      "Batch/Epoch: 82 / 2 , Generator loss: 36.19974 , Discriminator loss: 0.26967552 , time: 0:01:11.731855\n",
      "Batch/Epoch: 83 / 2 , Generator loss: 36.797062 , Discriminator loss: 0.14732563 , time: 0:01:11.895418\n",
      "Batch/Epoch: 84 / 2 , Generator loss: 33.61394 , Discriminator loss: 0.18772689 , time: 0:01:12.064858\n",
      "Batch/Epoch: 85 / 2 , Generator loss: 32.215027 , Discriminator loss: 1.0256544 , time: 0:01:12.232413\n",
      "Batch/Epoch: 86 / 2 , Generator loss: 38.105656 , Discriminator loss: 0.18648978 , time: 0:01:12.394037\n",
      "Batch/Epoch: 87 / 2 , Generator loss: 33.231136 , Discriminator loss: 0.124109104 , time: 0:01:12.554979\n",
      "Batch/Epoch: 88 / 2 , Generator loss: 33.488842 , Discriminator loss: 0.24790895 , time: 0:01:12.717543\n",
      "Batch/Epoch: 89 / 2 , Generator loss: 32.28845 , Discriminator loss: 0.31597584 , time: 0:01:12.879092\n",
      "Batch/Epoch: 90 / 2 , Generator loss: 35.05702 , Discriminator loss: 0.1261123 , time: 0:01:13.041032\n",
      "Batch/Epoch: 91 / 2 , Generator loss: 36.3785 , Discriminator loss: 0.2274972 , time: 0:01:13.199666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch/Epoch: 92 / 2 , Generator loss: 38.147045 , Discriminator loss: 0.2672795 , time: 0:01:13.359166\n",
      "Batch/Epoch: 93 / 2 , Generator loss: 38.562626 , Discriminator loss: 0.8608453 , time: 0:01:13.518117\n",
      "Batch/Epoch: 94 / 2 , Generator loss: 41.41567 , Discriminator loss: 0.14300206 , time: 0:01:13.674027\n",
      "Batch/Epoch: 95 / 2 , Generator loss: 35.790096 , Discriminator loss: 0.17051119 , time: 0:01:13.831661\n",
      "Batch/Epoch: 96 / 2 , Generator loss: 39.937046 , Discriminator loss: 0.21790257 , time: 0:01:13.991594\n",
      "Batch/Epoch: 97 / 2 , Generator loss: 32.256042 , Discriminator loss: 1.9208757 , time: 0:01:14.151634\n",
      "Batch/Epoch: 98 / 2 , Generator loss: 36.62108 , Discriminator loss: 0.22492768 , time: 0:01:14.311120\n",
      "Batch/Epoch: 99 / 2 , Generator loss: 36.477882 , Discriminator loss: 0.08610853 , time: 0:01:14.469674\n",
      "Batch/Epoch: 100 / 2 , Generator loss: 37.58007 , Discriminator loss: 0.10966139 , time: 0:01:14.627928\n",
      "Batch/Epoch: 101 / 2 , Generator loss: 34.48937 , Discriminator loss: 0.87318635 , time: 0:01:14.805451\n",
      "Batch/Epoch: 102 / 2 , Generator loss: 36.93553 , Discriminator loss: 0.30931398 , time: 0:01:14.965482\n",
      "Batch/Epoch: 103 / 2 , Generator loss: 33.689056 , Discriminator loss: 0.44254723 , time: 0:01:15.123672\n",
      "Batch/Epoch: 104 / 2 , Generator loss: 33.20224 , Discriminator loss: 0.6351356 , time: 0:01:15.284029\n",
      "Batch/Epoch: 105 / 2 , Generator loss: 31.658375 , Discriminator loss: 0.28769875 , time: 0:01:15.442886\n",
      "Batch/Epoch: 106 / 2 , Generator loss: 37.96618 , Discriminator loss: 0.3782272 , time: 0:01:15.606475\n",
      "Batch/Epoch: 107 / 2 , Generator loss: 36.12322 , Discriminator loss: 0.08829345 , time: 0:01:15.774179\n",
      "Batch/Epoch: 108 / 2 , Generator loss: 35.4082 , Discriminator loss: 0.26941937 , time: 0:01:15.935816\n",
      "Batch/Epoch: 109 / 2 , Generator loss: 36.52078 , Discriminator loss: 0.80365676 , time: 0:01:16.097787\n",
      "Batch/Epoch: 110 / 2 , Generator loss: 35.559647 , Discriminator loss: 0.18951985 , time: 0:01:16.258260\n",
      "Batch/Epoch: 111 / 2 , Generator loss: 33.741447 , Discriminator loss: 0.91853774 , time: 0:01:16.423817\n",
      "Batch/Epoch: 112 / 2 , Generator loss: 35.09632 , Discriminator loss: 1.2959146 , time: 0:01:16.586646\n",
      "Batch/Epoch: 113 / 2 , Generator loss: 38.55107 , Discriminator loss: 0.26469386 , time: 0:01:16.748007\n",
      "Batch/Epoch: 114 / 2 , Generator loss: 38.839813 , Discriminator loss: 0.10272743 , time: 0:01:16.909576\n",
      "Batch/Epoch: 115 / 2 , Generator loss: 32.409134 , Discriminator loss: 0.51992667 , time: 0:01:17.070020\n",
      "Batch/Epoch: 116 / 2 , Generator loss: 35.0297 , Discriminator loss: 0.28718626 , time: 0:01:17.230625\n",
      "Batch/Epoch: 117 / 2 , Generator loss: 37.01774 , Discriminator loss: 0.8308626 , time: 0:01:17.389202\n",
      "Batch/Epoch: 118 / 2 , Generator loss: 38.472736 , Discriminator loss: 0.15243176 , time: 0:01:17.549857\n",
      "Batch/Epoch: 119 / 2 , Generator loss: 34.788303 , Discriminator loss: 0.1626934 , time: 0:01:17.710632\n",
      "Batch/Epoch: 120 / 2 , Generator loss: 42.503227 , Discriminator loss: 0.24868676 , time: 0:01:17.867840\n",
      "Batch/Epoch: 121 / 2 , Generator loss: 36.292892 , Discriminator loss: 0.16607814 , time: 0:01:18.029832\n",
      "Batch/Epoch: 122 / 2 , Generator loss: 34.441116 , Discriminator loss: 0.14044611 , time: 0:01:18.189406\n",
      "Batch/Epoch: 123 / 2 , Generator loss: 36.228092 , Discriminator loss: 0.21413021 , time: 0:01:18.349678\n",
      "Batch/Epoch: 124 / 2 , Generator loss: 27.744589 , Discriminator loss: 0.8236447 , time: 0:01:18.511205\n",
      "Batch/Epoch: 125 / 2 , Generator loss: 33.634357 , Discriminator loss: 0.8402897 , time: 0:01:18.672772\n",
      "Batch/Epoch: 126 / 2 , Generator loss: 31.299345 , Discriminator loss: 1.1472919 , time: 0:01:18.833457\n",
      "Batch/Epoch: 127 / 2 , Generator loss: 37.213566 , Discriminator loss: 0.28303155 , time: 0:01:18.995149\n",
      "Batch/Epoch: 128 / 2 , Generator loss: 36.529484 , Discriminator loss: 0.3276084 , time: 0:01:19.154950\n",
      "Batch/Epoch: 129 / 2 , Generator loss: 33.00004 , Discriminator loss: 0.22770731 , time: 0:01:19.314008\n",
      "Batch/Epoch: 130 / 2 , Generator loss: 35.576473 , Discriminator loss: 0.48164892 , time: 0:01:19.473104\n",
      "Batch/Epoch: 131 / 2 , Generator loss: 39.76167 , Discriminator loss: 0.1858659 , time: 0:01:19.634013\n",
      "Batch/Epoch: 132 / 2 , Generator loss: 39.09967 , Discriminator loss: 0.14134145 , time: 0:01:19.796203\n",
      "Batch/Epoch: 133 / 2 , Generator loss: 26.60037 , Discriminator loss: 1.5922658 , time: 0:01:19.963758\n",
      "Batch/Epoch: 134 / 2 , Generator loss: 30.867176 , Discriminator loss: 0.20694755 , time: 0:01:20.129617\n",
      "Batch/Epoch: 135 / 2 , Generator loss: 32.991024 , Discriminator loss: 0.8365276 , time: 0:01:20.293507\n",
      "Batch/Epoch: 136 / 2 , Generator loss: 32.783974 , Discriminator loss: 1.137954 , time: 0:01:20.458033\n",
      "Batch/Epoch: 137 / 2 , Generator loss: 32.608467 , Discriminator loss: 0.6430776 , time: 0:01:20.621597\n",
      "Batch/Epoch: 138 / 2 , Generator loss: 35.996056 , Discriminator loss: 1.2242725 , time: 0:01:20.784162\n",
      "Batch/Epoch: 139 / 2 , Generator loss: 36.235252 , Discriminator loss: 0.14498413 , time: 0:01:20.941648\n",
      "Batch/Epoch: 140 / 2 , Generator loss: 37.97422 , Discriminator loss: 0.3537963 , time: 0:01:21.103013\n",
      "Batch/Epoch: 141 / 2 , Generator loss: 40.107037 , Discriminator loss: 0.3436741 , time: 0:01:21.264802\n",
      "Batch/Epoch: 142 / 2 , Generator loss: 35.466053 , Discriminator loss: 0.2147476 , time: 0:01:21.421919\n",
      "Batch/Epoch: 143 / 2 , Generator loss: 37.817974 , Discriminator loss: 1.1645634 , time: 0:01:21.579498\n",
      "Batch/Epoch: 144 / 2 , Generator loss: 28.94432 , Discriminator loss: 0.80551404 , time: 0:01:21.737109\n",
      "Batch/Epoch: 145 / 2 , Generator loss: 36.457695 , Discriminator loss: 0.23008263 , time: 0:01:21.900673\n",
      "Batch/Epoch: 146 / 2 , Generator loss: 32.4244 , Discriminator loss: 1.8921497 , time: 0:01:22.063335\n",
      "Batch/Epoch: 147 / 2 , Generator loss: 34.5299 , Discriminator loss: 1.5566479 , time: 0:01:22.224541\n",
      "Batch/Epoch: 148 / 2 , Generator loss: 32.24721 , Discriminator loss: 0.3286517 , time: 0:01:22.385941\n",
      "Batch/Epoch: 149 / 2 , Generator loss: 36.41696 , Discriminator loss: 1.2893153 , time: 0:01:22.547530\n",
      "Batch/Epoch: 150 / 2 , Generator loss: 31.486277 , Discriminator loss: 2.6445894 , time: 0:01:22.710043\n",
      "Batch/Epoch: 151 / 2 , Generator loss: 37.04731 , Discriminator loss: 0.42797983 , time: 0:01:22.872642\n",
      "Batch/Epoch: 152 / 2 , Generator loss: 33.94323 , Discriminator loss: 0.26637638 , time: 0:01:23.032193\n",
      "Batch/Epoch: 153 / 2 , Generator loss: 33.167866 , Discriminator loss: 1.1597497 , time: 0:01:23.190794\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Execute the training routine\n",
    "number_of_epochs = 2\n",
    "nm, ep = train(epochs=number_of_epochs)\n",
    "if True: #enable to plot NMSE over epochs\n",
    "    plt.figure()\n",
    "    plt.plot(ep,nm,'^-r')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('NMSE')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e85753",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "- [Marcos Yuichi Takeda - LASSE/UFPA](https://github.com/yuichitakeda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.14 ('ai6g-xssCGMI2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "dac2514730ec6dd4fc1d04cb6927967d7376870f25ae7edf50b318831380a3e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
